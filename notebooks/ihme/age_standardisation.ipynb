{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('../..')\n",
    "from data.dataloader import Covid19IndiaLoader\n",
    "from utils.age_standardisation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise_age(district, state, area_name):\n",
    "    data = district_timeseries[district].set_index('date')\n",
    "    raw_all_district_age_data = age_data[state]\n",
    "\n",
    "    all_district_age_data = clean(raw_all_district_age_data)\n",
    "\n",
    "    # Get relevant district(s) data\n",
    "    district_age_data = all_district_age_data[all_district_age_data['Area Name'] == area_name]\n",
    "\n",
    "    district_age_band_pops, district_total_pop = get_age_band_population(district_age_data)\n",
    "    assert(district_total_pop == sum(district_age_band_pops.values()))\n",
    "\n",
    "    district_age_band_ratios = {k: v / district_total_pop for k, v in district_age_band_pops.items()}\n",
    "\n",
    "    ref_age_band_ratios = {\n",
    "        '0-9': 0.1144545912,\n",
    "        '10-19': 0.1096780507,\n",
    "        '20-29': 0.1387701325,\n",
    "        '30-39': 0.1481915984,\n",
    "        '40-49': 0.1548679659,\n",
    "        '50-59': 0.1428622446,\n",
    "        '60-69': 0.1092853481,\n",
    "        '70-79': 0.05542319854,\n",
    "        '80+': 0.02646687006,\n",
    "    }\n",
    "\n",
    "    # calculated here: https://docs.google.com/spreadsheets/d/1APX7XwoJPIbUXOgXa2vZNreDn6UseBucSGq9fh-N5jE/edit#gid=1859974541\n",
    "    # CFR based\n",
    "    ref_mortality_rate = {\n",
    "        '0-9': 0.0002447933091,\n",
    "        '10-19': 0.000377136454,\n",
    "        '20-29': 0.0009389093188,\n",
    "        '30-39': 0.001769966645,\n",
    "        '40-49': 0.003645033792,\n",
    "        '50-59': 0.01343325563,\n",
    "        '60-69': 0.03884219978,\n",
    "        '70-79': 0.08406020728,\n",
    "        '80+': 0.1421208672,\n",
    "    }\n",
    "\n",
    "    # # Deaths/Population based (excl SK)\n",
    "    # ref_mortality_rate = {\n",
    "    #     '0-9': 0.00000001922452747,\n",
    "    #     '10-19': 0.00000001996437158,\n",
    "    #     '20-29': 0.0000001540307269,\n",
    "    #     '30-39': 0.0000004222770726,\n",
    "    #     '40-49': 0.00000128438119,\n",
    "    #     '50-59': 0.000005125162691,\n",
    "    #     '60-69': 0.00001948507013,\n",
    "    #     '70-79': 0.00009988464688,\n",
    "    #     '80+': 0.0003878624777,\n",
    "    # }\n",
    "\n",
    "    # Deaths/Population based (excl SK/China)\n",
    "    # ref_mortality_rate = {\n",
    "    #     '0-9': 0.00000008160306469,\n",
    "    #     '10-19': 0.00000005586337197,\n",
    "    #     '20-29': 0.0000005590581798,\n",
    "    #     '30-39': 0.000001683722774,\n",
    "    #     '40-49': 0.000005820174078,\n",
    "    #     '50-59': 0.00002088458866,\n",
    "    #     '60-69': 0.00007149402853,\n",
    "    #     '70-79': 0.0003066451643,\n",
    "    #     '80+': 0.0009211554807,\n",
    "    # }\n",
    "\n",
    "    # age weighted mortality based on other countries\n",
    "    implied_mortality = sum([ref_age_band_ratios[k] * ref_mortality_rate[k] for k in ref_mortality_rate.keys()])\n",
    "\n",
    "    # need mortality rate from India -- this is going to be dependent on case data, so introducing that testing bias...\n",
    "    # observed deaths/known cases\n",
    "    daily_observed_mortality = data['total_deaths']/district_total_pop\n",
    "\n",
    "    # how much different is it observed than 'implied'\n",
    "    daily_mortality_ratio = daily_observed_mortality/implied_mortality\n",
    "\n",
    "    # mortality rate accounting for observed/implied discrepancy\n",
    "    age_stratified_daily_mortality = {k: daily_mortality_ratio * ref_mortality_rate[k] for k in ref_mortality_rate.keys()}\n",
    "\n",
    "    # mortality rate accounting for observed/implied discrepancy and weighted by model location age\n",
    "    age_std_mortality = sum([age_stratified_daily_mortality[k] * district_age_band_ratios[k] for k in district_age_band_ratios.keys()])\n",
    "    # print(age_std_mortality)\n",
    "\n",
    "    log_age_std_mortality = np.log(age_std_mortality)\n",
    "\n",
    "    checker = pd.DataFrame()\n",
    "    # print(district_total_pop)\n",
    "    checker['age_std'] = age_std_mortality\n",
    "    checker['non_std'] = daily_observed_mortality\n",
    "    return checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = Covid19IndiaLoader()\n",
    "dataframes = loader.get_covid19india_api_data()\n",
    "\n",
    "districts = ['Mumbai', 'Bengaluru', 'Ahmadabad', 'Jaipur', 'Pune', 'New Delhi']\n",
    "states = ['Maharashtra', 'Karnataka', 'Gujarat', 'Rajasthan', 'Maharashtra', 'Delhi']\n",
    "district_timeseries = get_district_time_series(dataframes, state=states, district=districts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get age data in bands\n",
    "filenames = 'DDW-{}00C-13'\n",
    "state_file_mapping = {\n",
    "    filenames.format('24'): 'Gujarat',\n",
    "    filenames.format('29'): 'Karnataka',\n",
    "    filenames.format('27'): 'Maharashtra',\n",
    "    filenames.format('07'): 'Delhi',\n",
    "    filenames.format('08'): 'Rajasthan',\n",
    "}\n",
    "\n",
    "age_data = {}\n",
    "directory = '../../data/data/census/'\n",
    "for filename in os.listdir(directory):\n",
    "    df = pd.read_excel(os.path.join(directory, filename))\n",
    "    age_data[state_file_mapping[filename.split('.')[0]]] = df.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amd = 'District - Ahmadabad (07)'\n",
    "mumbai = 'District - Mumbai (23)'\n",
    "mumbai2 = 'District - Mumbai Suburban (22)'\n",
    "pune = 'District - Pune (25)'\n",
    "delhi ='District - New Delhi (05)'\n",
    "jaipur = 'District - Jaipur (12)'\n",
    "bengaluru = 'District - Bangalore (18)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# age_std = standardise_age('New Delhi', 'Delhi', delhi)\n",
    "# age_std = standardise_age('Bengaluru', 'Karnataka', bengaluru)\n",
    "age_std = standardise_age('Mumbai', 'Maharashtra', mumbai)\n",
    "# age_std = standardise_age('Pune', 'Maharashtra', pune)\n",
    "# age_std = standardise_age('Ahmadabad', 'Gujarat', amd)\n",
    "# age_std = standardise_age('Jaipur', 'Rajasthan', jaipur)\n",
    "age_std = age_std.reset_index(col_fill='date')\n",
    "age_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta, datetime\n",
    "\n",
    "import curvefit\n",
    "from curvefit.core.utils import data_translator\n",
    "from curvefit.pipelines.basic_model import BasicModel\n",
    "\n",
    "sys.path.append('../..')\n",
    "from utils.data import Params\n",
    "from models.ihme.plotting import Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load params\n",
    "daily, smoothing_window = False, False\n",
    "# params = Params(args.params)\n",
    "\n",
    "age_std['group'] = 1\n",
    "df = age_std\n",
    "agg_df = age_std\n",
    "\n",
    "from curvefit.core.functions import *\n",
    "func = erf\n",
    "# set vars\n",
    "date, groupcol = 'date', 'group'\n",
    "xcol, ycol = 'date', 'age_std'\n",
    "daysforward, daysback = 90, -10\n",
    "pipeline_run_args =  {\n",
    "    \"n_draws\": 20,\n",
    "    \"cv_threshold\": 1e-2,\n",
    "    \"smoothed_radius\": [7,7],\n",
    "    \"num_smooths\": 3,\n",
    "    \"exclude_groups\": [],\n",
    "    \"exclude_below\": 0,\n",
    "    \"exp_smoothing\": None,\n",
    "    \"max_last\": None,\n",
    "}\n",
    "\n",
    "priors = {\n",
    "            \"fe_init\": [0.33, 0.5, 0.66],\n",
    "\t\t\t\"fe_bounds\": [[0, 1], [1, 100], [1, 10000]]\n",
    "\t\t}\n",
    "# output\n",
    "fname = 'age_std_mumbai'\n",
    "output_folder = f'output/pipeline/{fname}'\n",
    "if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "predictdate = pd.to_datetime(pd.Series([timedelta(days=x)+df[date].iloc[0] for x in range(-daysback,daysforward)]))\n",
    "predictx = np.array([x+1 for x in range(-daysback,daysforward)])\n",
    "\n",
    "# link functions\n",
    "identity_fun = lambda x: x\n",
    "exp_fun = lambda x : np.exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_plot(curve_model, xcol, ycol, data, test, func, pargs={}, orig_ycol=None):\n",
    "    p_args = {\n",
    "        \"n_draws\": 5,\n",
    "        \"cv_threshold\": 1e-2,\n",
    "        \"smoothed_radius\": [3,3], \n",
    "        \"num_smooths\": 3, \n",
    "        \"exclude_groups\": [], \n",
    "        \"exclude_below\": 0,\n",
    "        \"exp_smoothing\": None, \n",
    "        \"max_last\": None\n",
    "    }\n",
    "    p_args.update(pargs)\n",
    "    \n",
    "    # pipeline\n",
    "    pipeline.setup_pipeline()\n",
    "    pipeline.run(n_draws=p_args['n_draws'], prediction_times=predictx, \n",
    "        cv_threshold=p_args['cv_threshold'], smoothed_radius=p_args['smoothed_radius'], \n",
    "        num_smooths=p_args['num_smooths'], exclude_groups=p_args['exclude_groups'], \n",
    "        exclude_below=p_args['exclude_below'], exp_smoothing=p_args['exp_smoothing'], \n",
    "        max_last=p_args['max_last']\n",
    "    )\n",
    "    params_estimate = pipeline.mod.params\n",
    "    print(params_estimate)\n",
    "    dailycolname = dailycol.format(ycol=ycol) if daily else None\n",
    "\n",
    "    plotter = Plotter(pipeline, params, predictdate, predictx, f'{fname}_{seed}', output_folder, ycol, func)\n",
    "    plotter.plot_draws(dailycolname=dailycolname)\n",
    "\n",
    "    # plot_prediction calls these functions:\n",
    "        # group_predictions, predictions = predict(func, multigroup)\n",
    "        # calc_error(test, predictions, agg_data, daysback)\n",
    "    plotter.plot_predictions(df, agg_data, agg_test, orig_ycol, test, daysback, smoothing_window, multigroup, dailycolname)\n",
    "\n",
    "    # Now, all plotting is complete. Re-acquire detailed draws information for output (csv)\n",
    "    # Reliability of these numbers are questionable. Uncertainty metric evalutation ongoing.\n",
    "    for group in pipeline.groups:\n",
    "        # x = prediction_times = predictx\n",
    "        draws = pipeline.draws[group].copy()\n",
    "        draws = data_translator(\n",
    "            data=draws,\n",
    "            input_space=pipeline.predict_space,\n",
    "            output_space=pipeline.predict_space\n",
    "        )\n",
    "        mean_fit = pipeline.mean_predictions[group].copy() # predictions\n",
    "        mean_fit = data_translator(\n",
    "            data=mean_fit,\n",
    "            input_space=pipeline.predict_space,\n",
    "            output_space=pipeline.predict_space\n",
    "        )\n",
    "        mean = draws.mean(axis=0)\n",
    "        # uncertainty\n",
    "        lower = np.quantile(draws, axis=0, q=0.025)\n",
    "        upper = np.quantile(draws, axis=0, q=0.975)\n",
    "\n",
    "    return mean_fit, lower, mean, upper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'covs'] = len(df) * [ 1.0 ]\n",
    "df.loc[:,'sd'] = df[date].apply(lambda x: [1.0 if x >= datetime(2020, 3, 24) else 0.0]).tolist()\n",
    "df.loc[:,f'{ycol}_normalized'] = df[ycol]/df[ycol].max()\n",
    "\n",
    "param_names  = [ 'alpha', 'beta', 'p' ]\n",
    "covs = ['covs', 'covs', 'covs']\n",
    "# link_fun = [ identity_fun, exp_fun, exp_fun ]\n",
    "link_fun = [ exp_fun, identity_fun, exp_fun ] # According to their methods should be\n",
    "var_link_fun = [ identity_fun, identity_fun, identity_fun ]\n",
    "# var_link_fun = link_fun\n",
    "\n",
    "\n",
    "pipeline = BasicModel(\n",
    "    all_data=df, #: (pd.DataFrame) of *all* the data that will go into this modeling pipeline\n",
    "    col_t=xcol, #: (str) name of the column with time\n",
    "    col_group=groupcol, #: (str) name of the column with the group in it\n",
    "    col_obs=ycol, #: (str) the name of the column with observations for fitting the model\n",
    "    col_obs_compare=ycol,\n",
    "    all_cov_names=covs, \n",
    "    fun=func, #: (callable) the space to fit in, one of curvefit.functions\n",
    "    predict_space=func,\n",
    "    obs_se_func=None,\n",
    "    fit_dict=priors, #: keyword arguments to CurveModel.fit_params()\n",
    "    basic_model_dict= { #: additional keyword arguments to the CurveModel class\n",
    "        'col_obs_se': None,#(str) of observation standard error\n",
    "        'col_covs': [[cov] for cov in covs],\n",
    "        'param_names': param_names,#(list{str}):\n",
    "        'link_fun': link_fun,#(list{function}):\n",
    "        'var_link_fun': var_link_fun,#(list{function}):\n",
    "    },\n",
    ")\n",
    "fit_predict_plot(pipeline, xcol, ycol, data, test, func, pargs=pipeline_run_args, orig_ycol=orig_ycol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
