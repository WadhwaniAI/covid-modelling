{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from hyperopt import hp, tpe, fmin, Trials\n",
    "from tqdm import tqdm\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "from collections import OrderedDict, defaultdict\n",
    "import itertools\n",
    "from functools import partial\n",
    "import datetime\n",
    "from joblib import Parallel, delayed\n",
    "import copy\n",
    "import json\n",
    "import pymc3 as pm\n",
    "from pymc3.ode import DifferentialEquation\n",
    "from theano.ifelse import ifelse\n",
    "from theano import tensor as T, function, printing\n",
    "import theano\n",
    "theano.config.compute_test_value='ignore'\n",
    "theano.config.gcc.cxxflags = \"-Wno-c++11-narrowing\"\n",
    "\n",
    "\n",
    "from data.dataloader import get_jhu_data, get_covid19india_api_data, get_rootnet_api_data\n",
    "from data.processing import get_data, get_district_time_series\n",
    "\n",
    "from models.seir.seir_testing import SEIR_Testing, SEIR_Test_pymc3\n",
    "from main.seir.optimiser import Optimiser\n",
    "from main.seir.losses import Loss_Calculator\n",
    "from main.seir.fitting import single_fitting_cycle, train_val_split\n",
    "from main.seir.forecast import create_region_csv, create_all_csvs, write_csv, plot_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of E/Hosp and I/Hosp ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for district in predictions_dict.keys():\n",
    "    district_dict = predictions_dict[district]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    ax.plot(district_dict['m1']['df_prediction']['date'], district_dict['m1']['df_prediction']['E'] / district_dict['m1']['df_prediction']['hospitalised'],\n",
    "            '-', color='C0', label='E / Hosp (M1)')\n",
    "    ax.plot(district_dict['m1']['df_prediction']['date'], district_dict['m1']['df_prediction']['I'] / district_dict['m1']['df_prediction']['hospitalised'],\n",
    "            '-.', color='C0', label='I / Hosp (M1)')\n",
    "    ax.xaxis.set_major_locator(mdates.DayLocator(interval=7))\n",
    "    ax.xaxis.set_minor_locator(mdates.DayLocator(interval=1))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    plt.ylabel('No of People')\n",
    "    plt.xlabel('Time')\n",
    "    plt.legend()\n",
    "    plt.title('I/Hosp and E/Hosp ratio for {}, {}'.format(district[0], district[1]))\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Covid19india Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = get_covid19india_api_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Districts to fit on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts_to_show = [('Maharashtra', 'Pune'), \n",
    "                     ('Maharashtra', 'Mumbai'), \n",
    "                     ('Rajasthan', 'Jaipur'), \n",
    "                     ('Gujarat', 'Ahmedabad'), \n",
    "                     ('Karnataka', 'Bengaluru Urban'),\n",
    "                     ('Delhi', None)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform M1 and M2 fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for state, district in districts_to_show:\n",
    "    predictions_dict[(state, district)] = {}\n",
    "    predictions_dict[(state, district)]['m1'] = single_fitting_cycle(dataframes, state, district, train_period=7, val_period=7, \n",
    "                                                                     data_from_tracker=True, initialisation='intermediate',\n",
    "                                                                     which_compartments=['hospitalised', 'total_infected'])\n",
    "    predictions_dict[(state, district)]['m2'] = single_fitting_cycle(dataframes, state, district, train_period=7, val_period=0, \n",
    "                                                                     train_on_val=True, data_from_tracker=True, initialisation='intermediate',\n",
    "                                                                     which_compartments=['hospitalised', 'total_infected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimiser_pymc3(Optimiser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def solve(self, variable_params, default_params, df_true, start_date=None, end_date=None, \n",
    "              state_init_values=None, initialisation='starting', loss_indices=[-20, -10]):\n",
    "        params_dict = {**variable_params, **default_params}\n",
    "        if initialisation == 'intermediate':\n",
    "            row = df_true.iloc[loss_indices[0], :]\n",
    "            \n",
    "            state_init_values = OrderedDict()\n",
    "            key_order = ['S', 'E', 'I', 'D_E', 'D_I', \n",
    "                'R_mild', 'R_severe_home', 'R_severe_hosp', 'R_fatal', 'C', 'D']\n",
    "            for key in key_order:\n",
    "                state_init_values[key] = 0\n",
    "\n",
    "            state_init_values['R_severe_hosp'] = params_dict['P_severe'] / (params_dict['P_severe'] + params_dict['P_fatal']) * row['hospitalised']\n",
    "            state_init_values['R_fatal'] = params_dict['P_fatal'] / (params_dict['P_severe'] + params_dict['P_fatal']) * row['hospitalised']\n",
    "            state_init_values['C'] = row['recovered']\n",
    "            state_init_values['D'] = row['deceased']\n",
    "\n",
    "            state_init_values['E'] = params_dict['E_hosp_ratio'] * row['hospitalised']\n",
    "            state_init_values['I'] = params_dict['I_hosp_ratio'] * row['hospitalised']\n",
    "            \n",
    "            nonSsum = sum(state_init_values.values())\n",
    "            state_init_values['S'] = (params_dict['N'] - nonSsum)\n",
    "            for key in state_init_values.keys():\n",
    "                state_init_values[key] = state_init_values[key]/params_dict['N']\n",
    "            params_dict['state_init_values'] = state_init_values\n",
    "        \n",
    "        if end_date == None:\n",
    "            end_date = df_true.iloc[-1, :]['date']\n",
    "        else:\n",
    "            if type(end_date) is str:\n",
    "                end_date = datetime.datetime.strptime(end_date, '%Y-%m-%d')\n",
    "        \n",
    "        if start_date != None:\n",
    "            if type(start_date) is str:\n",
    "                start_date = datetime.datetime.strptime(start_date, '%Y-%m-%d')\n",
    "            params_dict['starting_date'] = start_date\n",
    "\n",
    "\n",
    "        solver = SEIR_Testing_pymc3(**params_dict)\n",
    "        total_days = (end_date - params_dict['starting_date']).days\n",
    "        sol = solver.solve_ode(total_no_of_days=total_days, time_step=1)\n",
    "        return sol\n",
    "        #df_prediction = solver.return_predictions(sol)\n",
    "        #return df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_mcmc(params, default_params, df_train, initialisation, train_period):\n",
    "    if train_on_val:\n",
    "        df_prediction = optimiser.solve(params, default_params, df_train, end_date=df_train.iloc[-1, :]['date'], \n",
    "                                        initialisation=initialisation, loss_indices=[-train_period, None])\n",
    "    else:\n",
    "        df_prediction = optimiser.solve(params, default_params, df_train, end_date=df_val.iloc[-1, :]['date'],\n",
    "                                        initialisation=initialisation, loss_indices=[-train_period, None])\n",
    "    return df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_period=7\n",
    "val_period=0\n",
    "train_on_val=True\n",
    "data_from_tracker=True\n",
    "initialisation='intermediate'\n",
    "which_compartments=['hospitalised', 'total_infected']\n",
    "use_mcmc = True\n",
    "state = \"Maharashtra\"\n",
    "district= \"Mumbai\"\n",
    "filename=None\n",
    "pre_lockdown=False\n",
    "N=1e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('fitting to data with \"train_on_val\" set to {} ..'.format(train_on_val))\n",
    "\n",
    "if data_from_tracker:\n",
    "    df_district = get_data(dataframes, state=state, district=district, use_dataframe='districts_daily')\n",
    "else:\n",
    "    df_district = get_data(dataframes, state, district, disable_tracker=True, filename=filename)\n",
    "\n",
    "df_district_raw_data = get_data(dataframes, state=state, district=district, use_dataframe='raw_data')\n",
    "df_district_raw_data = df_district_raw_data[df_district_raw_data['date'] <= '2020-03-25']\n",
    "\n",
    "if district is None:\n",
    "    district = ''\n",
    "\n",
    "# Get train val split\n",
    "if pre_lockdown:\n",
    "    df_train, df_val, df_true_fitting = train_val_split(\n",
    "        df_district_raw_data, train_rollingmean=False, val_rollingmean=False, val_size=0)\n",
    "else:\n",
    "    if train_on_val:\n",
    "        df_train, df_val, df_true_fitting = train_val_split(\n",
    "            df_district, train_rollingmean=True, val_rollingmean=True, val_size=0)\n",
    "        df_train_nora, df_val_nora, df_true_fitting = train_val_split(\n",
    "            df_district, train_rollingmean=False, val_rollingmean=False, val_size=val_period)\n",
    "    else:\n",
    "        df_train, df_val, df_true_fitting = train_val_split(\n",
    "            df_district, train_rollingmean=True, val_rollingmean=True, val_size=val_period)\n",
    "        df_train_nora, df_val_nora, df_true_fitting = train_val_split(\n",
    "            df_district, train_rollingmean=False, val_rollingmean=False, val_size=val_period)\n",
    "\n",
    "print('train\\n', df_train.tail())\n",
    "print('val\\n', df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise Optimiser\n",
    "optimiser = Optimiser_pymc3()\n",
    "# Get the fixed params\n",
    "if initialisation == 'starting':\n",
    "    init_infected = max(df_district_raw_data.iloc[0, :]['total_infected'], 1)\n",
    "    start_date = df_district_raw_data.iloc[0, :]['date']\n",
    "    default_params = optimiser.init_default_params(df_train, N=N, init_infected=init_infected, \n",
    "                                                   start_date=start_date)\n",
    "if initialisation == 'intermediate':\n",
    "    start_date = df_train.iloc[-train_period, :]['date']\n",
    "    default_params = optimiser.init_default_params(df_train, N=N, init_infected=0, \n",
    "                                                   start_date=start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO implement which compartments\n",
    "SEIR_Test_obj = SEIR_Test_pymc3()\n",
    "num_patients = SEIR_Test_obj.__dict__['vanilla_params']['N']\n",
    "init_vals = list(SEIR_Test_obj.__dict__['state_init_values'].values())\n",
    "num_states = 11\n",
    "num_params = 7\n",
    "num_steps = 40\n",
    "num_train_steps = 7\n",
    "\n",
    "burn_in = 10\n",
    "mcmc_steps = 20\n",
    "\n",
    "observed = df_train['total_infected'][-num_train_steps:]\n",
    "num_train = len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sir_model = DifferentialEquation(\n",
    "    func=SEIR_Test_obj.get_derivative,\n",
    "    times=np.arange(0, num_steps, 1),\n",
    "    n_states= num_states,\n",
    "    n_theta= num_params,\n",
    "    t0 = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    R0 = pm.Uniform(\"R0\", lower = 1, upper = 3)#(1.6, 3)\n",
    "    T_inc = pm.Uniform(\"T_inc\", lower = 1, upper = 5)#(3, 4)\n",
    "    T_inf = pm.Uniform(\"T_inf\", lower = 1, upper = 4)#(3, 4)\n",
    "    T_recov_severe = pm.Uniform(\"T_recov_severe \", lower = 9, upper = 20)\n",
    "    P_severe = pm.Uniform(\"P_severe\", lower = 0.3, upper = 0.99)\n",
    "    P_fatal = pm.Uniform(\"P_fatal\", lower = 1e-6, upper = 0.3)\n",
    "    intervention_amount = pm.Uniform(\"intervention_amount\", lower = 0.3, upper = 1)\n",
    "    E_hosp_ratio = pm.Uniform(\"E_hosp_ratio\", lower = 1e-6, upper = 2)\n",
    "    I_hosp_ratio = pm.Uniform(\"I_hosp_ratio\", lower = 1e-6, upper = 1)\n",
    "    \n",
    "    ode_solution = sir_model(y0=init_vals , theta=[R0, T_inc, T_inf, T_recov_severe, P_severe,\n",
    "                                                   P_fatal, intervention_amount])\n",
    "    # The ode_solution has a shape of (n_times, n_states)\n",
    "\n",
    "    predictions = ode_solution[num_train-num_train_steps-1:num_train-1]\n",
    "    hospitalised = predictions[:,6] + predictions[:,7] + predictions[:,8]\n",
    "    recovered = predictions[:,9]\n",
    "    deceased = predictions[:,10]\n",
    "    total_infected = hospitalised + recovered + deceased\n",
    "    total_infected = total_infected * num_patients \n",
    "    #sigma = pm.HalfNormal('sigma',\n",
    "    #                      sigma=observed.std(),\n",
    "    #                      shape=num_params)\n",
    "    Y = pm.Normal('Y', mu = total_infected, observed=observed)\n",
    "\n",
    "    prior = pm.sample_prior_predictive()\n",
    "    trace = pm.sample(mcmc_steps, tune=burn_in , target_accept=0.9, cores=4)\n",
    "    posterior_predictive = pm.sample_posterior_predictive(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_predictions = pd.DataFrame() \n",
    "for params in trace:\n",
    "    df_prediction = get_predictions_mcmc(params, default_params, df_train, initialisation, train_period)\n",
    "    total_df_predictions = pd.concat([total_df_prediction, prediction], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction = total_df_predictions.mean(axis = 1)\n",
    "df_upper =  df_prediction  + 1.96*total_df_predictions.std(axis = 1)\n",
    "df_lower =  df_prediction  - 1.96*total_df_predictions.std(axis = 1)\n",
    "df_loss = calculate_loss(df_train_nora, df_val_nora, df_prediction, train_period,\n",
    "                         train_on_val, which_compartments=which_compartments)\n",
    "\n",
    "\n",
    "ax = create_plots(df_prediction, df_train, df_val, df_train_nora, df_val_nora, train_period, state, district,\n",
    "                  which_compartments=which_compartments)\n",
    "\n",
    "results_dict = {}\n",
    "for name in ['best_params', 'default_params', 'optimiser', 'df_prediction', 'df_district', 'df_train', \\\n",
    "    'df_val', 'df_loss', 'ax']:\n",
    "    results_dict[name] = eval(name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Master Loss Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_columns = pd.MultiIndex.from_product([predictions_dict[('Maharashtra', 'Pune')]['m1']['df_loss'].columns, predictions_dict[('Maharashtra', 'Pune')]['m1']['df_loss'].index])\n",
    "loss_index = predictions_dict.keys()\n",
    "\n",
    "df_loss_master = pd.DataFrame(columns=loss_columns, index=loss_index)\n",
    "for key in predictions_dict.keys():\n",
    "    df_loss_master.loc[key, :] = np.around(predictions_dict[key]['m1']['df_loss'].values.T.flatten().astype('float'), decimals=2)\n",
    "    \n",
    "df_loss_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict[('Maharashtra','Mumbai')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for region in predictions_dict.keys():\n",
    "    plot_forecast(predictions_dict[region], region, both_forecasts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Save Output CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = create_all_csvs(predictions_dict, initialisation='intermediate', train_period=7, icu_fraction=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(df_output, '../../output-{}.csv'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Pune Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(predictions_dict[('Maharashtra', 'Pune')], ('Maharashtra', 'Pune'), both_forecasts=False, filename='../../plots/m2-only.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(predictions_dict[('Maharashtra', 'Mumbai')])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
