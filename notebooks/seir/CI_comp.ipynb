{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import copy\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from data.processing import get_data\n",
    "\n",
    "import models\n",
    "\n",
    "from main.seir.fitting import single_fitting_cycle\n",
    "from main.seir.forecast import get_forecast, forecast_all_trials, create_all_trials_csv, create_decile_csv_new\n",
    "\n",
    "from utils.generic.create_report import save_dict_and_create_report\n",
    "from utils.generic.config import read_config\n",
    "from utils.generic.enums import Columns\n",
    "from utils.fitting.loss import Loss_Calculator\n",
    "#from utils.generic.logging import log_wandb\n",
    "from viz import plot_forecast, plot_top_k_trials, plot_ptiles, plot_ptiles_comp\n",
    "from viz.fit import plot_all_losses\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists, join, splitext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_filename1 = 'default.yaml'\n",
    "config_filename2 = 'uncer.yaml'\n",
    "config1 = read_config(config_filename1)\n",
    "config2 = read_config(config_filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('../../misc/predictions/test_mumbai_logdiff.pickle', 'rb') as handle:\n",
    "    PD = pkl.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict_b = PD['m0']['BO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict_m = PD['m0']['MCMC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict_m['m1']['forecasts'] = {}        \n",
    "predictions_dict_m['m1']['forecasts']['best'] = get_forecast(predictions_dict_m, train_fit='m1', \n",
    "                                                                model=config2['fitting']['model'], \n",
    "                                                                forecast_days=config2['forecast']['forecast_days'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict_b['m1']['forecasts'] = {}\n",
    "predictions_dict_b['m1']['forecasts']['best'] = get_forecast(predictions_dict_b, train_fit='m1', \n",
    "                                                                model=config1['fitting']['model'], \n",
    "                                                                forecast_days=config1['forecast']['forecast_days'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict_m['m1']['trials_processed'] = forecast_all_trials(predictions_dict_m, train_fit='m1', \n",
    "                                                                        model=config2['fitting']['model'], \n",
    "                                                                        forecast_days=config2['forecast']['forecast_days'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict_b['m1']['trials_processed'] = forecast_all_trials(predictions_dict_b, train_fit='m1', \n",
    "                                                                        model=config2['fitting']['model'], \n",
    "                                                                        forecast_days=config2['forecast']['forecast_days'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty_args_m = {'predictions_dict': predictions_dict_m, 'fitting_config': config2['fitting'],\n",
    "                    'forecast_config': config2['forecast'], **config2['uncertainty']['uncertainty_params']}\n",
    "uncertainty_args_b = {'predictions_dict': predictions_dict_b, 'fitting_config': config1['fitting'],\n",
    "                    'forecast_config': config1['forecast'], **config1['uncertainty']['uncertainty_params']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_filename1 = 'default.yaml'\n",
    "config_filename2 = 'uncer.yaml'\n",
    "config1 = read_config(config_filename1)\n",
    "config2 = read_config(config_filename2)\n",
    "uncertainty_args_m = {'predictions_dict': predictions_dict_m, 'fitting_config': config2['fitting'],\n",
    "                    'forecast_config': config2['forecast'], **config2['uncertainty']['uncertainty_params']}\n",
    "uncertainty_args_b = {'predictions_dict': predictions_dict_b, 'fitting_config': config1['fitting'],\n",
    "                    'forecast_config': config1['forecast'], **config1['uncertainty']['uncertainty_params']}\n",
    "config1['uncertainty']['uncertainty_params']['sort_trials_by_column']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty_m = config2['uncertainty']['method'](**uncertainty_args_m)\n",
    "predictions_dict_m['uncertainty_forecasts'] = uncertainty_m.get_forecasts()\n",
    "predictions_dict_m['ensemble_mean_forecast'] = uncertainty_m.ensemble_mean_forecast\n",
    "print('BO')\n",
    "uncertainty_b = config1['uncertainty']['method'](**uncertainty_args_b)\n",
    "predictions_dict_b['uncertainty_forecasts'] = uncertainty_b.get_forecasts()\n",
    "predictions_dict_b['ensemble_mean_forecast'] = uncertainty_b.ensemble_mean_forecast\n",
    "PD_t= {}\n",
    "PD_t['MCMC'] = predictions_dict_m.copy()\n",
    "PD_t['BO'] = predictions_dict_b.copy()\n",
    "import pickle as pkl\n",
    "with open('../../misc/predictions/mcmc_total_l.pickle', 'wb') as handle:\n",
    "    pkl.dump(PD_t, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_filename1 = 'default.yaml'\n",
    "config_filename2 = 'uncer.yaml'\n",
    "config1 = read_config(config_filename1)\n",
    "config2 = read_config(config_filename2)\n",
    "uncertainty_args_m = {'predictions_dict': predictions_dict_m, 'fitting_config': config2['fitting'],\n",
    "                    'forecast_config': config2['forecast'], **config2['uncertainty']['uncertainty_params']}\n",
    "uncertainty_args_b = {'predictions_dict': predictions_dict_b, 'fitting_config': config1['fitting'],\n",
    "                    'forecast_config': config1['forecast'], **config1['uncertainty']['uncertainty_params']}\n",
    "config1['uncertainty']['uncertainty_params']['sort_trials_by_column']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty_m = config2['uncertainty']['method'](**uncertainty_args_m)\n",
    "predictions_dict_m['uncertainty_forecasts'] = uncertainty_m.get_forecasts()\n",
    "predictions_dict_m['ensemble_mean_forecast'] = uncertainty_m.ensemble_mean_forecast\n",
    "uncertainty_b = config1['uncertainty']['method'](**uncertainty_args_b)\n",
    "predictions_dict_b['uncertainty_forecasts'] = uncertainty_b.get_forecasts()\n",
    "predictions_dict_b['ensemble_mean_forecast'] = uncertainty_b.ensemble_mean_forecast\n",
    "PD_a= {}\n",
    "PD_a['MCMC'] = predictions_dict_m.copy()\n",
    "PD_a['BO'] = predictions_dict_b.copy()\n",
    "import pickle as pkl\n",
    "with open('../../misc/predictions/mcmc_active_l.pickle', 'wb') as handle:\n",
    "    pkl.dump(PD_a, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_filename1 = 'default.yaml'\n",
    "config_filename2 = 'uncer.yaml'\n",
    "config1 = read_config(config_filename1)\n",
    "config2 = read_config(config_filename2)\n",
    "uncertainty_args_m = {'predictions_dict': predictions_dict_m, 'fitting_config': config2['fitting'],\n",
    "                    'forecast_config': config2['forecast'], **config2['uncertainty']['uncertainty_params']}\n",
    "uncertainty_args_b = {'predictions_dict': predictions_dict_b, 'fitting_config': config1['fitting'],\n",
    "                    'forecast_config': config1['forecast'], **config1['uncertainty']['uncertainty_params']}\n",
    "config1['uncertainty']['uncertainty_params']['sort_trials_by_column']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty_m = config2['uncertainty']['method'](**uncertainty_args_m)\n",
    "predictions_dict_m['uncertainty_forecasts'] = uncertainty_m.get_forecasts()\n",
    "predictions_dict_m['ensemble_mean_forecast'] = uncertainty_m.ensemble_mean_forecast\n",
    "uncertainty_b = config1['uncertainty']['method'](**uncertainty_args_b)\n",
    "predictions_dict_b['uncertainty_forecasts'] = uncertainty_b.get_forecasts()\n",
    "predictions_dict_b['ensemble_mean_forecast'] = uncertainty_b.ensemble_mean_forecast\n",
    "PD_r= {}\n",
    "PD_r['MCMC'] = predictions_dict_m.copy()\n",
    "PD_r['BO'] = predictions_dict_b.copy()\n",
    "with open('../../misc/predictions/mcmc_recovered_l.pickle', 'wb') as handle:\n",
    "    pkl.dump(PD_r, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deceased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_filename1 = 'default.yaml'\n",
    "config_filename2 = 'uncer.yaml'\n",
    "config1 = read_config(config_filename1)\n",
    "config2 = read_config(config_filename2)\n",
    "uncertainty_args_m = {'predictions_dict': predictions_dict_m, 'fitting_config': config2['fitting'],\n",
    "                    'forecast_config': config2['forecast'], **config2['uncertainty']['uncertainty_params']}\n",
    "uncertainty_args_b = {'predictions_dict': predictions_dict_b, 'fitting_config': config1['fitting'],\n",
    "                    'forecast_config': config1['forecast'], **config1['uncertainty']['uncertainty_params']}\n",
    "config1['uncertainty']['uncertainty_params']['sort_trials_by_column']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty_m = config2['uncertainty']['method'](**uncertainty_args_m)\n",
    "predictions_dict_m['uncertainty_forecasts'] = uncertainty_m.get_forecasts()\n",
    "predictions_dict_m['ensemble_mean_forecast'] = uncertainty_m.ensemble_mean_forecast\n",
    "uncertainty_b = config1['uncertainty']['method'](**uncertainty_args_b)\n",
    "predictions_dict_b['uncertainty_forecasts'] = uncertainty_b.get_forecasts()\n",
    "predictions_dict_b['ensemble_mean_forecast'] = uncertainty_b.ensemble_mean_forecast\n",
    "PD_d= {}\n",
    "PD_d['MCMC'] = predictions_dict_m.copy()\n",
    "PD_d['BO'] = predictions_dict_b.copy()\n",
    "with open('../../misc/predictions/mcmc_deceased_l.pickle', 'wb') as handle:\n",
    "    pkl.dump(PD_d, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    'text.usetex': True,\n",
    "    'font.size': 15,\n",
    "    'font.family': 'Palatino',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('../../misc/predictions/mcmc_total.pickle', 'rb') as handle:\n",
    "    PD_t = pkl.load(handle)\n",
    "with open('../../misc/predictions/mcmc_active.pickle', 'rb') as handle:\n",
    "    PD_a = pkl.load(handle)\n",
    "with open('../../misc/predictions/mcmc_recovered.pickle', 'rb') as handle:\n",
    "    PD_r = pkl.load(handle)\n",
    "with open('../../misc/predictions/mcmc_deceased.pickle', 'rb') as handle:\n",
    "    PD_d = pkl.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(figsize=(30,30),nrows=2,ncols=2) \n",
    "plot_ptiles_comp(PD_t, compartment=config1['forecast']['plot_ptiles_for_columns'][0],ax=axs.flat[0])\n",
    "plot_ptiles_comp(PD_a, compartment=config1['forecast']['plot_ptiles_for_columns'][1],ax=axs.flat[1])\n",
    "plot_ptiles_comp(PD_r, compartment=config1['forecast']['plot_ptiles_for_columns'][2],ax=axs.flat[2])\n",
    "plot_ptiles_comp(PD_d, compartment=config1['forecast']['plot_ptiles_for_columns'][3],ax=axs.flat[3])\n",
    "fig.savefig('/Users/avtansht/Desktop/Desktop/Wadhwani/Plots_final/CI_logg_diff.pdf',  format='pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(figsize=(30,30),nrows=2,ncols=2) \n",
    "plot_ptiles_comp(PD_t, compartment=config1['forecast']['plot_ptiles_for_columns'][0],ax=axs.flat[0])\n",
    "plot_ptiles_comp(PD_a, compartment=config1['forecast']['plot_ptiles_for_columns'][1],ax=axs.flat[1])\n",
    "plot_ptiles_comp(PD_r, compartment=config1['forecast']['plot_ptiles_for_columns'][2],ax=axs.flat[2])\n",
    "plot_ptiles_comp(PD_d, compartment=config1['forecast']['plot_ptiles_for_columns'][3],ax=axs.flat[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
