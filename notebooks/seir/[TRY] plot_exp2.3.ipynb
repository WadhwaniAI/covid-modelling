{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "import datetime\n",
    "import copy\n",
    "import time\n",
    "import wandb\n",
    "import pickle as pkl\n",
    "import sys\n",
    "import math\n",
    "sys.path.append('../../')\n",
    "from data.processing import get_data\n",
    "import models\n",
    "from main.seir.fitting import single_fitting_cycle\n",
    "from main.seir.forecast import get_forecast, forecast_all_trials, create_all_trials_csv, create_decile_csv_new\n",
    "from main.seir.sensitivity import calculate_sensitivity_and_plot\n",
    "from utils.generic.create_report import save_dict_and_create_report\n",
    "from utils.generic.config import read_config\n",
    "from utils.generic.enums import Columns\n",
    "from utils.fitting.loss import Loss_Calculator\n",
    "from utils.generic.logging import log_wandb\n",
    "from viz import plot_forecast, plot_top_k_trials, plot_ptiles\n",
    "from viz.fit import plot_histogram, plot_all_histograms, plot_mean_variance, plot_scatter, plot_kl_divergence, plot_heatmap_distribution_sigmas, plot_all_params, plot_all_losses, plot_all_buckets, plot_cv_in_params, plot_recovery_loss, plot_confidence_interval\n",
    "import yaml\n",
    "from data.dataloader import SimulatedDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_hosp_ratios(param_set, data_config, model_config):\n",
    "    df = pd.read_csv(os.path.join('../../data/data/simulated_data/', data_config['output_file_name']), index_col=0)\n",
    "    if model_config['end_date']:\n",
    "        # print(model_config['end_date'])\n",
    "        if isinstance(model_config['end_date'], int):\n",
    "            if end_date > 0:\n",
    "                raise ValueError('Please enter a negative value for end_date if entering an integer')\n",
    "        if isinstance(model_config['end_date'], datetime.date):\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            end_date = df.loc[df['date'].dt.date == model_config['end_date']].index[0] - len(df) + 1\n",
    "    else:\n",
    "        end_date = 0\n",
    "    train_start_row = df.iloc[len(df) - (model_config['train_period'] + model_config['val_period'] + model_config['test_period']) + end_date]\n",
    "    if data_config['model'] == 'SEIRHD':\n",
    "        param_set['E_hosp_ratio'] = train_start_row['E'] / train_start_row['active']\n",
    "        param_set['I_hosp_ratio'] = train_start_row['I'] / train_start_row['active']\n",
    "    elif data_config['model'] == 'SEIRHD_Beta':\n",
    "        param_set['E_hosp_ratio'] = train_start_row['E'] / train_start_row['active']\n",
    "        param_set['I_hosp_ratio'] = train_start_row['I'] / train_start_row['active']\n",
    "    elif data_config['model'] == 'SEIR_PU':\n",
    "        param_set['E_hosp_ratio'] = train_start_row['E'] / train_start_row['active']\n",
    "        param_set['I_hosp_ratio'] = train_start_row['I'] / train_start_row['active']\n",
    "        param_set['Pu_pop_ratio'] = train_start_row['Pu'] / train_start_row['']\n",
    "    return param_set"
   ]
  },
  {
   "source": [
    "# Create short pickle file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '../../misc/predictions/exp3' \n",
    "file_name = 'exp3_fixed_params_multiple_val.pickle'\n",
    "with open(os.path.join(save_dir, file_name), 'rb') as handle:\n",
    "    input_dict = pkl.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for pred in input_dict['predictions_dicts']:\n",
    "    pd_output = {}\n",
    "    pd_output['prediction_dict'] = {}\n",
    "    pd_output['prediction_dict']['best_params'] = pred['prediction_dict']['best_params']\n",
    "    pd_output['prediction_dict']['df_loss'] = pred['prediction_dict']['df_loss']\n",
    "    pd_output['run_tuple'] = pred['run_tuple']\n",
    "    # pd['trials'] = pd['prediction_dict']['trials']\n",
    "    # del pd['prediction_dict']\n",
    "    output.append(pd_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = {}\n",
    "output_dict['predictions_dicts'] = output\n",
    "output_dict['model_config'] = input_dict['model_config']\n",
    "output_dict['val_periods'] = input_dict['val_periods']\n",
    "output_dict['train_periods'] = input_dict['train_periods']\n",
    "output_dict['end_dates'] = input_dict['end_dates']\n",
    "with open(os.path.join('../../misc/predictions/exp2', \"exp2_trial2_short.pickle\"), 'wb') as handle:\n",
    "    pkl.dump(output_dict, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '../../misc/predictions/exp2' \n",
    "file_name = 'exp2_trial1_short.pickle'\n",
    "with open(os.path.join(save_dir, file_name), 'rb') as handle:\n",
    "    run_dict = pkl.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_periods = run_dict['val_periods']\n",
    "format_str = '%d-%m-%Y' # The format\n",
    "end_date = datetime.datetime.strptime('31-12-2020',format_str).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dict = {val:[] for val in val_periods}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_period = 28\n",
    "for run in run_dict['predictions_dicts'] : \n",
    "    run_tuple = run['run_tuple']\n",
    "    if(run_tuple['train'] != train_period or run_tuple['end_date'] != end_date):\n",
    "        continue\n",
    "    losses = run['prediction_dict']['df_loss']\n",
    "    plot_dict[run_tuple['val']].append(np.mean(losses[which_loss]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for val in val_periods : \n",
    "    plot_dict[val] = np.mean(np.array(plot_dict[val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dict.keys(), plot_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subplots = 1\n",
    "ncols = 2\n",
    "nrows = math.ceil(n_subplots/ncols)\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, \n",
    "                        figsize=(18, 6*nrows))\n",
    "ax_counter = 0\n",
    "which_loss = 'val'\n",
    "loss_dict = plot_dict[which_loss]\n",
    "ax = axs.flat[ax_counter]\n",
    "for end_date, end_date_dict in loss_dict.items():\n",
    "    ax.plot(list(end_date_dict.keys()), list(end_date_dict.values()), label=end_date)\n",
    "ax_counter += 1\n",
    "ax.set_title(which_loss)\n",
    "ax.set_xlabel(\"Val periods\")\n",
    "ax.set_ylabel(\"Average MAPE loss\")\n",
    "ax.legend(title=\"end date\")"
   ]
  },
  {
   "source": [
    "# Plot 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '../../misc/predictions/exp2' \n",
    "file_name = 'exp2_trial2_short.pickle'\n",
    "with open(os.path.join(save_dir, file_name), 'rb') as handle:\n",
    "    run_dict = pkl.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dict['end_dates'], run_dict['val_periods']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_periods = [14, 28, 42, 56, 70, 84, 98, 112]\n",
    "format_str = '%d-%m-%Y' # The format\n",
    "end_date = datetime.datetime.strptime('1-1-2021',format_str).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dict_1 = {val:[] for val in val_periods}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_period = 28\n",
    "for run in run_dict['predictions_dicts'] : \n",
    "    run_tuple = run['run_tuple']\n",
    "    if(run_tuple['train'] != train_period or run_tuple['end_date'] != end_date):\n",
    "        continue\n",
    "    losses = run['prediction_dict']['df_loss']\n",
    "    for val in val_periods:\n",
    "        plot_dict_1[val].append(np.mean(losses[\"val_\" + str(val)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dict_1_std = {}\n",
    "for val in val_periods : \n",
    "    plot_dict_1[val] = np.mean(np.array(plot_dict_1[val]))\n",
    "    plot_dict_1_std[val] = np.mean(np.array(plot_dict_1[val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dict_1.keys(), plot_dict_1.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(plot_dict.keys()), list(plot_dict.values()), label=\"sc1\")\n",
    "plt.plot(list(plot_dict_1.keys()), list(plot_dict_1.values()), label=\"sc2\")\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel(\"Average Val Loss (MAPE %)\")\n",
    "plt.xlabel(\"Val period\")\n",
    "plt.title(\"sc1: None \\n sc2: T_recov_fatal, T_inf, T_inc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}