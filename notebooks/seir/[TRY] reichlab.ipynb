{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import cm\n",
    "\n",
    "import geoplot as gplt\n",
    "import geoplot.crs as gcrs\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "import re\n",
    "from datetime import datetime, date, timedelta\n",
    "from glob import glob\n",
    "\n",
    "from utils.generic.config import read_config, make_date_key_str\n",
    "from utils.generic.reichlab import *\n",
    "from viz.reichlab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "## for Palatino and other serif fonts use:\n",
    "#rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_states_abbv_df = pd.read_csv('../../data/data/us_states_abbv.csv')\n",
    "us_states_abbv_dict = dict(zip(us_states_abbv_df['state'], us_states_abbv_df['state_code']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_run = '2020_1022_014310'\n",
    "aug22 = '2020_1031_203437'\n",
    "aug29 = '2020_1031_211038'\n",
    "sept05 = '2020_1031_181912'\n",
    "sept26 = '2020_1031_100231'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_pkl_filename = '/scratch/users/sansiddh/covid-modelling/2020_1111_162416/predictions_dict.pkl'\n",
    "with open(predictions_pkl_filename, 'rb') as f:\n",
    "    predictions_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_comparison(predictions_dict, us_states_abbv_dict):\n",
    "    try:\n",
    "        config = predictions_dict[list(predictions_dict.keys())[0]]['m2']['run_params']\n",
    "    except:\n",
    "        config_filename = 'us2.yaml'\n",
    "        config = read_config(config_filename)['fitting']\n",
    "\n",
    "    loss_comp = config['loss']['loss_compartments'][0]\n",
    "    data_last_date = config['split']['end_date']\n",
    "    date_of_submission = (data_last_date + timedelta(days=2)).strftime('%Y-%m-%d')\n",
    "    if loss_comp == 'deceased':\n",
    "        comp = 'cum_death'\n",
    "    if loss_comp == 'total':\n",
    "        comp = 'cum_case'\n",
    "    print(comp)\n",
    "    print(date_of_submission)\n",
    "\n",
    "    list_of_models = get_list_of_models(date_of_submission, comp, reichlab_path='../../../covid19-forecast-hub',\n",
    "                                        num_submissions_filter=45)\n",
    "    df_all_submissions = process_all_submissions(list_of_models, date_of_submission, comp, reichlab_path='../../../covid19-forecast-hub')\n",
    "    df_gt, df_gt_loss, df_gt_loss_wk, loc_name_to_key_dict = process_gt(comp, df_all_submissions, reichlab_path='../../../covid19-forecast-hub')\n",
    "\n",
    "    df_wiai_submission = format_wiai_submission(predictions_dict, df_all_submissions, loc_name_to_key_dict,\n",
    "                                                which_fit='m2', use_as_point_forecast='ensemble_mean', skip_percentiles=True)\n",
    "    df_all_submissions = combine_wiai_subm_with_all(df_all_submissions, df_wiai_submission, comp)\n",
    "\n",
    "    df_comb, df_mape, df_rank = compare_gt_pred(df_all_submissions, df_gt_loss_wk)\n",
    "    df_mape.drop(['Guam', 'Virgin Islands', 'Northern Mariana Islands'], axis=1, inplace=True)\n",
    "    df_rank.drop(['Guam', 'Virgin Islands', 'Northern Mariana Islands'], axis=1, inplace=True)\n",
    "        \n",
    "    num_models = len(df_mape.median(axis=1))\n",
    "    print(f'Total # of models - {num_models}')\n",
    "    print(df_mape.loc[:, np.logical_not(df_mape.loc['Wadhwani_AI', :].isna())].median(axis=1).sort_values())\n",
    "    print(df_rank.loc[:, np.logical_not(df_rank.loc['Wadhwani_AI', :].isna())].median(axis=1).sort_values())\n",
    "\n",
    "    df = calculate_z_score(df_mape, df_rank, model_name='Wadhwani_AI')\n",
    "\n",
    "    fig = create_heatmap(df, var_name='z_score', center=0)\n",
    "    fig = create_heatmap(df, var_name='non_param_z_score', center=0)\n",
    "    fig = create_heatmap(df, var_name='model_rank', center=num_models//2)\n",
    "\n",
    "    df_wadhwani = combine_with_train_error(predictions_dict, df)\n",
    "    \n",
    "    print(f'# -ve Z score {len(df_wadhwani[df_wadhwani[\"z_score\"] <= 0])}')\n",
    "    print(f'# +ve Z score {len(df_wadhwani[df_wadhwani[\"z_score\"] > 0])}')\n",
    "    \n",
    "    fig = create_scatter_plot_mape(df_wadhwani, annotate=True, abbv=True, abbv_dict=us_states_abbv_dict, log_scale=True)\n",
    "    fig = create_scatter_plot_mape(df_wadhwani, annotate=True, abbv=True, abbv_dict=us_states_abbv_dict, log_scale=False)\n",
    "\n",
    "    df_bad = df_wadhwani[df_wadhwani['z_score'] > 0]\n",
    "\n",
    "    return date_of_submission, df_mape, df_rank, df_bad, df_wadhwani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_of_submission, df_mape, df_rank, df_bad, df_wadhwani = full_comparison(predictions_dict, us_states_abbv_dict)\n",
    "bad_dict[date_of_submission] = df_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(14, 14), nrows=2, ncols=1)\n",
    "_ = create_geoplot_choropleth(df_wadhwani, var='z_score', vcenter=0, cmap='coolwarm', ax=axs.flat[0])\n",
    "_ = create_geoplot_choropleth(df_wadhwani, var='non_param_z_score', vcenter=0, cmap='coolwarm', ax=axs.flat[1])\n",
    "fig.colorbar(cm.ScalarMappable(norm=colors.TwoSlopeNorm(vmin=-1, vcenter=0, vmax=1), cmap='coolwarm'), ax=axs.flat[0])\n",
    "fig.colorbar(cm.ScalarMappable(norm=colors.TwoSlopeNorm(vmin=-1, vcenter=0, vmax=1), cmap='coolwarm'), ax=axs.flat[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = create_geoplot_choropleth(df_wadhwani, var='non_param_z_score', vcenter=0, cmap='bwr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "ax.scatter(df_wadhwani['z_score'], df_wadhwani['non_param_z_score'])\n",
    "ax.plot(df_wadhwani['z_score'], df_wadhwani['z_score'], '-r', label='y=x line')\n",
    "ax.set_xlabel('Z Score (Mean, Std)')\n",
    "ax.set_ylabel('Non Param Z Score (Median, MAD)')\n",
    "ax.set_title('Non Param Z Score vs Z Score ')\n",
    "ax.grid()\n",
    "# for i, (index, row) in enumerate(df_wadhwani.iterrows()):\n",
    "#     annot_str = us_states_abbv_dict[index]\n",
    "#     ax.annotate(annot_str, (row['z_score'], row['non_param_z_score']))\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = create_geoplot_choropleth(df_wadhwani, var='model_rank', vcenter=13, cmap='bwr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(21, 6*15), nrows=15, ncols=3)\n",
    "columns = df_mape.loc[:, np.logical_not(df_mape.loc['Wadhwani_AI', :].isna())].columns\n",
    "for i, state in enumerate(columns):\n",
    "    ax = axs.flat[i]\n",
    "    sns.ecdfplot(data=df_mape[state], ax=ax)\n",
    "    ax.axvline(df_mape.loc['Wadhwani_AI', state], ls=':', c='red', label='Wadhwani AI Submission')\n",
    "#     ax.axvline(df_mape.loc['UMass-MechBayes', state], ls=':', c='maroon', label='UMass-MechBayes Submission (lowest rank)')\n",
    "    ax.set_title(state)\n",
    "    ax.legend()\n",
    "fig.suptitle('Emperical Cumulative Distribution Function Plots for all states')\n",
    "fig.subplots_adjust(top=0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(21, 6*15), nrows=15, ncols=3)\n",
    "columns = df_mape.loc[:, np.logical_not(df_mape.loc['Wadhwani_AI', :].isna())].columns\n",
    "for i, state in enumerate(columns):\n",
    "    ax = axs.flat[i]\n",
    "#     sm.qqplot(df_mape[state], dist=stats.norm, fit=True, line='45', ax=ax)\n",
    "    sm.qqplot(df_mape[state], dist=stats.norm, loc=df_wadhwani.loc[state, 'mean_mape'], \n",
    "              scale=df_wadhwani.loc[state, 'std_mape'], line='45', ax=ax)\n",
    "    ax.set_title(state)\n",
    "fig.suptitle('Q-Q plots for all states')\n",
    "fig.subplots_adjust(top=0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for col_name, mapes in df_mape.loc[:, df_bad.index].iteritems():\n",
    "    fig, ax = plt.subplots(figsize=(18, 2))\n",
    "    sns.heatmap(mapes.to_numpy().reshape(1, -1), cmap='Reds', ax=ax, xticklabels=mapes.index, annot=True)\n",
    "    ax.set_title(col_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for state in df_bad.index:\n",
    "    print(state)\n",
    "    fig = predictions_dict[state]['m1']['plots']['fit']\n",
    "    show_figure(fig)\n",
    "    fig.show()\n",
    "    fig = predictions_dict[state]['m2']['plots']['fit']\n",
    "    show_figure(fig)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dfs = list(bad_dict.values())\n",
    "np.intersect1d(dfs[0].index, dfs[1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (covid)",
   "language": "python",
   "name": "covid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
