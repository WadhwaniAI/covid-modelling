{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import cm\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import geoplot as gplt\n",
    "import geoplot.crs as gcrs\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from scipy.stats import zscore\n",
    "from shapely.geometry import MultiPolygon\n",
    "from tabulate import tabulate\n",
    "\n",
    "from utils.fitting.loss import Loss_Calculator\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "import re\n",
    "from datetime import datetime, date, timedelta\n",
    "from glob import glob\n",
    "\n",
    "from utils.generic.config import read_config, make_date_key_str\n",
    "from utils.generic.reichlab import *\n",
    "from viz.reichlab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_states_abbv_df = pd.read_csv('../../data/data/us_states_abbv.csv')\n",
    "us_states_abbv_dict = dict(zip(us_states_abbv_df['state'], us_states_abbv_df['state_code']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_pkl_filename = '/scratch/users/sansiddh/covid-modelling/2020_1111_162416/predictions_dict.pkl'\n",
    "with open(predictions_pkl_filename, 'rb') as f:\n",
    "    predictions_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_comparison(predictions_dict, us_states_abbv_dict):\n",
    "    try:\n",
    "        config = predictions_dict[list(predictions_dict.keys())[0]]['m2']['run_params']\n",
    "    except:\n",
    "        config_filename = 'us2.yaml'\n",
    "        config = read_config(config_filename)['fitting']\n",
    "\n",
    "    loss_comp = config['loss']['loss_compartments'][0]\n",
    "    data_last_date = config['split']['end_date']\n",
    "    date_of_submission = (data_last_date + timedelta(days=2)).strftime('%Y-%m-%d')\n",
    "    if loss_comp == 'deceased':\n",
    "        comp = 'cum_death'\n",
    "    if loss_comp == 'total':\n",
    "        comp = 'cum_case'\n",
    "    print(comp)\n",
    "    print(date_of_submission)\n",
    "\n",
    "    list_of_models = get_list_of_models(date_of_submission, comp, reichlab_path='../../../covid19-forecast-hub',\n",
    "                                        num_submissions_filter=45)\n",
    "    df_all_submissions = process_all_submissions(list_of_models, date_of_submission, comp, reichlab_path='../../../covid19-forecast-hub')\n",
    "    df_gt, df_gt_loss, df_gt_loss_wk, loc_name_to_key_dict = process_gt(comp, df_all_submissions, reichlab_path='../../../covid19-forecast-hub')\n",
    "\n",
    "    df_wiai_submission = format_wiai_submission(predictions_dict, df_all_submissions, loc_name_to_key_dict,\n",
    "                                                which_fit='m2', use_as_point_forecast='ensemble_mean', skip_percentiles=False)\n",
    "    df_all_submissions = combine_wiai_subm_with_all(df_all_submissions, df_wiai_submission, comp)\n",
    "\n",
    "    df_comb, df_mape, df_rank = compare_gt_pred(df_all_submissions, df_gt_loss_wk)\n",
    "    df_mape.drop(['Guam', 'Virgin Islands', 'Northern Mariana Islands'], axis=1, inplace=True)\n",
    "    df_rank.drop(['Guam', 'Virgin Islands', 'Northern Mariana Islands'], axis=1, inplace=True)\n",
    "        \n",
    "    num_models = len(df_mape.median(axis=1))\n",
    "    print(f'Total # of models - {num_models}')\n",
    "    median_mape = df_mape.loc[:, np.logical_not(df_mape.loc['Wadhwani_AI', :].isna())].median(axis=1).rename('median_mape')\n",
    "    median_rank = df_rank.loc[:, np.logical_not(df_rank.loc['Wadhwani_AI', :].isna())].median(axis=1).rename('median_rank')\n",
    "    merged = pd.concat([median_mape, median_rank], axis=1)\n",
    "\n",
    "    df = calculate_z_score(df_mape, df_rank, model_name='Wadhwani_AI')\n",
    "\n",
    "    fig = create_heatmap(df, var_name='z_score', center=0)\n",
    "    fig = create_heatmap(df, var_name='non_param_z_score', center=0)\n",
    "\n",
    "    df_wadhwani = combine_with_train_error(predictions_dict, df)\n",
    "    \n",
    "    print(f'# -ve Z score {len(df_wadhwani[df_wadhwani[\"z_score\"] <= 0])}')\n",
    "    print(f'# +ve Z score {len(df_wadhwani[df_wadhwani[\"z_score\"] > 0])}')\n",
    "    \n",
    "    print(f'# -ve non param Z score {len(df_wadhwani[df_wadhwani[\"non_param_z_score\"] <= 0])}')\n",
    "    print(f'# +ve non param Z score {len(df_wadhwani[df_wadhwani[\"non_param_z_score\"] > 0])}')\n",
    "    \n",
    "    fig = create_scatter_plot_mape(df_wadhwani, annotate=True, abbv=True, abbv_dict=us_states_abbv_dict, \n",
    "                                   stat_metric_to_use='z_score', log_scale=True)\n",
    "    fig = create_scatter_plot_mape(df_wadhwani, annotate=True, abbv=True, abbv_dict=us_states_abbv_dict, \n",
    "                                   stat_metric_to_use='non_param_z_score', log_scale=True)\n",
    "\n",
    "    return date_of_submission, df_comb, df_mape, df_rank, df_wadhwani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_of_submission, df_comb, df_mape, df_rank, df_wadhwani = full_comparison(predictions_dict, us_states_abbv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = create_performance_table(df_mape, df_rank)\n",
    "x = datetime.strptime(date_of_submission, '%Y-%m-%d')\n",
    "data_last_date = (x - timedelta(days=2))\n",
    "print('Data last date -  {}'.format(data_last_date.strftime('%Y-%m-%d')))\n",
    "print('Test period till -  {}'.format((data_last_date + timedelta(days=28)).strftime('%Y-%m-%d')))\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_filename = 'us4.yaml'\n",
    "config = read_config(config_filename)\n",
    "\n",
    "wandb_config = read_config(config_filename, preprocess=False)\n",
    "wandb_config = make_date_key_str(wandb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty_args = {'predictions_dict': predictions_dict['Texas'], 'fitting_config': config['fitting'],\n",
    "                    'forecast_config': config['forecast'], 'process_trials': False, **config['uncertainty']['uncertainty_params']}\n",
    "uncertainty = config['uncertainty']['method'](**uncertainty_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty_forecasts = uncertainty.get_forecasts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = Loss_Calculator()\n",
    "df_comb['perc_loss_ape'] = np.nan\n",
    "for i, row in df_comb.iterrows():\n",
    "    if row['type'] == 'quantile':\n",
    "        df_comb.loc[i, 'perc_loss_ape'] = lc._calc_mape_perc(np.array([row['forecast_value']]), np.array([row['true_value']]), row['quantile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_comb[df_comb['quantile'] == 0.05]\n",
    "\n",
    "df_mape = df_temp.groupby(['model', 'location',\n",
    "                           'location_name']).mean().reset_index()\n",
    "    \n",
    "df_mape = df_mape.pivot(index='model', columns='location_name', \n",
    "                        values='ape')\n",
    "\n",
    "df_rank = df_mape.rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_performance_table(df_mape, df_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = preprocess_shape_file(filename='cb_2018_us_state_5m/cb_2018_us_state_5m.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_plot = {\n",
    "    'non_param_z_score' : {'cmap':'RdYlGn_r', 'vmin':-1, 'vcenter':0, 'vmax':1},\n",
    "    'model_rank' : {'cmap':'Purples', 'vmin':0, 'vcenter':13, 'vmax':26},\n",
    "}\n",
    "fig, axs = plot_multiple_choropleths(df_wadhwani, gdf, vars_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_plot = {\n",
    "    'z_score' : {'cmap':'RdYlGn_r', 'vmin':-1, 'vcenter':0, 'vmax':1},\n",
    "    'model_rank' : {'cmap':'Purples', 'vmin':0, 'vcenter':13, 'vmax':26},\n",
    "}\n",
    "fig, axs = plot_multiple_choropleths(df_wadhwani, gdf, vars_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = create_scatter_plot_zscores(df_wadhwani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_ecdf_all_states(df_mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_qq_all_states(df_mape, fit=False, df_wadhwani=df_wadhwani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (covid)",
   "language": "python",
   "name": "covid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
