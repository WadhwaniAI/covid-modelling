{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from hyperopt import hp, tpe, fmin, Trials\n",
    "from tqdm import tqdm\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "from collections import OrderedDict, defaultdict\n",
    "import itertools\n",
    "from functools import partial\n",
    "import datetime\n",
    "from joblib import Parallel, delayed\n",
    "import copy\n",
    "import json\n",
    "\n",
    "import sys; sys.path.append('../../')\n",
    "\n",
    "from data.dataloader import Covid19IndiaLoader\n",
    "from data.processing.processing import get_data, get_district_time_series, get_dataframes_cached\n",
    "\n",
    "from models.seir.seir_testing import SEIR_Testing\n",
    "from main.seir.optimiser import Optimiser\n",
    "from utils.loss import Loss_Calculator\n",
    "from main.seir.fitting import single_fitting_cycle, train_val_split\n",
    "from main.seir.forecast import create_region_csv, create_all_csvs, write_csv, get_forecast\n",
    "from viz.forecast import plot_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of E/Hosp and I/Hosp ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# for district in predictions_dict.keys():\n",
    "#     district_dict = predictions_dict[district]\n",
    "    \n",
    "#     fig, ax = plt.subplots(figsize=(12, 12))\n",
    "#     ax.plot(district_dict['m1']['df_prediction']['date'], district_dict['m1']['df_prediction']['E'] / district_dict['m1']['df_prediction']['hospitalised'],\n",
    "#             '-', color='C0', label='E / Hosp (M1)')\n",
    "#     ax.plot(district_dict['m1']['df_prediction']['date'], district_dict['m1']['df_prediction']['I'] / district_dict['m1']['df_prediction']['hospitalised'],\n",
    "#             '-.', color='C0', label='I / Hosp (M1)')\n",
    "#     ax.xaxis.set_major_locator(mdates.DayLocator(interval=7))\n",
    "#     ax.xaxis.set_minor_locator(mdates.DayLocator(interval=1))\n",
    "#     ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "#     plt.ylabel('No of People')\n",
    "#     plt.xlabel('Time')\n",
    "#     plt.legend()\n",
    "#     plt.title('I/Hosp and E/Hosp ratio for {}, {}'.format(district[0], district[1]))\n",
    "#     plt.grid()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Covid19india Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes = loader.get_covid19india_api_data()\n",
    "dataframes = get_dataframes_cached()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Districts to fit on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# districts_to_show = [('Maharashtra', 'Pune'), \n",
    "#                      ('Maharashtra', 'Mumbai'), \n",
    "#                      ('Rajasthan', 'Jaipur'), \n",
    "#                      ('Gujarat', 'Ahmedabad'), \n",
    "#                      ('Karnataka', 'Bengaluru Urban'),\n",
    "#                      ('Delhi', None)]\n",
    "\n",
    "#districts_to_show = [('Maharashtra', 'Pune')]\n",
    "districts_to_show = [('Maharashtra', 'Mumbai')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform M1 and M2 fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# for state, district in districts_to_show:\n",
    "#    predictions_dict[(state, district)] = {}\n",
    "#    predictions_dict[(state, district)]['m1'] = single_fitting_cycle(\n",
    "#        dataframes, state, district, train_period=7, val_period=7, \n",
    "#        data_from_tracker=True, initialisation='intermediate',\n",
    "#        which_compartments=['hospitalised', 'total_infected', 'deceased', 'recovered'])\n",
    "#    predictions_dict[(state, district)]['m2'] = single_fitting_cycle(\n",
    "#        dataframes, state, district, train_period=7, val_period=0, \n",
    "#        data_from_tracker=True, initialisation='intermediate',\n",
    "#        which_compartments=['hospitalised', 'total_infected', 'deceased', 'recovered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"dark\")\n",
    "for state, district in districts_to_show:\n",
    "    predictions_dict[(state, district)] = {}\n",
    "    predictions_dict[(state, district)]['m1'] = single_fitting_cycle(\n",
    "        dataframes, state, district, train_period=7, val_period=7, \n",
    "        data_from_tracker=False,\n",
    "        # filename='../../data/data/official-pune-21-05-20.csv', data_format='new',\n",
    "        # filename='../../data/data/official-mumbai-27-05-20.csv', data_format='old',\n",
    "        initialisation='intermediate',\n",
    "        which_compartments=['hospitalised', 'total_infected', 'deceased', 'recovered'],\n",
    "        smooth_jump = True,\n",
    "    )\n",
    "    predictions_dict[(state, district)]['m2'] = single_fitting_cycle(\n",
    "        dataframes, state, district, train_period=7, val_period=0, \n",
    "        data_from_tracker=False, \n",
    "        # filename='../../data/data/official-pune-25-05-20.csv', data_format='new',\n",
    "        # filename='../../data/data/official-mumbai-27-05-20.csv', data_format='old',\n",
    "        initialisation='intermediate',\n",
    "        which_compartments=['hospitalised', 'total_infected', 'deceased', 'recovered'],\n",
    "        smooth_jump = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Master Loss Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M1 Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict[('Maharashtra','Mumbai')]['m1'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_key = list(predictions_dict.keys())[0]\n",
    "\n",
    "loss_columns = pd.MultiIndex.from_product([predictions_dict[starting_key]['m1']['df_loss'].columns, predictions_dict[starting_key]['m1']['df_loss'].index])\n",
    "loss_index = predictions_dict.keys()\n",
    "\n",
    "df_loss_master = pd.DataFrame(columns=loss_columns, index=loss_index)\n",
    "for key in districts_to_show:\n",
    "    df_loss_master.loc[key, :] = np.around(predictions_dict[key]['m1']['df_loss'].values.T.flatten().astype('float'), decimals=2)\n",
    "    \n",
    "df_loss_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M2 Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions_dict[('Maharashtra','Pune')]['m2']\n",
    "predictions_dict[('Maharashtra','Mumbai')]['m2'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_key = list(predictions_dict.keys())[0]\n",
    "\n",
    "loss_columns = pd.MultiIndex.from_product([predictions_dict[starting_key]['m2']['df_loss'].columns, predictions_dict[starting_key]['m2']['df_loss'].index])\n",
    "loss_index = predictions_dict.keys()\n",
    "\n",
    "df_loss_master = pd.DataFrame(columns=loss_columns, index=loss_index)\n",
    "for key in predictions_dict.keys():\n",
    "    df_loss_master.loc[key, :] = np.around(predictions_dict[key]['m2']['df_loss'].values.T.flatten().astype('float'), decimals=2)\n",
    "    \n",
    "df_loss_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in predictions_dict.keys():\n",
    "    plot_forecast(predictions_dict[region], region, both_forecasts=False, error_bars=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Save Output CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = create_all_csvs(predictions_dict, icu_fraction=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(df_output, '../../output-mumbai-{}.csv'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_array = np.array([trial['result']['loss'] for trial in predictions_dict[(state, district)]['m1']['trials']])\n",
    "#losses_array = np.array([trial['result']['loss'] for trial in predictions_dict[(state, district)]['m2']['trials']])\n",
    "least_losses_indices = np.argsort(losses_array)\n",
    "losses_array[least_losses_indices][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_array = []\n",
    "for trial in predictions_dict[(state, district)]['m1']['trials']:\n",
    "#for trial in predictions_dict[(state, district)]['m2']['trials']:\n",
    "    params_dict = copy.copy(trial['misc']['vals'])\n",
    "    for key in params_dict.keys():\n",
    "        params_dict[key] = params_dict[key][0]\n",
    "    params_array.append(params_dict)\n",
    "\n",
    "params_array = np.array(params_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_losses_indices[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_array[least_losses_indices[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions_array = [get_forecast(predictions_dict[('Maharashtra', 'Pune')],\n",
    "#                                  best_params=params_dict) for params_dict in params_array[least_losses_indices[:10]]]\n",
    "predictions_array = [get_forecast(predictions_dict[('Maharashtra', 'Mumbai')],\n",
    "                                  best_params=params_dict) for params_dict in params_array[least_losses_indices[:10]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true = predictions_dict[('Maharashtra', 'Mumbai')]['m1']['df_district']\n",
    "#df_true = predictions_dict[('Maharashtra', 'Mumbai')]['m2']['df_district']\n",
    "\n",
    "#sns.set_style(\"ticks\")\n",
    "#sns.set_style(\"whitegrid\")\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "ax.plot(df_true['date'], df_true['total_infected'],\n",
    "        '-o', color='C0', label='Confirmed Cases (Observed)')\n",
    "for i, df_prediction in enumerate(predictions_array):\n",
    "    loss_value = np.around(np.sort(losses_array)[:10][i], 2)\n",
    "    sns.lineplot(x=\"date\", y=\"total_infected\", data=df_prediction,\n",
    "                 ls='-', label='Confirmed Cases ({})'.format(loss_value))\n",
    "    plt.text(x=df_prediction['date'].iloc[-1], y=df_prediction['total_infected'].iloc[-1], s=loss_value)\n",
    "    \n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(interval=7))\n",
    "ax.xaxis.set_minor_locator(mdates.DayLocator(interval=1))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.ylabel('No of People', fontsize=16)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Time', fontsize=16)\n",
    "plt.legend()\n",
    "plt.title('Forecast - ({} {})'.format(region[0], region[1]), fontsize=16)\n",
    "#plt.grid()\n",
    "plt.show()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true = predictions_dict[('Maharashtra', 'Mumbai')]['m1']['df_district']\n",
    "#df_true = predictions_dict[('Maharashtra', 'Mumbai')]['m2']['df_district']\n",
    "sns.set_style(\"darkgrid\")\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "ax.plot(df_true['date'], df_true['hospitalised'],\n",
    "        '-o', color='orange', label='Active Cases (Observed)')\n",
    "for i, df_prediction in enumerate(predictions_array):\n",
    "    loss_value = np.around(np.sort(losses_array)[:10][i], 2)\n",
    "    params_dict = params_array[least_losses_indices[:10]]\n",
    "    true_r0 = params_dict[i]['lockdown_R0'] #np.around(params_dict[i]['lockdown_R0']*params_dict[i]['intervention_amount'], 2)\n",
    "    #if true_r0 > 1.7:\n",
    "    #    continue\n",
    "    #if true_r0 == 0.59 or true_r0 == 1.04:\n",
    "    #    continue\n",
    "    sns.lineplot(x=\"date\", y=\"hospitalised\", data=df_prediction,\n",
    "                 ls='-', label='Active Cases ({})'.format(loss_value))\n",
    "    plt.text(x=df_prediction['date'].iloc[-1], y=df_prediction['hospitalised'].iloc[-1], s=true_r0)\n",
    "    \n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(interval=7))\n",
    "ax.xaxis.set_minor_locator(mdates.DayLocator(interval=1))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.ylabel('No of People', fontsize=16)\n",
    "# plt.yscale('log')\n",
    "plt.xlabel('Time', fontsize=16)\n",
    "plt.xticks(rotation=45,horizontalalignment='right')\n",
    "plt.legend()\n",
    "plt.title('Forecast - ({} {})'.format(region[0], region[1]), fontsize=16)\n",
    "#plt.grid()\n",
    "plt.show()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check varying R0 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_plot = \\\n",
    "{\n",
    "    'low':{'E_hosp_ratio': 0.115406221316017, 'I_hosp_ratio': 0.4763871081949848, 'P_fatal': 0.050419345187462467, 'P_severe': 0.7809853621826006, 'T_inc': 4.484977212179257, 'T_inf': 3.3342249004558697, 'T_recov_severe': 52.054485355979445, 'lockdown_R0': 1.0974118812671074},\n",
    "    'medium':{'E_hosp_ratio': 0.5105188613649609, 'I_hosp_ratio': 0.3039459885534656, 'P_fatal': 0.05832975188719784, 'P_severe': 0.8668707539589996, 'T_inc': 4.554494614633725, 'T_inf': 3.3958101193846915, 'T_recov_severe': 48.49542471232895, 'lockdown_R0': 1.1227557408135034},\n",
    "    'high':   {'E_hosp_ratio': 0.2806960144261442, 'I_hosp_ratio': 0.3800638057872212, 'P_fatal': 0.05326820833691313, 'P_severe': 0.8339542948758695, 'T_inc': 4.304052648857938, 'T_inf': 3.4673218430188513, 'T_recov_severe': 47.044942872805294, 'lockdown_R0': 1.3444274930627533}\n",
    "}\n",
    "multipliers = [0.9, 1, 1.1, 1.25]\n",
    "columns_for_csv = ['date', 'total_infected', 'hospitalised', 'recovered', 'deceased']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_r0_multiplier(params_dict, mul):\n",
    "    new_params = params_dict.copy()\n",
    "    new_params['post_lockdown_R0']= params_dict['lockdown_R0']*mul\n",
    "    return new_params\n",
    "\n",
    "\n",
    "#predictions_array_mul = [get_forecast(predictions_dict[('Maharashtra', 'Mumbai')],\n",
    "#                                  best_params=set_r0_multiplier(best_params_dict, mul)) \\\n",
    "#                                 for mul in multipliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = Loss_Calculator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_district = predictions_dict[districts_to_show[0]]['m2']['df_district']\n",
    "df_train_nora, df_val_nora, df_true_fitting = train_val_split(\n",
    "                df_district, train_rollingmean=False, val_rollingmean=False, val_size=0)\n",
    "\n",
    "for key in params_to_plot:\n",
    "    print(\"R0\", params_to_plot[key]['lockdown_R0'])\n",
    "    best_params_dict = params_to_plot[key]#predictions_dict[districts_to_show[0]]['m2']['best_params']\n",
    "    df_predictions = get_forecast(predictions_dict[('Maharashtra', 'Mumbai')],\n",
    "                                train_fit = \"m2\",\n",
    "                                best_params = best_params_dict)\n",
    "    df_loss = lc.create_loss_dataframe_region(df_train_nora, df_val_nora, df_predictions, train_period=7,\n",
    "                             which_compartments=['hospitalised', 'total_infected', 'deceased', 'recovered'])\n",
    "    print(df_loss)\n",
    "    #print(df_loss.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true = predictions_dict[('Maharashtra', 'Mumbai')]['m2']['df_district']\n",
    "params_array[least_losses_indices[:10]]\n",
    "for key in params_to_plot:\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    ax.plot(df_true['date'], df_true['hospitalised'],\n",
    "        '-o', color='orange', label='Active Cases (Observed)')\n",
    "    best_params_dict = params_to_plot[key]#predictions_dict[districts_to_show[0]]['m2']['best_params']\n",
    "    predictions_array_mul = [get_forecast(predictions_dict[('Maharashtra', 'Mumbai')],\n",
    "                                train_fit = \"m2\",\n",
    "                                best_params=set_r0_multiplier(best_params_dict, mul))\n",
    "                                 for mul in multipliers]\n",
    "    for i, df_prediction in enumerate(predictions_array_mul):\n",
    "        filename = \"Mumbai-\" + key + \"-\" + str(multipliers[i]) + \".csv\"\n",
    "        print(filename)\n",
    "        today = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "        path = f'../../outputs/Mumbai-{today}/'\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "        df_prediction[columns_for_csv].to_csv(os.path.join(path, filename))\n",
    "        #loss_value = np.around(np.sort(losses_array)[:10][i], 2)\n",
    "        label = multipliers[i]\n",
    "        true_r0 = label*best_params_dict['lockdown_R0'] #np.around(params_dict[i]['lockdown_R0']*params_dict[i]['intervention_amount'], 2)\n",
    "        #if true_r0 > 1.7:\n",
    "        #    continue\n",
    "        #if true_r0 == 0.59 or true_r0 == 1.04:\n",
    "        #    continue\n",
    "        sns.lineplot(x=\"date\", y=\"hospitalised\", data=df_prediction,\n",
    "                     ls='-', label='Active Cases ({})'.format(label))\n",
    "        plt.text(x=df_prediction['date'].iloc[-1], y=df_prediction['hospitalised'].iloc[-1], s=true_r0)\n",
    "\n",
    "    ax.xaxis.set_major_locator(mdates.DayLocator(interval=7))\n",
    "    ax.xaxis.set_minor_locator(mdates.DayLocator(interval=1))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    plt.ylabel('No of People', fontsize=16)\n",
    "    # plt.yscale('log')\n",
    "    plt.xticks(rotation=45,horizontalalignment='right')\n",
    "\n",
    "    plt.xlabel('Time', fontsize=16)\n",
    "    plt.legend()\n",
    "    plt.title('Forecast - ({} {})'.format(region[0], region[1]), fontsize=16)\n",
    "    #plt.grid()\n",
    "    plt.show()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for elt in params_array[least_losses_indices[:10]]:\n",
    "    print(\"R0\", elt['lockdown_R0'])\n",
    "    #best_params_dict = params_to_plot[key]#predictions_dict[districts_to_show[0]]['m2']['best_params']\n",
    "    df_predictions = get_forecast(\n",
    "        predictions_dict[('Maharashtra', 'Mumbai')],\n",
    "        train_fit = \"m1\",\n",
    "        best_params = elt)\n",
    "    df_loss =  lc.create_loss_dataframe_region(\n",
    "        df_train_nora, df_val_nora, df_predictions, train_period=7,\n",
    "        which_compartments=['hospitalised', 'total_infected', 'deceased', 'recovered'])\n",
    "    print(df_loss.iloc[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['forecastRunDate', 'regionType', 'region', 'model_name', 'error_function', 'error_value', 'current_total', 'current_active', 'current_recovered',\n",
    "           'current_deceased', 'current_hospitalized', 'current_icu', 'current_ventilator', 'predictionDate', 'active_mean', 'active_min',\n",
    "           'active_max', 'hospitalized_mean', 'hospitalized_min', 'hospitalized_max', 'icu_mean', 'icu_min', 'icu_max', 'deceased_mean',\n",
    "           'deceased_min', 'deceased_max', 'recovered_mean', 'recovered_min', 'recovered_max', 'total_mean', 'total_min', 'total_max']\n",
    "\n",
    "region = ('Maharashtra', 'Mumbai')\n",
    "\n",
    "df_final = pd.DataFrame(columns=columns)\n",
    "for params_dict in params_array[least_losses_indices[:10]]:\n",
    "    df_output = create_region_csv(predictions_dict[region], region=region[1],\n",
    "    regionType='district', best_params=params_dict,\n",
    "    icu_fraction=0.02)\n",
    "    df_final = pd.concat([df_final, df_output], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('../../outputs/mumbai-{}.csv'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, params_dict in enumerate(params_array[least_losses_indices[:10]]):\n",
    "    print('Loss - ', np.around(losses_array[least_losses_indices[:10][index]], 2))\n",
    "    params_dict_temp = copy.copy(params_dict)\n",
    "    params_dict_temp['true_R0'] = params_dict_temp['lockdown_R0']#*params_dict_temp['intervention_amount']\n",
    "    #del params_dict_temp['intervention_amount']\n",
    "    del params_dict_temp['lockdown_R0']\n",
    "    for key in params_dict_temp.keys():\n",
    "        params_dict_temp[key] = np.around(params_dict_temp[key], 2)\n",
    "    print('Params - ', params_dict_temp)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find beta and mean params for uncertainty estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO\n",
    "1. Check with Excel file (potentially different value of N) -> they use N = 1000. chekc that data is same too.\n",
    "2. Check between 0 and 0.2\n",
    "3. N = 2000\n",
    "4. Mean forecast matching\n",
    "5. Compare your code with excel (their best beta was 0.9)\n",
    "6. \n",
    "\n",
    "-------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compartment_list = ['hospitalised', 'total_infected', 'deceased', 'recovered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_array_m1 = []\n",
    "for trial in predictions_dict[(state, district)]['m1']['trials']:\n",
    "    params_dict = copy.copy(trial['misc']['vals'])\n",
    "    for key in params_dict.keys():\n",
    "        params_dict[key] = params_dict[key][0]\n",
    "    params_array_m1.append(params_dict)\n",
    "\n",
    "params_array_m1= np.array(params_array_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_array_m1 = np.array([trial['result']['loss'] for trial in predictions_dict[(state, district)]['m1']['trials']])\n",
    "least_losses_indices_m1 = np.argsort(losses_array_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples=range(10,2000,10)\n",
    "betas= np.arange(0, 1,0.025)\n",
    "\n",
    "params_fulldict_m1 = params_array_m1[least_losses_indices_m1]\n",
    "params_list = list(params_array_m1[0].keys())\n",
    "means_m1 = {}\n",
    "std_devs_m1 = {}\n",
    "sums_m1 = {}\n",
    "sqsums_m1 = {}\n",
    "\n",
    "for i, beta in enumerate(betas):\n",
    "    print(beta)\n",
    "    means_m1[i] = {}\n",
    "    std_devs_m1[i] = {}\n",
    "    for key in params_list:\n",
    "        means_m1[i][key] = []\n",
    "        std_devs_m1[i][key] = []\n",
    "    for nums in num_samples:\n",
    "        Loss_norm_m1=0\n",
    "        for key in params_list:\n",
    "            sums_m1[key] = 0\n",
    "            sqsums_m1[key] = 0\n",
    "        tempdict_m1 = params_fulldict_m1[0:nums]\n",
    "        templosses_m1 = losses_array_m1[least_losses_indices_m1[0:nums]]\n",
    "        for k in range(len(tempdict_m1)):\n",
    "            Loss_norm_m1 += np.exp(-beta*templosses_m1[k])\n",
    "            for key in params_list:\n",
    "                sums_m1[key] += np.exp(-beta*templosses_m1[k])*tempdict_m1[k][key]\n",
    "                sqsums_m1[key] += np.exp(-beta*templosses_m1[k])*tempdict_m1[k][key]**2\n",
    "        for key in params_list:\n",
    "            means_m1[i][key].append(sums_m1[key]/Loss_norm_m1)\n",
    "            std_devs_m1[i][key].append(np.sqrt(sqsums_m1[key]/Loss_norm_m1-(sums_m1[key]/Loss_norm_m1)**2))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_m1[0]['E_hosp_ratio'][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(params_list),2)\n",
    "plt.rcParams['figure.dpi']=200\n",
    "plt.rcParams['figure.figsize']=[30, 50]\n",
    "plt.rcParams.update({'font.size':20})\n",
    "colors =['blue','brown', 'black','green','orange','red']\n",
    "for row, key in enumerate(params_list):\n",
    "    for idx, betaind in enumerate([0,1,2,5,10,30]):    \n",
    "        axs[row,0].plot(num_samples, means_m1[betaind][key] , color = colors[idx],label=r'\\beta=${:.1f}'.format(betas[betaind]))\n",
    "        axs[row,0].set_title('{}'.format(key))\n",
    "        axs[row,0].set(ylabel= \"Estimated Mean\")\n",
    "        axs[row,1].plot(num_samples,std_devs_m1[betaind][key], color = colors[idx],label=r'$\\beta=${:.1f}'.format(betas[betaind]))\n",
    "        axs[row,1].set_title('{}'.format(key))\n",
    "        axs[row,1].set(ylabel=\"Estimated Std. Devn.\")\n",
    "        if (row==0):\n",
    "            axs[row,0].legend(loc='center right')\n",
    "        if (row==3):\n",
    "            axs[row,0].set(xlabel=\"Number of top Hyperopt samples\")\n",
    "            axs[row,1].set(xlabel=\"Number of top Hyperopt samples\")\n",
    "\n",
    "fig.tight_layout(pad = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define N from plots!\n",
    "N = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(means_m1[i][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On val set, instead of taking mean param, take mean forecast. For each param set, compute forecast on the val set\n",
    "#and then weight each trjectory by e^(-loss), use to pick beta\n",
    "# Function(betas, params-len 1500), computes mean forecast on given time range. \n",
    "# Get_losses function for this mean forecast\n",
    "\n",
    "def get_loss_mean_param(i):\n",
    "    skip_length = 10\n",
    "    mean_params = {key:means_m1[i][key][N // skip_length] for key in params_list} \n",
    "    df_train = predictions_dict[districts_to_show[0]]['m1']['df_train']\n",
    "    df_val = predictions_dict[districts_to_show[0]]['m1']['df_val']\n",
    "    df_predictions= get_forecast(predictions_dict[districts_to_show[0]],\n",
    "                                train_fit='m1',\n",
    "                                best_params=mean_params)\n",
    "    df_loss =  lc.create_loss_dataframe_region(df_train, df_val, df_predictions, train_period=7,\n",
    "                                 which_compartments= compartment_list )\n",
    "    return df_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_mean_forecast(i, train_fit = 'm1'):\n",
    "    beta = betas[i]\n",
    "    if train_fit == 'm1':\n",
    "        tempdict= params_fulldict_m1[0:N]\n",
    "        templosses = losses_array_m1[least_losses_indices_m1[0:N]]\n",
    "    else:\n",
    "        tempdict= params_fulldict_m2[0:N]\n",
    "        templosses = losses_array_m2[least_losses_indices_m2[0:N]]\n",
    "    Loss_norm = 0\n",
    "    df_predictions = pd.DataFrame()\n",
    "    for k in range(len(tempdict)):\n",
    "        weight_trial = np.exp(-beta*templosses[k])\n",
    "        param_trial = tempdict[k]\n",
    "        df_predictions_trial= get_forecast(predictions_dict[districts_to_show[0]],\n",
    "                                    train_fit= train_fit,\n",
    "                                    best_params=param_trial)#* weight_trial\n",
    "        Loss_norm += weight_trial\n",
    "        if (df_predictions.empty):\n",
    "            df_predictions = df_predictions_trial[compartment_list]*weight_trial\n",
    "        else:\n",
    "            df_predictions += df_predictions_trial[compartment_list]*weight_trial\n",
    "    df_predictions = df_predictions/Loss_norm\n",
    "    df_predictions['date'] = df_predictions_trial.date\n",
    "    return df_predictions\n",
    "\n",
    "def get_loss_mean_forecast(i):\n",
    "    print(\"FORECAST MEAN FOR \",i)\n",
    "    print(\"*\"*20)\n",
    "    df_train = predictions_dict[districts_to_show[0]]['m1']['df_train']\n",
    "    df_val = predictions_dict[districts_to_show[0]]['m1']['df_val']\n",
    "    df_predictions =  get_mean_forecast(i)\n",
    "    df_loss =  lc.create_loss_dataframe_region(df_train, df_val, df_predictions, train_period=7,\n",
    "                                 which_compartments= compartment_list )\n",
    "    return df_loss\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [get_loss_mean_param(i) for i in range(len(betas))]\n",
    "val_losses = [loss['val'].sum() for loss in losses]\n",
    "min_loss_ind = np.argmin(val_losses)\n",
    "beta_min = betas[min_loss_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(beta_min )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_forecast = [get_loss_mean_forecast(i) for i in range(len(betas))]\n",
    "val_losses_forecast = [loss['val'].sum() for loss in losses_forecast]\n",
    "min_loss_ind_forecast = np.argmin(val_losses_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_losses_forecast "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate uncertainty estimates using M2 fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_array_m2 = []\n",
    "for trial in predictions_dict[(state, district)]['m2']['trials']:\n",
    "#for trial in predictions_dict[(state, district)]['m2']['trials']:\n",
    "    params_dict = copy.copy(trial['misc']['vals'])\n",
    "    for key in params_dict.keys():\n",
    "        params_dict[key] = params_dict[key][0]\n",
    "    params_array_m2.append(params_dict)\n",
    "\n",
    "params_array_m2= np.array(params_array_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_array_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute weighted estimates for m2 (only for a single point)\n",
    "\n",
    "losses_array_m2 = np.array([trial['result']['loss'] for trial in predictions_dict[(state, district)]['m2']['trials']])\n",
    "least_losses_indices_m2 = np.argsort(losses_array_m2)\n",
    "\n",
    "nums= N\n",
    "params_fulldict_m2 = params_array_m2[least_losses_indices_m2]\n",
    "mean_m2 = {}\n",
    "std_devs_m2 = {}\n",
    "sums_m2 = {}\n",
    "sqsums_m2 = {}\n",
    "\n",
    "for key in params_list:\n",
    "    sums_m2[key] = 0\n",
    "    sqsums_m2[key] = 0\n",
    "Loss_norm_m2 = 0\n",
    "tempdict_m2 = params_fulldict_m2[0:nums]\n",
    "templosses_m2 = losses_array_m2[least_losses_indices_m2[0:nums]]\n",
    "for k in range(len(tempdict_m2)):\n",
    "    Loss_norm_m2 += np.exp(-beta_min*templosses_m2[k])\n",
    "    for key in params_list:\n",
    "        sums_m2[key] += np.exp(-beta_min*templosses_m2[k])*tempdict_m2[k][key]\n",
    "        sqsums_m2[key] += np.exp(-beta_min*templosses_m2[k])*tempdict_m2[k][key]**2\n",
    "for key in params_list:\n",
    "    mean_m2[key] = sums_m2[key]/Loss_norm_m2\n",
    "    std_devs_m2[key] = np.sqrt(sqsums_m2[key]/Loss_norm_m2-(sums_m2[key]/Loss_norm_m2)**2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_m2 = params_fulldict_m2[:N]\n",
    "best_params_total_loss_m2 = sum(np.exp(-beta_min * losses_array[least_losses_indices[:N]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_m2():    \n",
    "    df_train = predictions_dict[districts_to_show[0]]['m2']['df_train']\n",
    "    df_val = predictions_dict[districts_to_show[0]]['m2']['df_val']\n",
    "    df_predictions= get_forecast(predictions_dict[districts_to_show[0]],\n",
    "                                train_fit='m2',\n",
    "                                best_params=mean_m2)\n",
    "    return df_predictions\n",
    "\n",
    "def get_loss_m2(params):\n",
    "    N = 1500\n",
    "    skip_length = 10\n",
    "    df_train = predictions_dict[districts_to_show[0]]['m2']['df_train']\n",
    "    df_val = predictions_dict[districts_to_show[0]]['m2']['df_val']\n",
    "    df_predictions= get_forecast(predictions_dict[districts_to_show[0]],\n",
    "                                train_fit='m2',\n",
    "                                best_params=params)\n",
    "    df_loss =  lc.create_loss_dataframe_region(df_train, df_val, df_predictions, train_period=7,\n",
    "                                 which_compartments=['hospitalised', 'total_infected', 'deceased', 'recovered'])\n",
    "    return df_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m2_losses = [get_loss_m2(params)['train'] for params in best_params_m2]\n",
    "m2_losses = losses_array_m2[least_losses_indices_m2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_forecasts = pd.DataFrame()\n",
    "for params in best_params_m2:\n",
    "    all_forecasts = pd.concat([all_forecasts , get_forecast(predictions_dict[('Maharashtra', 'Mumbai')],\n",
    "                                                train_fit='m2',\n",
    "                                                best_params=params)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should also pick the interbval (95% etc)\n",
    "# Also give it functionality to pick a percentile\n",
    "# also include a median prediction -> if 2 \n",
    "\n",
    "    \n",
    "def gen_CI(day = 1, compartment = 'hospitalised', CI = 0.95, beta = beta_min, percentile = -1):\n",
    "    daily_forecasts = all_forecasts[compartment].iloc[day,:]\n",
    "    sorted_daily_forecasts_indices = np.argsort(daily_forecasts)\n",
    "    sorted_daily_forecasts = np.sort(daily_forecasts)\n",
    "    sorted_losses_array = m2_losses[:N][sorted_daily_forecasts_indices]\n",
    "    \n",
    "    best_params_total_loss_m2 = sum(np.exp(-beta * sorted_losses_array))\n",
    "    \n",
    "    if (percentile >= 0):\n",
    "        bound = 0 \n",
    "        score = 0 \n",
    "        threshold = percentile * best_params_total_loss_m2\n",
    "        while score < threshold:\n",
    "            score += np.exp(- beta*sorted_losses_array[bound])\n",
    "            bound += 1\n",
    "        forecast = sorted_daily_forecasts[bound]   \n",
    "        return all_forecasts['date'].iloc[day,0], forecast\n",
    "    else:\n",
    "        threshold_factor = (1 - CI)/ 2\n",
    "        threshold = threshold_factor * best_params_total_loss_m2\n",
    "        upperbound = N-1\n",
    "        lowerbound = 0 \n",
    "        upperscore, lowerscore = 0, 0\n",
    "        while upperscore < threshold:\n",
    "            upperscore += np.exp(- beta*sorted_losses_array[upperbound])\n",
    "            upperbound -= 1\n",
    "        while lowerscore < threshold:\n",
    "            lowerscore += np.exp(- beta*sorted_losses_array[lowerbound])\n",
    "            lowerbound += 1\n",
    "        lower_forecast = sorted_daily_forecasts[lowerbound]\n",
    "        upper_forecast = sorted_daily_forecasts[upperbound]\n",
    "        return all_forecasts['date'].iloc[day,0], lower_forecast, upper_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions_mf = get_mean_forecast(min_loss_ind_forecast, 'm2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions_mf[['date','hospitalised']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_true = predictions_dict[('Maharashtra', 'Mumbai')]['m1']['df_district']\n",
    "\n",
    "df_true = predictions_dict[('Maharashtra', 'Mumbai')]['m2']['df_district']\n",
    "df_predictions = get_preds_m2()\n",
    "sns.set()\n",
    "#sns.set_style(\"darkgrid\")\n",
    "colors = ['orange', 'blue', 'red', 'green']\n",
    "ci_cols = {}\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "plt.rcParams['figure.dpi']=200\n",
    "plt.rcParams['figure.figsize']=[30, 50]\n",
    "plt.rcParams.update({'font.size':20})\n",
    "for idx, compartment in enumerate(['hospitalised', 'total_infected', 'deceased', 'recovered']):\n",
    "    ax.plot(df_true['date'], df_true[compartment],\n",
    "            '-o', color= colors[idx], label= compartment)\n",
    "    ci_cols[idx] = pd.DataFrame([gen_CI(day = i, compartment = compartment, CI = 0.95) for i in range(len(all_forecasts))])\n",
    "    ci_cols[idx].columns = ['date', 'lower', 'upper']\n",
    "    full_data = pd.concat([ci_cols[idx][['date','upper']].rename(columns={'upper':compartment}),\n",
    "                           ci_cols[idx][['date', 'lower']].rename(columns={'lower':compartment}),\n",
    "                           df_predictions[['date',compartment]]], axis = 0)\n",
    "    \n",
    "    sns.lineplot(data = full_data, y =  compartment,  x ='date' , \n",
    "                 ls='-', color = colors[idx], label= compartment+\" prediction (mean param)\" )\n",
    "    ax.plot(df_predictions_mf['date'],  df_predictions_mf[compartment], '--',\n",
    "                  color = colors[idx], label= compartment+\" prediction (mean forecast)\" )\n",
    "    \n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(interval=7))\n",
    "ax.xaxis.set_minor_locator(mdates.DayLocator(interval=1))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.ylabel('No of People', fontsize=16)\n",
    "# plt.yscale('log')\n",
    "plt.xlabel('Time', fontsize=16)\n",
    "plt.xticks(rotation=45,horizontalalignment='right')\n",
    "plt.legend()\n",
    "plt.title('Forecast - ({} {})'.format(region[0], region[1]), fontsize=16)\n",
    "#plt.grid()\n",
    "plt.show()   \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_true = predictions_dict[('Maharashtra', 'Mumbai')]['m1']['df_district']\n",
    "\n",
    "df_true = predictions_dict[('Maharashtra', 'Mumbai')]['m2']['df_district']\n",
    "df_predictions = get_preds_m2()\n",
    "sns.set()\n",
    "#sns.set_style(\"darkgrid\")\n",
    "colors = ['orange', 'blue', 'red', 'green']\n",
    "ci_cols = {}\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "plt.rcParams['figure.dpi']=200\n",
    "plt.rcParams['figure.figsize']=[30, 50]\n",
    "plt.rcParams.update({'font.size':20})\n",
    "ax.plot(df_true['date'], df_true['hospitalised'],\n",
    "            '-o', color= 'orange', label= 'hospitalised')\n",
    "percentile_list = [0.025, 0.05, 0.1, 0.2, 0.5, 0.7, 0.8, 0.9, 0.95]\n",
    "for idx, percentile in enumerate(percentile_list):\n",
    "    ci_cols[idx] = pd.DataFrame([gen_CI(i, 'hospitalised', percentile= percentile) for i in range(len(all_forecasts))])\n",
    "    ci_cols[idx].columns = ['date', 'forecast']\n",
    "    sns.lineplot(data = ci_cols[idx], y =  'forecast',  x ='date' , \n",
    "                  label= percentile )\n",
    "   \n",
    "    \n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(interval=7))\n",
    "ax.xaxis.set_minor_locator(mdates.DayLocator(interval=1))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.ylabel('No of People', fontsize=16)\n",
    "# plt.yscale('log')\n",
    "plt.xlabel('Time', fontsize=16)\n",
    "plt.xticks(rotation=45,horizontalalignment='right')\n",
    "plt.legend()\n",
    "plt.title('Forecast - ({} {})'.format(region[0], region[1]), fontsize=16)\n",
    "#plt.grid()\n",
    "plt.show()   \n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
