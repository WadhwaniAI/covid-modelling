{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "import datetime\n",
    "import copy\n",
    "import time\n",
    "import wandb\n",
    "import pickle as pkl\n",
    "import sys\n",
    "import math\n",
    "sys.path.append('../../')\n",
    "from data.processing import get_data\n",
    "import models\n",
    "from main.seir.fitting import single_fitting_cycle\n",
    "from main.seir.forecast import get_forecast, forecast_all_trials, create_all_trials_csv, create_decile_csv_new\n",
    "from main.seir.sensitivity import calculate_sensitivity_and_plot\n",
    "from utils.generic.create_report import save_dict_and_create_report\n",
    "from utils.generic.config import read_config\n",
    "from utils.generic.enums import Columns\n",
    "from utils.fitting.loss import Loss_Calculator\n",
    "from utils.generic.logging import log_wandb\n",
    "from viz import plot_forecast, plot_top_k_trials, plot_ptiles\n",
    "from viz.fit import plot_histogram, plot_all_histograms, plot_mean_variance, plot_scatter, plot_kl_divergence, plot_heatmap_distribution_sigmas, plot_all_params, plot_all_losses, plot_all_buckets, plot_cv_in_params, plot_recovery_loss, plot_confidence_interval\n",
    "import yaml\n",
    "from data.dataloader import SimulatedDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_hosp_ratios(param_set, data_config, model_config):\n",
    "    df = pd.read_csv(os.path.join('../../data/data/simulated_data/', data_config['output_file_name']), index_col=0)\n",
    "    if model_config['end_date']:\n",
    "        # print(model_config['end_date'])\n",
    "        if isinstance(model_config['end_date'], int):\n",
    "            if end_date > 0:\n",
    "                raise ValueError('Please enter a negative value for end_date if entering an integer')\n",
    "        if isinstance(model_config['end_date'], datetime.date):\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            end_date = df.loc[df['date'].dt.date == model_config['end_date']].index[0] - len(df) + 1\n",
    "    else:\n",
    "        end_date = 0\n",
    "    train_start_row = df.iloc[len(df) - (model_config['train_period'] + model_config['val_period'] + model_config['test_period']) + end_date]\n",
    "    if data_config['model'] == 'SEIRHD':\n",
    "        param_set['E_hosp_ratio'] = train_start_row['E'] / train_start_row['active']\n",
    "        param_set['I_hosp_ratio'] = train_start_row['I'] / train_start_row['active']\n",
    "    elif data_config['model'] == 'SEIRHD_Beta':\n",
    "        param_set['E_hosp_ratio'] = train_start_row['E'] / train_start_row['active']\n",
    "        param_set['I_hosp_ratio'] = train_start_row['I'] / train_start_row['active']\n",
    "    elif data_config['model'] == 'SEIR_PU':\n",
    "        param_set['E_hosp_ratio'] = train_start_row['E'] / train_start_row['active']\n",
    "        param_set['I_hosp_ratio'] = train_start_row['I'] / train_start_row['active']\n",
    "        param_set['Pu_pop_ratio'] = train_start_row['Pu'] / train_start_row['']\n",
    "    return param_set"
   ]
  },
  {
   "source": [
    "# Create short pickle file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '../../misc/predictions/exp3' \n",
    "file_name = 'exp3_fixed_params.pickle'\n",
    "with open(os.path.join(save_dir, file_name), 'rb') as handle:\n",
    "    input_dict = pkl.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for pred in input_dict['predictions_dicts']:\n",
    "    pd_output = {}\n",
    "    pd_output['prediction_dict'] = {}\n",
    "    pd_output['prediction_dict']['best_params'] = pred['prediction_dict']['best_params']\n",
    "    pd_output['prediction_dict']['df_loss'] = pred['prediction_dict']['df_loss']\n",
    "    pd_output['run_tuple'] = pred['run_tuple']\n",
    "    # pd['trials'] = pd['prediction_dict']['trials']\n",
    "    # del pd['prediction_dict']\n",
    "    output.append(pd_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = {}\n",
    "output_dict['predictions_dicts'] = output\n",
    "output_dict['model_config'] = input_dict['model_config']\n",
    "output_dict['val_periods'] = input_dict['val_periods']\n",
    "output_dict['train_periods'] = input_dict['train_periods']\n",
    "output_dict['end_dates'] = input_dict['end_dates']\n",
    "with open(os.path.join(save_dir, \"exp3_trial2_short.pickle\"), 'wb') as handle:\n",
    "    pkl.dump(output_dict, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '../../misc/predictions/exp3/short' \n",
    "file_name = 'exp3_trial1_short.pickle'\n",
    "with open(os.path.join(save_dir, file_name), 'rb') as handle:\n",
    "    run_dict = pkl.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = run_dict['model_config']\n",
    "simulated_config_filename = model_config['data']['dataloading_params']['config_file']\n",
    "with open(os.path.join(\"../../configs/simulated_data/\", simulated_config_filename)) as configfile:\n",
    "    simulated_config = yaml.load(configfile, Loader=yaml.SafeLoader)    \n",
    "actual_params = simulated_config['params']\n",
    "del actual_params['N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_periods = run_dict['train_periods']\n",
    "end_dates = run_dict['end_dates'] \n",
    "format_str = '%d-%m-%Y' # The format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dict = {}\n",
    "for param in actual_params :\n",
    "    plot_dict[param] = {}\n",
    "    for end_date in end_dates :\n",
    "        end_date = datetime.datetime.strptime(end_date,format_str).date()\n",
    "        plot_dict[param][end_date] = {}\n",
    "        for train in train_periods : \n",
    "            plot_dict[param][end_date][train] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape_loss(pred,true):\n",
    "    return (abs(pred-true)/true)*100\n",
    "\n",
    "def calc_loss(pred,true,method='mape'):\n",
    "    if method == 'mape':\n",
    "        return mape_loss(pred,true)\n",
    "\n",
    "def compute_losses(best_params,true_params,method='mape'):\n",
    "    losses = {}\n",
    "    for param in best_params:\n",
    "        losses[param] = calc_loss(best_params[param],true_params[param],method)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "val_period = 7\n",
    "for run in run_dict['predictions_dicts'] : \n",
    "    run_tuple = run['run_tuple']\n",
    "    if(run_tuple['val'] != val_period):\n",
    "        continue\n",
    "    pred = run['prediction_dict']\n",
    "    best_params = pred['best_params']\n",
    "    model_config['split']['end_date'] = run_tuple['end_date']\n",
    "    model_config['split']['train_period'] = run_tuple['train']\n",
    "    model_config['split']['val_period'] = run_tuple['val']\n",
    "    # print(model_config['split'])\n",
    "    true_params = update_hosp_ratios(actual_params, simulated_config, model_config['split'])\n",
    "    losses = compute_losses(best_params,true_params)\n",
    "    print (run_tuple, best_params['beta'])\n",
    "    for param in losses :\n",
    "        plot_dict[param][run_tuple['end_date']][run_tuple['train']].append(losses[param])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for param in actual_params : \n",
    "    for end_date in end_dates :\n",
    "        end_date = datetime.datetime.strptime(end_date,format_str).date()\n",
    "        for train in train_periods : \n",
    "            losses = np.array(plot_dict[param][end_date][train])\n",
    "            plot_dict[param][end_date][train] = np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "cmap = sns.cm.rocket_r\n",
    "\n",
    "n_subplots = len(plot_dict)\n",
    "ncols = 2\n",
    "nrows = math.ceil(n_subplots/ncols)\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, \n",
    "                        figsize=(18, 6*nrows))\n",
    "ax_counter = 0\n",
    "for param, param_dict in plot_dict.items():\n",
    "    # if param in ['T_inf', 'T_inc', 'T_recov_fatal']:\n",
    "        # continue\n",
    "    ax = axs.flat[ax_counter]\n",
    "    arr = []\n",
    "    for end_date in end_dates:\n",
    "        end_date_dict = param_dict[datetime.datetime.strptime(end_date,format_str).date()]\n",
    "        l = []\n",
    "        for train in train_periods:\n",
    "            train_dict = end_date_dict[train]\n",
    "            l.append(train_dict)\n",
    "        arr.append(l)\n",
    "    df_cm = pd.DataFrame(arr, index = end_dates,\n",
    "                  columns = train_periods)\n",
    "    sn.heatmap(df_cm, annot=False, ax=ax, cmap=cmap, cbar_kws={'label': 'recovery loss (MAPE %)'})\n",
    "    ax_counter += 1\n",
    "    ax.set_title(param)\n",
    "    ax.set_xlabel(\"Train periods\")\n",
    "    ax.set_ylabel(\"End dates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}