{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "import datetime\n",
    "import copy\n",
    "import time\n",
    "import wandb\n",
    "import pickle as pkl\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from data.processing import get_data\n",
    "\n",
    "import models\n",
    "\n",
    "from main.seir.fitting import single_fitting_cycle\n",
    "from main.seir.forecast import get_forecast, forecast_all_trials, create_all_trials_csv, create_decile_csv_new\n",
    "from main.seir.sensitivity import calculate_sensitivity_and_plot\n",
    "from utils.generic.create_report import save_dict_and_create_report\n",
    "from utils.generic.config import read_config\n",
    "from utils.generic.enums import Columns\n",
    "from utils.fitting.loss import Loss_Calculator\n",
    "from utils.generic.logging import log_wandb\n",
    "from viz import plot_forecast, plot_top_k_trials, plot_ptiles\n",
    "from viz.fit import plot_histogram, plot_all_histograms, plot_mean_variance, plot_scatter, plot_kl_divergence, plot_heatmap_distribution_sigmas, plot_all_params, plot_all_losses, plot_all_buckets\n",
    "import yaml\n",
    "from data.dataloader import SimulatedDataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = '../../misc/reports/{}'.format(datetime.datetime.now().strftime(\"%Y_%m%d_%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rep_trials = 5\n",
    "actual_params = []\n",
    "simulated_data_configs = ['seir_pu_variable.yaml']\n",
    "for config_filename in simulated_data_configs:\n",
    "    for m in range(num_rep_trials):\n",
    "        with open(os.path.join(\"../../configs/simulated_data/\", config_filename)) as configfile:\n",
    "            config = yaml.load(configfile, Loader=yaml.SafeLoader)    \n",
    "        config['output_file_name'] = config_filename.split('.')[0] + '_' + str(m) + '.csv'\n",
    "        loader = SimulatedDataLoader()\n",
    "        _, actual_param = loader.load_data(**config)\n",
    "        actual_params.append(actual_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_filenames = ['experiments/seirhd.yaml', 'experiments/seirhd_const.yaml', 'experiments/seir_pu.yaml']\n",
    "model_params = {\n",
    "        'SEIRHD Free': [ 'lockdown_R0', 'T_inc', 'T_inf', 'T_inf', 'T_recov', 'T_recov_fatal', 'P_fatal', 'E_hosp_ratio', 'I_hosp_ratio'],\n",
    "        'SEIRHD Cons': [ 'lockdown_R0', 'T_inc', 'T_inf', 'T_inf', 'T_recov', 'T_recov_fatal', 'P_fatal', 'E_hosp_ratio', 'I_hosp_ratio'],\n",
    "        'SEIR_PU': [ 'T_inc', 'T_inf_U', 'T_recov', 'T_recov_fatal', 'beta', 'd', 'P_fatal', 'I_hosp_ratio', 'E_hosp_ratio','Pu_pop_ratio'],\n",
    "    }\n",
    "model_types = {'SEIRHD' : 'SEIRHD', 'SEIRHD Free' : 'SEIRHD', 'SEIRHD Cons' : 'SEIRHD', 'SEIR_Undetected':'SEIR_Undetected','SEIR_PU':'SEIR_PU','SEIR_PU_Testing':'SEIR_PU_Testing'}\n",
    "model_names = list(model_params.keys())\n",
    "configs = [read_config(config_filename) for config_filename in config_filenames]\n",
    "# location_tuples = {\n",
    "#     # 'MUM(Latest)' : ('Maharashtra', 'Mumbai', None, None), # peak inside training\n",
    "#     'MUM(15Aug)' : ('Maharashtra', 'Mumbai', datetime.date(2020,8,15), None), \n",
    "#     'MUM(1July)' : ('Maharashtra', 'Mumbai', datetime.date(2020,7,1), None), \n",
    "#     # 'DEL(Latest)' : ('Delhi', None, None, None),\n",
    "#     'DEL(15Aug)' : ('Delhi', None, datetime.date(2020,8,15), None),\n",
    "#     'DEL(1Aug)' : ('Delhi', None, datetime.date(2020,8,1), None),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for simulated_data in range(num_rep_trials):\n",
    "    tag = \"seir_pu_variable_\" + str(simulated_data)\n",
    "    predictions_dict[tag] = {}\n",
    "    for j, config in enumerate(configs):\n",
    "        predictions_dict[tag][model_names[j]] = {}\n",
    "        config_params = copy.deepcopy(config['fitting'])\n",
    "        config_params['data']['data_source'] = 'simulated'\n",
    "        config_params['data']['smooth_jump'] = False\n",
    "        config_params['data']['rolling_average'] = False\n",
    "        config_params['data']['dataloading_params']['generate'] = False\n",
    "        config_params['data']['dataloading_params']['filename'] = \"../../data/data/simulated_data/\" + tag + \".csv\"\n",
    "        for k in range(num_rep_trials):\n",
    "            print (tag, model_names[j], k)\n",
    "            predictions_dict[tag][model_names[j]][f'm{k}'] = single_fitting_cycle(**config_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../misc/predictions/predictions_dict_time.pickle', 'wb') as handle:\n",
    "    pkl.dump(predictions_dict, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the pickle file to read the predicitons_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../misc/predictions/predictions_dict.pickle', 'rb') as handle:\n",
    "    predictions_dict = pkl.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"covid-modelling\")\n",
    "wandb.run.name = \"degeneracy-exps-location\"+wandb.run.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_all_params(predictions_dict, model_params, method='ensemble_combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_compartments = {model_names[i]: config['fitting']['loss']['loss_compartments'] for i, config in enumerate(configs)}\n",
    "plot_all_losses(predictions_dict, which_losses=['train', 'val'], which_compartments=which_compartments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_buckets(predictions_dict, which_buckets=['S', 'I', 'E', 'I_U'], compare='model', model_types=model_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('covid_modelling': conda)",
   "display_name": "Python 3.8.5 64-bit ('covid_modelling': conda)",
   "metadata": {
    "interpreter": {
     "hash": "8d4520c4ae250cc42f52066aee3414cc1b6850f2df392ef0f675cfc8e593b997"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}