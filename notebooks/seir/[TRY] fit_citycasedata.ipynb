{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from hyperopt import hp, tpe, fmin, Trials\n",
    "from tqdm import tqdm\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "from collections import OrderedDict, defaultdict\n",
    "import itertools\n",
    "from functools import partial\n",
    "import datetime\n",
    "from joblib import Parallel, delayed\n",
    "import copy\n",
    "import json\n",
    "\n",
    "from data.dataloader import Covid19IndiaLoader\n",
    "from data.processing import get_data, get_district_time_series\n",
    "\n",
    "from models.seir.seir_testing import SEIR_Testing\n",
    "from main.seir.optimiser import Optimiser\n",
    "from utils.loss import Loss_Calculator\n",
    "from main.seir.fitting import single_fitting_cycle\n",
    "from main.seir.forecast import get_forecast, create_region_csv, create_all_csvs, write_csv, plot_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Covid19india Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = Covid19IndiaLoader()\n",
    "dataframes = loader.get_covid19india_api_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Districts to fit on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts_to_show = [('Maharashtra', 'Pune'), \n",
    "                     ('Maharashtra', 'Mumbai'), \n",
    "                     ('Rajasthan', 'Jaipur'), \n",
    "                     ('Gujarat', 'Ahmedabad'), \n",
    "                     ('Karnataka', 'Bengaluru Urban'),\n",
    "                     ('Delhi', None)]\n",
    "\n",
    "districts_to_show = [('Maharashtra', 'Pune')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform M1 and M2 fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state, district in districts_to_show:\n",
    "    predictions_dict[(state, district)] = {}\n",
    "    predictions_dict[(state, district)]['m1'] = single_fitting_cycle(dataframes, state, district, train_period=7, val_period=7, \n",
    "                                                                     data_from_tracker=False, filename=\"../../data/data/official-pune-21-05-20.csv\", initialisation='intermediate', num_evals=2000,\n",
    "                                                                     which_compartments=['hospitalised', 'total_infected', 'deceased', 'recovered'])\n",
    "    predictions_dict[(state, district)]['m2'] = single_fitting_cycle(dataframes, state, district, train_period=7, val_period=0, num_evals=2000,\n",
    "                                                                     train_on_val=True, data_from_tracker=False, filename=\"../../data/data/official-pune-21-05-20.csv\",initialisation='intermediate',\n",
    "                                                                     which_compartments=['hospitalised', 'total_infected', 'deceased', 'recovered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state, district in districts_to_show:\n",
    "    predictions_dict[(state, district)] = {}\n",
    "    predictions_dict[(state, district)]['m1'] = single_fitting_cycle(dataframes, state, district, train_period=7, val_period=7, num_evals=1000,\n",
    "                                                                     data_from_tracker=False, filename='../../data/data/official-mumbai.csv', \n",
    "                                                                     initialisation='intermediate',\n",
    "                                                                     which_compartments=['hospitalised', 'total_infected', 'deceased', 'recovered'])\n",
    "    predictions_dict[(state, district)]['m2'] = single_fitting_cycle(dataframes, state, district, train_period=7, val_period=0, num_evals=1000,\n",
    "                                                                     data_from_tracker=False, filename='../../data/data/official-mumbai.csv',\n",
    "                                                                     initialisation='intermediate', train_on_val=True, \n",
    "                                                                     which_compartments=['hospitalised', 'total_infected', 'deceased', 'recovered'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Master Loss Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M1 Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_key = list(predictions_dict.keys())[0]\n",
    "\n",
    "loss_columns = pd.MultiIndex.from_product([predictions_dict[starting_key]['m1']['df_loss'].columns, predictions_dict[starting_key]['m1']['df_loss'].index])\n",
    "loss_index = predictions_dict.keys()\n",
    "\n",
    "df_loss_master = pd.DataFrame(columns=loss_columns, index=loss_index)\n",
    "for key in predictions_dict.keys():\n",
    "    df_loss_master.loc[key, :] = np.around(predictions_dict[key]['m1']['df_loss'].values.T.flatten().astype('float'), decimals=2)\n",
    "    \n",
    "df_loss_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M2 Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_key = list(predictions_dict.keys())[0]\n",
    "\n",
    "loss_columns = pd.MultiIndex.from_product([predictions_dict[starting_key]['m2']['df_loss'].columns, predictions_dict[starting_key]['m2']['df_loss'].index])\n",
    "loss_index = predictions_dict.keys()\n",
    "\n",
    "df_loss_master = pd.DataFrame(columns=loss_columns, index=loss_index)\n",
    "for key in predictions_dict.keys():\n",
    "    df_loss_master.loc[key, :] = np.around(predictions_dict[key]['m2']['df_loss'].values.T.flatten().astype('float'), decimals=2)\n",
    "    \n",
    "df_loss_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in predictions_dict.keys():\n",
    "    plot_forecast(predictions_dict[region], region, both_forecasts=False, error_bars=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in predictions_dict.keys():\n",
    "    plot_forecast(predictions_dict[region], region, both_forecasts=True, error_bars=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Save Output CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = create_all_csvs(predictions_dict, initialisation='intermediate', train_period=7, icu_fraction=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(df_output, '../../output-{}.csv'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_key=list(predictions_dict.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict[starting_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Multiple Forecasts For Top 10 Param Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_array = np.array([trial['result']['loss'] for trial in predictions_dict[starting_key]['m2']['trials']])\n",
    "least_losses_indices = np.argsort(losses_array)\n",
    "np.sort(losses_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(losses_array)[1:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_array = []\n",
    "for trial in predictions_dict[starting_key]['m2']['trials']:\n",
    "    params_dict = copy.copy(trial['misc']['vals'])\n",
    "    for key in params_dict.keys():\n",
    "        params_dict[key] = params_dict[key][0]\n",
    "    params_array.append(params_dict)\n",
    "\n",
    "params_array = np.array(params_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(losses_array)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_array = [get_forecast(predictions_dict[starting_key], best_params=params_dict) for params_dict in params_array[least_losses_indices[:10]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = params_array[least_losses_indices[:10]]\n",
    "params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true = predictions_dict[starting_key]['m2']['df_district']\n",
    "color_idx=np.linspace(0,1,10)\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "ax.plot(df_true['date'], df_true['hospitalised'],\n",
    "        '-o', color='orange', label='Active Cases (Observed)')\n",
    "for i, df_prediction in enumerate(predictions_array):\n",
    "    loss_value = np.around(np.sort(losses_array)[:10][i], 3)\n",
    "    params_dict = params_array[least_losses_indices[:10]]\n",
    "    true_r0 = np.around(params_dict[i]['lockdown_R0'], 3)\n",
    "    if true_r0 > 1.7:\n",
    "        continue\n",
    "    sns.lineplot(x=\"date\", y=\"hospitalised\", data=df_prediction,\n",
    "                 ls='-', color=plt.cm.summer(color_idx[i]), label='Active Cases ({})'.format(loss_value))\n",
    "    plt.text(x=df_prediction['date'].iloc[-1], y=df_prediction['hospitalised'].iloc[-1], s=\"{0:.3f}\".format(true_r0))\n",
    "    \n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(interval=7))\n",
    "ax.xaxis.set_minor_locator(mdates.DayLocator(interval=1))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.ylabel('No of People', fontsize=16)\n",
    "# plt.yscale('log')\n",
    "plt.xlabel('Time', fontsize=16)\n",
    "plt.legend()\n",
    "plt.title('Forecast - ({} {})'.format(region[0], region[1]), fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
