{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "import datetime\n",
    "import copy\n",
    "import time\n",
    "import wandb\n",
    "import pickle as pkl\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from data.processing import get_data\n",
    "import models\n",
    "from main.seir.fitting import single_fitting_cycle\n",
    "from main.seir.forecast import get_forecast, forecast_all_trials, create_all_trials_csv, create_decile_csv_new\n",
    "from main.seir.sensitivity import calculate_sensitivity_and_plot\n",
    "from utils.generic.create_report import save_dict_and_create_report\n",
    "from utils.generic.config import read_config\n",
    "from utils.generic.enums import Columns\n",
    "from utils.fitting.loss import Loss_Calculator\n",
    "from utils.generic.logging import log_wandb\n",
    "from viz import plot_forecast, plot_top_k_trials, plot_ptiles\n",
    "from viz.fit import plot_histogram, plot_all_histograms, plot_mean_variance, plot_scatter, plot_kl_divergence, plot_heatmap_distribution_sigmas, plot_all_params, plot_all_losses, plot_all_buckets, plot_cv_in_params, plot_recovery_loss\n",
    "import yaml\n",
    "from data.dataloader import SimulatedDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = '../../misc/reports/{}'.format(datetime.datetime.now().strftime(\"%Y_%m%d_%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rep_trials = 2\n",
    "actual_params = []\n",
    "simulated_data_configs = ['seir_pu_variable.yaml']\n",
    "for config_filename in simulated_data_configs:\n",
    "    for m in range(num_rep_trials):\n",
    "        with open(os.path.join(\"../../configs/simulated_data/\", config_filename)) as configfile:\n",
    "            config = yaml.load(configfile, Loader=yaml.SafeLoader)    \n",
    "        config['output_file_name'] = config_filename.split('.')[0] + '_' + str(m) + '.csv'\n",
    "        loader = SimulatedDataLoader()\n",
    "        _, actual_param = loader.load_data(**config)\n",
    "        actual_params.append(actual_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_filenames = ['experiments/seirhd.yaml']\n",
    "model_params = {\n",
    "        'SEIRHD': [ 'lockdown_R0', 'T_inc', 'T_inf', 'T_inf', 'T_recov', 'T_recov_fatal', 'P_fatal', 'E_hosp_ratio', 'I_hosp_ratio'],\n",
    "    }\n",
    "model_types = {'SEIRHD' : 'SEIRHD', 'SEIRHD Free' : 'SEIRHD', 'SEIRHD Cons' : 'SEIRHD', 'SEIR_Undetected':'SEIR_Undetected','SEIR_PU':'SEIR_PU','SEIR_PU_Testing':'SEIR_PU_Testing'}\n",
    "model_names = list(model_params.keys())\n",
    "configs = [read_config(config_filename) for config_filename in config_filenames]\n",
    "# param_tuples = {\n",
    "#     'free':{},\n",
    "#     'lat_params_fixed':{'I_hosp_ratio': 0.5, 'E_hosp_ratio': 0.5,'Pu_pop_ratio': 0.3}\n",
    "# }\n",
    "param_tuples = {\n",
    "    # 'all':{'I_hosp_ratio': 0.5, 'E_hosp_ratio': 0.5,'lockdown_R0': 0.8,'P_fatal':0.3,'T_recov_fatal':25,'T_recov':15,'T_inc':4.5,'T_inf':5}\n",
    "    'P_fatal':{'I_hosp_ratio': 0.5, 'E_hosp_ratio': 0.5,'lockdown_R0': 0.8,'T_recov_fatal':25,'T_recov':15,'T_inc':4.5,'T_inf':5},\n",
    "    'r0':{'I_hosp_ratio': 0.5, 'E_hosp_ratio': 0.5,'P_fatal':0.3,'T_recov_fatal':25,'T_recov':15,'T_inc':4.5,'T_inf':5},\n",
    "    'T_inf':{'I_hosp_ratio': 0.5, 'E_hosp_ratio': 0.5,'lockdown_R0': 0.8,'P_fatal':0.3,'T_recov_fatal':25,'T_recov':15,'T_inc':4.5}\n",
    "    # 'free':{}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "configs = [read_config(config_filename) for config_filename in config_filenames]\n",
    "num_rep_trials = 2\n",
    "for tag, loc in param_tuples.items():\n",
    "    predictions_dict[tag] = {}\n",
    "    for j, config in enumerate(configs):\n",
    "        predictions_dict[tag][model_names[j]] = {}\n",
    "        config_params = copy.deepcopy(config['fitting'])\n",
    "        for param in loc:\n",
    "            if param in config_params['variable_param_ranges']:\n",
    "                del config_params['variable_param_ranges'][param] \n",
    "            config_params['default_params'][param] = loc[param]\n",
    "        print ('variable param ranges:', config_params['variable_param_ranges'])\n",
    "        print ('default param ranges:', config_params['default_params'])\n",
    "        for k in range(num_rep_trials):\n",
    "            predictions_dict[tag][model_names[j]][f'm{k}'] = single_fitting_cycle(**config_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '../../misc/predictions/deg_exp/'    \n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "for tag, tag_dict in predictions_dict.items():\n",
    "    with open(os.path.join(save_dir, tag + \".pickle\"), 'wb') as handle:\n",
    "        pkl.dump(tag_dict, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the pickle file to read the predicitons_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '../../misc/predictions/deg_exp/'    \n",
    "predictions_dict_complete = {}\n",
    "files_to_read = []\n",
    "files = [i+'.pickle' for i in files_to_read if i+'.pickle' in os.listdir(save_dir)]\n",
    "if len(files) == 0:\n",
    "    files = os.listdir(save_dir)\n",
    "for file_name in files:\n",
    "    with open(os.path.join(save_dir, file_name), 'rb') as handle:\n",
    "        predictions_dict_complete[file_name.split('.')[0]] = pkl.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(project=\"covid-modelling\")\n",
    "# wandb.run.name = \"degeneracy-exps-location\"+wandb.run.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_all_params(predictions_dict_complete, model_params, method='ensemble_combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"../../configs/simulated_data/\", 'seir_pu_fixed.yaml')) as configfile:\n",
    "    config_simlated_data = yaml.load(configfile, Loader=yaml.SafeLoader) \n",
    "actual_param = config_simlated_data['params']\n",
    "plot_recovery_loss(predictions_dict_complete, actual_param, model_params, method='ensemble_combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficient of varience\n",
    "plot_cv_in_params(predictions_dict_complete, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_compartments = {model_names[i]: config['fitting']['loss']['loss_compartments'] for i, config in enumerate(configs)}\n",
    "plot_all_losses(predictions_dict_complete, which_losses=['train', 'val'], which_compartments=which_compartments,method='best_loss_nora')\n",
    "which_compartments = {model_names[i]: [] for i, config in enumerate(configs)}\n",
    "# plot_all_losses(predictions_dict_complete, which_losses=['train'], which_compartments=which_compartments,method='best_loss_ra')\n",
    "# plot_all_losses(predictions_dict_complete, which_losses=['train'], which_compartments=which_compartments,method='ensemble_loss_ra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_buckets(predictions_dict, which_buckets=['S', 'I', 'E', 'I_U'], compare='model', model_types=model_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('anaconda3': virtualenv)",
   "metadata": {
    "interpreter": {
     "hash": "483dd91e9e5776a554fa707e4e3da737dc749f524ad6485bce7bd4bb723db086"
    }
   },
   "name": "Python 3.7.6 64-bit ('anaconda3': virtualenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
