{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from utils.fitting.loss import Loss_Calculator\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "import re\n",
    "from datetime import datetime, date, timedelta\n",
    "from glob import glob\n",
    "\n",
    "from utils.generic.config import read_config, make_date_key_str\n",
    "from utils.generic.reichlab import *\n",
    "from viz.reichlab import *\n",
    "from viz import plot_ptiles\n",
    "from viz.uncertainty import plot_ptiles_reichlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_states_abbv_df = pd.read_csv('../../data/data/us_states_abbv.csv')\n",
    "us_states_abbv_dict = dict(zip(us_states_abbv_df['state'], us_states_abbv_df['state_code']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_name_to_key_dict = get_mapping(which='location_name_to_code')\n",
    "us_states_abbv_dict = get_mapping(which='location_name_to_abbv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_pkl_filename = '/scratch/users/sansiddh/covid-modelling/2020_1211_183006/predictions_dict.pkl'\n",
    "with open(predictions_pkl_filename, 'rb') as f:\n",
    "    predictions_dict1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_pkl_filename = '/scratch/users/sansiddh/covid-modelling/2020_1212_015547/predictions_dict.pkl'\n",
    "with open(predictions_pkl_filename, 'rb') as f:\n",
    "    predictions_dict2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_pkl_filename = '/scratch/users/sansiddh/covid-modelling/2020_1212_041024/predictions_dict.pkl'\n",
    "with open(predictions_pkl_filename, 'rb') as f:\n",
    "    predictions_dict3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_pkl_filename = '/scratch/users/sansiddh/covid-modelling/2020_1212_021044/predictions_dict.pkl'\n",
    "with open(predictions_pkl_filename, 'rb') as f:\n",
    "    predictions_dict4 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_pkl_filename = '/scratch/users/sansiddh/covid-modelling/2020_1211_221217/predictions_dict.pkl'\n",
    "with open(predictions_pkl_filename, 'rb') as f:\n",
    "    predictions_dict5 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beta = pd.DataFrame(columns=[key for key in predictions_dict1.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beta.loc[0, :] = [predictions_dict1[key]['m2']['beta'] for key in predictions_dict1.keys()]\n",
    "df_beta.loc[1, :] = [predictions_dict2[key]['m2']['beta'] for key in predictions_dict2.keys()]\n",
    "df_beta.loc[2, :] = [predictions_dict3[key]['m2']['beta'] for key in predictions_dict3.keys()]\n",
    "df_beta.loc[3, :] = [predictions_dict4[key]['m2']['beta'] for key in predictions_dict3.keys()]\n",
    "df_beta.loc[4, :] = [predictions_dict5[key]['m2']['beta'] for key in predictions_dict3.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beta = df_beta.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beta.merge(df_mape_wiai, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = predictions_dict1[list(predictions_dict1.keys())[0]]['m2']['run_params']\n",
    "except:\n",
    "    config_filename = 'us2.yaml'\n",
    "    config = read_config(config_filename)['fitting']\n",
    "\n",
    "loss_comp = config['loss']['loss_compartments'][0]\n",
    "data_last_date = config['split']['end_date']\n",
    "date_of_submission = (data_last_date + timedelta(days=2)).strftime('%Y-%m-%d')\n",
    "if loss_comp == 'deceased':\n",
    "    comp = 'cum_death'\n",
    "if loss_comp == 'total':\n",
    "    comp = 'cum_case'\n",
    "print(comp)\n",
    "print(date_of_submission)\n",
    "\n",
    "list_of_models = get_list_of_models(date_of_submission, comp, reichlab_path='../../../covid19-forecast-hub',\n",
    "                                    num_submissions_filter=45)\n",
    "df_all_submissions = process_all_submissions(list_of_models, date_of_submission, comp, reichlab_path='../../../covid19-forecast-hub')\n",
    "df_gt, df_gt_loss, df_gt_loss_wk = process_gt(comp, df_all_submissions, reichlab_path='../../../covid19-forecast-hub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_mape(predictions_dict, df_all_submissions):\n",
    "    df_wiai_submission = format_wiai_submission(predictions_dict, loc_name_to_key_dict, which_fit='m2', \n",
    "                                                use_as_point_forecast='ensemble_mean', skip_percentiles=False)\n",
    "\n",
    "    df_all = combine_wiai_subm_with_all(df_all_submissions, df_wiai_submission, comp)\n",
    "\n",
    "    df_comb, df_mape, df_rank = compare_gt_pred(df_all, df_gt_loss_wk)\n",
    "    return df_mape.loc['Wadhwani_AI', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_wiai_submission = format_wiai_submission(predictions_dict1, loc_name_to_key_dict, which_fit='m2', \n",
    "                                            use_as_point_forecast='ensemble_mean', skip_percentiles=False)\n",
    "\n",
    "df_all = combine_wiai_subm_with_all(df_all_submissions, df_wiai_submission, comp)\n",
    "\n",
    "df_comb, df_mape, df_rank = compare_gt_pred(df_all, df_gt_loss_wk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_mape1 = return_mape(predictions_dict1, df_all_submissions)\n",
    "df_mape2 = return_mape(predictions_dict2, df_all_submissions)\n",
    "df_mape3 = return_mape(predictions_dict3, df_all_submissions)\n",
    "df_mape4 = return_mape(predictions_dict4, df_all_submissions)\n",
    "df_mape5 = return_mape(predictions_dict5, df_all_submissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mape_wiai = pd.concat([df_mape1, df_mape2, df_mape3, df_mape4, df_mape5], axis=1)\n",
    "df_mape_wiai = pd.concat([df_mape_wiai, df_mape_wiai.median(axis=1)], axis=1)\n",
    "df_mape_wiai.columns = ['Wadhwani_AI']*len(df_mape_wiai.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mape_wiai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mape.loc['Wadhwani_AI', :] = df_mape_wiai.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mape.loc['Wadhwani_AI', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank = df_mape.rank()\n",
    "try:\n",
    "    df_mape.drop(['Guam', 'Virgin Islands', 'Northern Mariana Islands'], axis=1, inplace=True)\n",
    "    df_rank.drop(['Guam', 'Virgin Islands', 'Northern Mariana Islands'], axis=1, inplace=True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = create_performance_table(df_mape, df_rank)\n",
    "x = datetime.strptime(date_of_submission, '%Y-%m-%d')\n",
    "data_last_date = (x - timedelta(days=2))\n",
    "print('Data last date -  {}'.format(data_last_date.strftime('%Y-%m-%d')))\n",
    "print('Test period till -  {}'.format((data_last_date + timedelta(days=28)).strftime('%Y-%m-%d')))\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_models = len(df_mape.median(axis=1))\n",
    "print(f'Total # of models - {num_models}')\n",
    "median_mape = df_mape.loc[:, np.logical_not(df_mape.loc['Wadhwani_AI', :].isna())].median(axis=1).rename('median_mape')\n",
    "median_rank = df_rank.loc[:, np.logical_not(df_rank.loc['Wadhwani_AI', :].isna())].median(axis=1).rename('median_rank')\n",
    "merged = pd.concat([median_mape, median_rank], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = calculate_z_score(df_mape, df_rank, model_name='Wadhwani_AI')\n",
    "\n",
    "fig, ax = create_heatmap(df, var_name='non_param_z_score', center=0)\n",
    "\n",
    "df_wadhwani = combine_with_train_error(predictions_dict, df)\n",
    "\n",
    "print(f'# -ve Z score {len(df_wadhwani[df_wadhwani[\"z_score\"] <= 0])}')\n",
    "print(f'# +ve Z score {len(df_wadhwani[df_wadhwani[\"z_score\"] > 0])}')\n",
    "\n",
    "print(f'# -ve non param Z score {len(df_wadhwani[df_wadhwani[\"non_param_z_score\"] <= 0])}')\n",
    "print(f'# +ve non param Z score {len(df_wadhwani[df_wadhwani[\"non_param_z_score\"] > 0])}')\n",
    "\n",
    "fig = create_scatter_plot_mape(df_wadhwani, annotate=True, abbv=True, abbv_dict=us_states_abbv_dict, \n",
    "                               stat_metric_to_use='non_param_z_score', log_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = create_performance_table(df_mape, df_rank)\n",
    "x = datetime.strptime(date_of_submission, '%Y-%m-%d')\n",
    "data_last_date = (x - timedelta(days=2))\n",
    "print('Data last date -  {}'.format(data_last_date.strftime('%Y-%m-%d')))\n",
    "print('Test period till -  {}'.format((data_last_date + timedelta(days=28)).strftime('%Y-%m-%d')))\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, state = ('Karlen-pypm', 'Texas')\n",
    "fig, ax = plot_ptiles_reichlab(df_comb, model, state, compartment='deceased')\n",
    "fig.savefig(f'../../../paper/plots/ptiles-{model}-{state}.pdf', format='pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, state = ('Wadhwani_AI', 'Texas')\n",
    "fig, ax = plot_ptiles_reichlab(df_comb, model, state, compartment='deceased')\n",
    "fig.savefig(f'../../../paper/plots/ptiles-{model}-{state}.pdf', format='pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = Loss_Calculator()\n",
    "df_comb['perc_loss_mape'] = np.nan\n",
    "for i, row in df_comb.iterrows():\n",
    "    if row['type'] == 'quantile':\n",
    "        df_comb.loc[i, 'perc_loss_mape'] = lc._calc_mape_perc(np.array([row['forecast_value']]), np.array([row['true_value']]), row['quantile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant = 0.8\n",
    "fig, ax = qtile_barchart(df_comb, quant, color='firebrick', latex=True)\n",
    "fig.savefig(f'../../../paper/plots/quant-loss-{quant}.pdf',\n",
    "            format='pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_performance_table(df_mape, df_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = preprocess_shape_file(filename='cb_2018_us_state_5m/cb_2018_us_state_5m.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wadhwani.loc[['Connecticut', 'Wyoming']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_plot = {\n",
    "    'non_param_z_score' : {'cmap':'RdYlGn_r', 'vmin':-1, 'vcenter':0, 'vmax':1},\n",
    "    'model_rank' : {'cmap':'Purples', 'vmin':0, 'vcenter':13, 'vmax':26},\n",
    "}\n",
    "fig, axs = plot_multiple_choropleths(df_wadhwani, gdf, vars_to_plot)\n",
    "fig.savefig('../../../paper/plots/choropleth.pdf', format='pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_plot = {\n",
    "    'z_score' : {'cmap':'RdYlGn_r', 'vmin':-1, 'vcenter':0, 'vmax':1},\n",
    "    'model_rank' : {'cmap':'Purples', 'vmin':0, 'vcenter':13, 'vmax':26},\n",
    "}\n",
    "fig, axs = plot_multiple_choropleths(df_wadhwani, gdf, vars_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = create_scatter_plot_zscores(df_wadhwani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_ecdf_all_states(df_mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(12, 6), ncols=2)\n",
    "plot_ecdf_single_state(df_mape, 'Connecticut', axs[0], model='Wadhwani_AI')\n",
    "plot_ecdf_single_state(df_mape, 'Wyoming', axs[1], model='Wadhwani_AI')\n",
    "fig.suptitle('Emperical Cumulative Distribution Plots')\n",
    "fig.savefig('../../../paper/plots/ecdf_plots.pdf', format='pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_qq_all_states(df_mape, fit=False, df_wadhwani=df_wadhwani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (covid)",
   "language": "python",
   "name": "covid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
