{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import copy\n",
    "import time\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../../')\n",
    "\n",
    "import models\n",
    "\n",
    "from main.seir.fitting import single_fitting_cycle\n",
    "from main.seir.forecast import get_forecast, forecast_all_trials, create_all_trials_csv, create_decile_csv_new\n",
    "from utils.generic.create_report import save_dict_and_create_report\n",
    "from utils.generic.config import read_config, make_date_key_str\n",
    "from utils.generic.enums import Columns\n",
    "from utils.fitting.loss import Loss_Calculator\n",
    "from utils.generic.logging import log_wandb, log_mlflow\n",
    "from viz import plot_forecast, plot_top_k_trials, plot_ptiles\n",
    "\n",
    "import yaml\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_filename = 'exp_simulate_2.yaml'\n",
    "config = read_config(config_filename)\n",
    "\n",
    "wandb_config = read_config(config_filename, preprocess=False)\n",
    "wandb_config = make_date_key_str(wandb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now()\n",
    "output_folder = '../../misc/reports/{}'.format(timestamp.strftime(\"%Y_%m%d_%H%M%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform M1 and M2 fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({\n",
    "    'text.usetex': False,\n",
    "    'font.size': 12,\n",
    "    'font.family': 'Palatino',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# scenario_dict ={}   \n",
    "# for i in range(7):\n",
    "#     file_name = '../../misc/predictions/exp_{}.pickle'.format(i)\n",
    "#     with open(file_name, 'rb') as handle:\n",
    "#         PD = pkl.load(handle)\n",
    "#     scenario_dict['exp'+str(i)] = PD['m1']\n",
    "# with open('../../misc/predictions/scenario_dict.pickle', 'wb') as handle:\n",
    "#     pkl.dump(scenario_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../misc/predictions/exp_simulate_2.pickle', 'rb') as handle:\n",
    "        PD = pkl.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_dict['exp4'] = PD['m1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs, axs = plt.subplots(2,4,figsize = [18,10])\n",
    "arr = ['beta', 'T_inc', 'T_inf', 'T_recov', 'T_recov_fatal', 'P_fatal', 'E_hosp_ratio', 'I_hosp_ratio']\n",
    "plot_2_histogram(scenario_dict,'exp0','exp4',arr,true_val,figs,axs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('../../misc/predictions/exp_simulate_2.pickle', 'rb') as handle:\n",
    "        PD = pkl.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('../../misc/predictions/exp_simulate_1.pickle', 'rb') as handle:\n",
    "        PD1 = pkl.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_hosp_ratios(param_set, data_config, model_config):\n",
    "    df = pd.read_csv(os.path.join('../../data/data/simulated_data/', data_config['output_file_name']), index_col=0)\n",
    "    if model_config['end_date']:\n",
    "        # print(model_config['end_date'])\n",
    "        if isinstance(model_config['end_date'], int):\n",
    "            if end_date > 0:\n",
    "                raise ValueError('Please enter a negative value for end_date if entering an integer')\n",
    "        if isinstance(model_config['end_date'], datetime.date):\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            end_date = df.loc[df['date'].dt.date == model_config['end_date']].index[0] - len(df) + 1\n",
    "    else:\n",
    "        end_date = 0\n",
    "    train_start_row = df.iloc[len(df) - (model_config['train_period'] + model_config['val_period'] + model_config['test_period']) + end_date]\n",
    "    if data_config['model'] == 'SEIRHD':\n",
    "        param_set['E_hosp_ratio'] = train_start_row['E'] / train_start_row['active']\n",
    "        param_set['I_hosp_ratio'] = train_start_row['I'] / train_start_row['active']\n",
    "    elif data_config['model'] == 'SEIRHD_Beta':\n",
    "        param_set['E_hosp_ratio'] = train_start_row['E'] / train_start_row['active']\n",
    "        param_set['I_hosp_ratio'] = train_start_row['I'] / train_start_row['active']\n",
    "    elif data_config['model'] == 'SEIR_PU':\n",
    "        param_set['E_hosp_ratio'] = train_start_row['E'] / train_start_row['active']\n",
    "        param_set['I_hosp_ratio'] = train_start_row['I'] / train_start_row['active']\n",
    "        param_set['Pu_pop_ratio'] = train_start_row['Pu'] / train_start_row['']\n",
    "    return param_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'seirhd_beta.yaml'\n",
    "with open(f'../../configs/simulated_data/{filename}') as configfile:\n",
    "        data_config = yaml.load(configfile, Loader=yaml.SafeLoader)\n",
    "true_val = data_config['params']\n",
    "true_val = update_hosp_ratios(true_val,data_config,config['fitting']['split'])\n",
    "print(true_val)\n",
    "true_val['P_fatal'] = 0.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs, axs = plt.subplots(2,4,figsize = [18,9])\n",
    "from viz.fit import plot_histogram,plot_all_histogram,plot_2_histogram,plot_log_density\n",
    "arr = ['beta', 'T_inc', 'T_inf', 'T_recov', 'T_recov_fatal', 'P_fatal', 'E_hosp_ratio', 'I_hosp_ratio']\n",
    "plot_log_density(PD['m1'],arr,true_val,figs,axs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs, axs = plt.subplots(2,4,figsize = [20,10])\n",
    "plot_histogram(PD1['m1'],arr,true_val,figs,axs)\n",
    "plot_histogram(PD['m1'],arr,true_val,figs,axs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidip import UniDip\n",
    "import pandas as pd\n",
    "arr = list(true_val.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('../../misc/predictions/exp_simulate_1.pickle', 'rb') as handle:\n",
    "        PD = pkl.load(handle)\n",
    "from main.seir.forecast import _order_trials_by_loss\n",
    "params_array, losses_array = _order_trials_by_loss(PD['m1'])\n",
    "params_dict = {param: [param_dict[param] for param_dict in params_array]\n",
    "                for param in arr}\n",
    "df = pd.DataFrame.from_dict(params_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    'text.usetex': False,\n",
    "    'font.size': 18,\n",
    "    'font.family': 'Palatino',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "CM = df.corr()\n",
    "fig = plt.figure(figsize = (16,14))\n",
    "heatmap = sns.heatmap(df.corr(), vmin=-1, vmax=1, annot=True,cmap = 'coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((CM.abs().mean()*8 - 1)/7).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in arr:\n",
    "#     R_0 = df[i].to_numpy()\n",
    "#     R_0 = np.msort(R_0)\n",
    "#     interavals = UniDip(R_0,alpha=0.0000001, ntrials=1000).run()\n",
    "#     print(i,interavals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions_dict['m1'] = single_fitting_cycle(**copy.deepcopy(config['fitting']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_params = copy.deepcopy(config['fitting'])\n",
    "m2_params['split']['val_period'] = 0\n",
    "predictions_dict['m2'] = single_fitting_cycle(**m2_params)\n",
    "\n",
    "predictions_dict['fitting_date'] = timestamp.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict['m1']['best_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict['m2']['best_params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M1 Loss DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict['m1']['df_loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M2 Loss DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict['m2']['df_loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict['m1']['plots']['sensitivity'], _, _ = calculate_sensitivity_and_plot(predictions_dict, config, which_fit='m1')\n",
    "predictions_dict['m2']['plots']['sensitivity'], _, _ = calculate_sensitivity_and_plot(predictions_dict, config, which_fit='m2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict['m2']['forecasts'] = {}\n",
    "predictions_dict['m2']['forecasts']['best'] = get_forecast(predictions_dict, train_fit='m2', \n",
    "                                                           model=config['fitting']['model'], \n",
    "                                                           forecast_days=config['forecast']['forecast_days'])\n",
    "\n",
    "predictions_dict['m2']['plots']['forecast_best'] = plot_forecast(predictions_dict, \n",
    "                                                                 'test', \n",
    "                                                                 error_bars=False)\n",
    "\n",
    "predictions_dict['m1']['trials_processed'] = forecast_all_trials(predictions_dict, train_fit='m1', \n",
    "                                                                 model=config['fitting']['model'], \n",
    "                                                                 forecast_days=config['forecast']['forecast_days'])\n",
    "\n",
    "predictions_dict['m2']['trials_processed'] = forecast_all_trials(predictions_dict, train_fit='m2', \n",
    "                                                                 model=config['fitting']['model'], \n",
    "                                                                 forecast_days=config['forecast']['forecast_days'])\n",
    "\n",
    "kforecasts = plot_top_k_trials(predictions_dict, train_fit='m2',\n",
    "                               k=config['forecast']['num_trials_to_plot'],\n",
    "                               which_compartments=config['forecast']['plot_topk_trials_for_columns'])\n",
    "                               \n",
    "predictions_dict['m2']['plots']['forecasts_topk'] = {}\n",
    "for column in config['forecast']['plot_topk_trials_for_columns']:\n",
    "    predictions_dict['m2']['plots']['forecasts_topk'][column.name] = kforecasts[column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty + Uncertainty Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_config(config_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty_args = {'predictions_dict': predictions_dict, 'fitting_config': config['fitting'],\n",
    "                    'forecast_config': config['forecast'], **config['uncertainty']['uncertainty_params']}\n",
    "                    \n",
    "uncertainty = config['uncertainty']['method'](**uncertainty_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty.ensemble_mean_forecast['df_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty_forecasts = uncertainty.get_forecasts()\n",
    "for key in uncertainty_forecasts.keys():\n",
    "    predictions_dict['m2']['forecasts'][key] = uncertainty_forecasts[key]['df_prediction']\n",
    "    \n",
    "predictions_dict['m2']['forecasts']['ensemble_mean'] = uncertainty.ensemble_mean_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict['m2']['beta'] = uncertainty.beta\n",
    "predictions_dict['m2']['beta_loss'] = uncertainty.beta_loss\n",
    "predictions_dict['m2']['deciles'] = uncertainty_forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict['m2']['plots']['forecast_best_50'] = plot_forecast(predictions_dict, \n",
    "                                                                    (config['fitting']['data']['dataloading_params']['state'], \n",
    "                                                                     config['fitting']['data']['dataloading_params']['district']),\n",
    "                                                                    fits_to_plot=['best', 48.7804878], error_bars=False)\n",
    "predictions_dict['m2']['plots']['forecast_best_80'] = plot_forecast(predictions_dict, \n",
    "                                                                    (config['fitting']['data']['dataloading_params']['state'], \n",
    "                                                                     config['fitting']['data']['dataloading_params']['district']),\n",
    "                                                                    fits_to_plot=['best', 80.48780488], error_bars=False)\n",
    "predictions_dict['m2']['plots']['forecast_ensemble_mean_50'] = plot_forecast(predictions_dict, \n",
    "                                                                             (config['fitting']['data']['dataloading_params']['state'], \n",
    "                                                                              config['fitting']['data']['dataloading_params']['district']),\n",
    "                                                                             fits_to_plot=['ensemble_mean', 48.7804878], error_bars=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['forecast']['plot_ptiles_for_columns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptiles_plots = plot_ptiles(predictions_dict, which_compartments=config['forecast']['plot_ptiles_for_columns'])\n",
    "predictions_dict['m2']['plots']['forecasts_ptiles'] = {}\n",
    "for column in config['forecast']['plot_ptiles_for_columns']:\n",
    "    predictions_dict['m2']['plots']['forecasts_ptiles'][column.name] = ptiles_plots[column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict_and_create_report(predictions_dict, config, ROOT_DIR=output_folder, config_filename=config_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Output CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = create_decile_csv_new(predictions_dict)\n",
    "df_output.to_csv(f'{output_folder}/deciles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log on W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"covid-modelling\", config=wandb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_wandb(predictions_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create All Trials Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = create_all_trials_csv(predictions_dict)\n",
    "df_all.to_csv(f'{output_folder}/all_trials.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log on MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {1:[2,3],2:[3,4],3:[4,5]}\n",
    "b = {1:[4,5],2:[5,6],3:[7,8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.update(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_mlflow(config['logging']['experiment_name'], run_name=config['logging']['run_name'], artifact_dir=output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
