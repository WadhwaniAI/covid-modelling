{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "import copy\n",
    "import json\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from data.dataloader import Covid19IndiaLoader\n",
    "from data.processing import get_data\n",
    "from data.processing import get_dataframes_cached\n",
    "\n",
    "from models.seir.seir_testing import SEIR_Testing\n",
    "from models.seir.seirhd import SEIRHD\n",
    "from models.seir.seir_movement import SEIR_Movement\n",
    "from models.seir.seir_movement_testing import SEIR_Movement_Testing\n",
    "\n",
    "from main.seir.fitting import single_fitting_cycle, get_variable_param_ranges\n",
    "from main.seir.forecast import get_forecast, create_region_csv, create_all_csvs, write_csv, plot_forecast\n",
    "from utils.create_report import create_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Covid19india Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = get_dataframes_cached()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Districts to fit on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# districts_to_show = [('Maharashtra', 'Pune'), \n",
    "#                      ('Maharashtra', 'Mumbai'), \n",
    "#                      ('Rajasthan', 'Jaipur'), \n",
    "#                      ('Gujarat', 'Ahmedabad'), \n",
    "#                      ('Karnataka', 'Bengaluru Urban'),\n",
    "#                      ('Delhi', None)]\n",
    "\n",
    "districts_to_show = [('Maharashtra', 'Mumbai')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform M1 and M2 fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state, district in districts_to_show:\n",
    "    predictions_dict[(state, district)] = {}\n",
    "    predictions_dict[(state, district)]['m1'] = single_fitting_cycle(\n",
    "        dataframes, state, district, train_period=7, val_period=7, num_evals=5,\n",
    "        data_from_tracker=False, initialisation='intermediate', model=SEIR_Testing, \n",
    "        smooth_jump=True, smoothing_method='weighted', smoothing_length=20,\n",
    "        which_compartments=['hospitalised', 'total_infected', 'deceased', 'recovered'])\n",
    "    predictions_dict[(state, district)]['m2'] = single_fitting_cycle(\n",
    "        dataframes, state, district, train_period=7, val_period=0, num_evals=5,\n",
    "        data_from_tracker=False, initialisation='intermediate', model=SEIR_Testing, \n",
    "        smooth_jump=True, smoothing_method='weighted', smoothing_length=20,\n",
    "        which_compartments=['hospitalised', 'total_infected', 'deceased', 'recovered'])\n",
    "    \n",
    "    predictions_dict[(state, district)]['state'] = state\n",
    "    predictions_dict[(state, district)]['dist'] = district\n",
    "    predictions_dict[(state, district)]['fitting_date'] = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    predictions_dict[(state, district)]['datasource'] = 'covid19api' if predictions_dict[(state, district)]['m1']['data_from_tracker'] else 'municipality'\n",
    "    predictions_dict[(state, district)]['variable_param_ranges'] = predictions_dict[(state, district)]['m1']['variable_param_ranges']\n",
    "    predictions_dict[(state, district)]['data_last_date'] = predictions_dict[(state, district)]['m2']['data_last_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Master Loss Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M1 Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_key = list(predictions_dict.keys())[0]\n",
    "\n",
    "loss_columns = pd.MultiIndex.from_product([predictions_dict[starting_key]['m1']['df_loss'].columns, predictions_dict[starting_key]['m1']['df_loss'].index])\n",
    "loss_index = predictions_dict.keys()\n",
    "\n",
    "df_loss_master = pd.DataFrame(columns=loss_columns, index=loss_index)\n",
    "for key in predictions_dict.keys():\n",
    "    df_loss_master.loc[key, :] = np.around(predictions_dict[key]['m1']['df_loss'].values.T.flatten().astype('float'), decimals=2)\n",
    "    \n",
    "df_loss_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M2 Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_key = list(predictions_dict.keys())[0]\n",
    "\n",
    "loss_columns = pd.MultiIndex.from_product([predictions_dict[starting_key]['m2']['df_loss'].columns, predictions_dict[starting_key]['m2']['df_loss'].index])\n",
    "loss_index = predictions_dict.keys()\n",
    "\n",
    "df_loss_master = pd.DataFrame(columns=loss_columns, index=loss_index)\n",
    "for key in predictions_dict.keys():\n",
    "    df_loss_master.loc[key, :] = np.around(predictions_dict[key]['m2']['df_loss'].values.T.flatten().astype('float'), decimals=2)\n",
    "    \n",
    "df_loss_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in predictions_dict.keys():\n",
    "    predictions_dict[region]['forecast'] = plot_forecast(predictions_dict[region], region, both_forecasts=False, error_bars=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Report (v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in predictions_dict.keys():\n",
    "    create_report(predictions_dict[region])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Save Output CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = create_all_csvs(predictions_dict, icu_fraction=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(df_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Produce Top 10 Trials / Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 'm2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_array = []\n",
    "for trial in predictions_dict[(state, district)][m]['trials']:\n",
    "    params_dict = copy.copy(trial['misc']['vals'])\n",
    "    for key in params_dict.keys():\n",
    "        params_dict[key] = params_dict[key][0]\n",
    "    params_array.append(params_dict)\n",
    "params_array = np.array(params_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_array = np.array([trial['result']['loss'] for trial in predictions_dict[(state, district)][m]['trials']])\n",
    "least_losses_indices = np.argsort(losses_array)\n",
    "top10losses = losses_array[least_losses_indices][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10params = params_array[least_losses_indices[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10predictions = [get_forecast(predictions_dict[('Maharashtra', 'Mumbai')],\n",
    "                                  best_params=params_dict) for params_dict in top10params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "def plot_trials(m_dict, top10losses, top10params, top10predictions):\n",
    "    df_true = m_dict['df_district']\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    ax.plot(df_true['date'], df_true['total_infected'],\n",
    "            '-o', color='C0', label='Confirmed Cases (Observed)')\n",
    "    for i, df_prediction in enumerate(top10predictions):\n",
    "        loss_value = np.around(np.sort(top10losses)[:10][i], 2)\n",
    "        sns.lineplot(x=\"date\", y=\"total_infected\", data=df_prediction,\n",
    "                    ls='-', label='Confirmed Cases ({})'.format(loss_value))\n",
    "        plt.text(x=df_prediction['date'].iloc[-1], y=df_prediction['total_infected'].iloc[-1], s=loss_value)\n",
    "        \n",
    "    ax.xaxis.set_major_locator(mdates.DayLocator(interval=7))\n",
    "    ax.xaxis.set_minor_locator(mdates.DayLocator(interval=1))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    plt.ylabel('No of People', fontsize=16)\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Time', fontsize=16)\n",
    "    plt.legend()\n",
    "    plt.title('Forecast - ({} {})'.format(region[0], region[1]), fontsize=16)\n",
    "    #plt.grid()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in predictions_dict.keys():\n",
    "    predictions_dict[region][m]['top10params'] = top10params\n",
    "    predictions_dict[region][m]['forecast_top10'] = plot_trials(predictions_dict[region][m], top10losses, top10params, top10predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "for region in predictions_dict.keys():\n",
    "    t = time.time()\n",
    "    create_report(predictions_dict[region], ROOT_DIR=f'../../reports/{t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main.seir.fitting import get_regional_data \n",
    "\n",
    "orig_df_district, _ = get_regional_data(dataframes, 'Maharashtra', 'Mumbai', data_from_tracker=False, data_format='new', filename=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes\n",
    "state='Maharashtra'\n",
    "district='Mumbai'\n",
    "data_from_tracker=False\n",
    "smooth_jump=True\n",
    "smoothing_length=33\n",
    "smoothing_method='weighted'\n",
    "filename=None\n",
    "data_format='new'\n",
    "\n",
    "if data_from_tracker:\n",
    "    main_df_district = get_data(dataframes, state=state, district=district, use_dataframe='districts_daily')\n",
    "else:\n",
    "    main_df_district = get_data(state=state, district=district, disable_tracker=True, filename=filename, \n",
    "                            data_format=data_format)\n",
    "\n",
    "df_district_raw_data = get_data(dataframes, state=state, district=district, use_dataframe='raw_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_district=copy.copy(main_df_district)\n",
    "if smooth_jump:\n",
    "    if data_from_tracker:\n",
    "        d1, d2 = '2020-05-29', '2020-05-30'\n",
    "    else:\n",
    "        d1, d2 = '2020-05-28', '2020-05-29'\n",
    "    df_district = df_district.set_index('date')\n",
    "    big_jump = df_district.loc[d2, 'recovered'] - df_district.loc[d1, 'recovered']\n",
    "    print(big_jump)\n",
    "    if smoothing_method == 'linear':\n",
    "        for i, day_number in enumerate(range(smoothing_length-2, -1, -1)):\n",
    "            date = datetime.datetime.strptime(d1, '%Y-%m-%d') - datetime.timedelta(days=day_number)\n",
    "            offset = np.random.binomial(1, (big_jump%smoothing_length)/smoothing_length)\n",
    "            df_district.loc[date, 'recovered'] += ((i+1)*big_jump)//smoothing_length + offset\n",
    "            df_district.loc[date, 'hospitalised'] -= ((i+1)*big_jump)//smoothing_length + offset\n",
    "\n",
    "    elif smoothing_method == 'weighted':\n",
    "        newcases = df_district['total_infected'].shift(14) - df_district['total_infected'].shift(15)\n",
    "        idx = newcases.first_valid_index()\n",
    "        newcases = newcases.loc[idx:d1]\n",
    "        truncated = df_district.loc[idx:d1, :]\n",
    "        invpercent = newcases.sum()/newcases\n",
    "        runningsum = 0\n",
    "        for i, day_number in enumerate(range(smoothing_length-2, -1, -1)):\n",
    "            date = datetime.datetime.strptime(d1, '%Y-%m-%d') - datetime.timedelta(days=day_number)\n",
    "            print (date, (big_jump%invpercent.loc[date])/newcases.loc[date])\n",
    "            offset = np.random.binomial(1, (big_jump%invpercent.loc[date])/invpercent.loc[date])\n",
    "            runningsum += (big_jump // invpercent.loc[date]) + offset\n",
    "            truncated.loc[date:, 'recovered'] += (big_jump // invpercent.loc[date]) + offset\n",
    "            truncated.loc[date:, 'hospitalised'] -= (big_jump // invpercent.loc[date]) + offset\n",
    "            print(date, runningsum)\n",
    "        print(truncated.index)\n",
    "        df_district.loc[truncated.index, 'recovered'] = truncated['recovered'].astype('int64')\n",
    "        df_district.loc[truncated.index, 'hospitalised'] = truncated['hospitalised'].astype('int64')\n",
    "\n",
    "    assert((df_district['total_infected'] == df_district['hospitalised'] + df_district['deceased'] + df_district['recovered']).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = df_district\n",
    "orig = main_df_district.set_index('date')\n",
    "# print(pd.concat([new['hospitalised'],orig['hospitalised']], axis=1))\n",
    "print(new['recovered'] - orig['recovered'])\n",
    "# print(pd.concat([new['recovered'],orig['recovered']], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_district[44:][-10:]\n",
    "compare_cols = ['total_infected','hospitalised','deceased','recovered']\n",
    "# compare = (orig[compare_cols][-20:], new[compare_cols][-20:])\n",
    "# compare = (new[compare_cols][-20:])\n",
    "compare = (orig[compare_cols] - new[compare_cols])[-20:]\n",
    "print (compare)# df_district[44:][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti_check = copy.copy(orig['total_infected'])\n",
    "ti_check2 = copy.copy(new['total_infected'])\n",
    "for col in ['hospitalised', 'recovered', 'deceased']:\n",
    "    ti_check -= new[col]\n",
    "    ti_check2 -= new[col]\n",
    "print(pd.concat([ti_check[-25:], ti_check2[-25:]], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (covid)",
   "language": "python",
   "name": "covid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
