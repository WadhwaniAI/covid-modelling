{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "from scipy.stats import entropy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from hyperopt import tpe, rand\n",
    "\n",
    "import datetime\n",
    "\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from models.seir import SEIRHD\n",
    "\n",
    "from main.seir.fitting import single_fitting_cycle\n",
    "from main.seir.forecast import _order_trials_by_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Districts to fit on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, district = ('Maharashtra', 'Mumbai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_days = 54\n",
    "now = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "folder = str(now)\n",
    "ktrials = 10\n",
    "model=SEIRHD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform M1 and M2 fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict['m1'] = single_fitting_cycle(\n",
    "    state, district, train_period=21, val_period=0, num_evals=500,\n",
    "    data_from_tracker=False, initialisation='intermediate', model=model, \n",
    "    smooth_jump=True, algo=tpe,\n",
    "    which_compartments=['active', 'total', 'deceased', 'recovered'])\n",
    "\n",
    "predictions_dict['m2'] = single_fitting_cycle(\n",
    "    state, district, train_period=21, val_period=0, num_evals=1000,\n",
    "    data_from_tracker=False, initialisation='intermediate', model=model, \n",
    "    smooth_jump=True, algo=tpe,\n",
    "    which_compartments=['active', 'total', 'deceased', 'recovered'])\n",
    "\n",
    "predictions_dict['m3'] = single_fitting_cycle(\n",
    "    state, district, train_period=21, val_period=0, num_evals=1500,\n",
    "    data_from_tracker=False, initialisation='intermediate', model=model, \n",
    "    smooth_jump=True, algo=tpe,\n",
    "    which_compartments=['active', 'total', 'deceased', 'recovered'])\n",
    "\n",
    "predictions_dict['m4'] = single_fitting_cycle(\n",
    "    state, district, train_period=21, val_period=0, num_evals=2000,\n",
    "    data_from_tracker=False, initialisation='intermediate', model=model, \n",
    "    smooth_jump=True, algo=tpe,\n",
    "    which_compartments=['active', 'total', 'deceased', 'recovered'])\n",
    "\n",
    "predictions_dict['m5'] = single_fitting_cycle(\n",
    "    state, district, train_period=21, val_period=0, num_evals=2500,\n",
    "    data_from_tracker=False, initialisation='intermediate', model=model, \n",
    "    smooth_jump=True, algo=tpe,\n",
    "    which_compartments=['active', 'total', 'deceased', 'recovered'])\n",
    "\n",
    "predictions_dict['m6'] = single_fitting_cycle(\n",
    "    state, district, train_period=21, val_period=0, num_evals=3000,\n",
    "    data_from_tracker=False, initialisation='intermediate', model=model, \n",
    "    smooth_jump=True, algo=tpe,\n",
    "    which_compartments=['active', 'total', 'deceased', 'recovered'])\n",
    "\n",
    "predictions_dict['m7'] = single_fitting_cycle(\n",
    "    state, district, train_period=21, val_period=0, num_evals=3500,\n",
    "    data_from_tracker=False, initialisation='intermediate', model=model, \n",
    "    smooth_jump=True, algo=tpe,\n",
    "    which_compartments=['active', 'total', 'deceased', 'recovered'])\n",
    "\n",
    "predictions_dict['m8'] = single_fitting_cycle(\n",
    "    state, district, train_period=21, val_period=0, num_evals=4000,\n",
    "    data_from_tracker=False, initialisation='intermediate', model=model, \n",
    "    smooth_jump=True, algo=tpe,\n",
    "    which_compartments=['active', 'total', 'deceased', 'recovered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dicts = {}\n",
    "weights_dict = {}\n",
    "for key in predictions_dict.keys():\n",
    "    params_array, losses_array = _order_trials_by_loss(predictions_dict[key])\n",
    "    params_dicts[key] = {param: [param_dict[param] for param_dict in params_array] for param in params_array[0].keys()}\n",
    "    weights_dict[key] = np.exp(-np.array(losses_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    'E_hosp_ratio': scipy.stats.expon,\n",
    "    'I_hosp_ratio': scipy.stats.gamma,\n",
    "    'P_fatal': scipy.stats.beta,\n",
    "    'T_inc': scipy.stats.norm,\n",
    "    'T_inf': scipy.stats.norm,\n",
    "    'T_recov_fatal': scipy.stats.norm,\n",
    "    'T_recov_severe': scipy.stats.norm,\n",
    "    'lockdown_R0': scipy.stats.norm\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for run in params_dicts.keys():\n",
    "    fig, axs = plt.subplots(nrows=len(param_distributions)//2, ncols=2, figsize=(18, 6*(len(param_distributions)//2)))\n",
    "    for i, param in enumerate(params_dicts[run].keys()):\n",
    "        ax = axs.flat[i]\n",
    "        ax.hist(params_dicts[run][param], density=True, histtype='bar')\n",
    "        ax.set_title(f'Historgram of parameter {param} for run {run}')\n",
    "        ax.set_ylabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_histograms_and_plot(plot_lines=False, weighted=True, savefig=False, filename=''):\n",
    "    histograms = {}\n",
    "    fig, axs = plt.subplots(nrows=len(param_distributions)//2, ncols=2, figsize=(18, 6*(len(param_distributions)//2)))\n",
    "    for run in params_dicts.keys():\n",
    "        histograms[run] = {}\n",
    "        for i, param in enumerate(params_dicts[run].keys()):\n",
    "            histograms[run][param] = {}\n",
    "            ax = axs.flat[i]\n",
    "            if plot_lines:\n",
    "                bar_heights, endpoints = np.histogram(params_dicts[run][param], density=True, bins=20, weights=weights_dict[run])\n",
    "                centers = (endpoints[1:] + endpoints[:-1]) / 2\n",
    "                ax.plot(centers, bar_heights, label=f'{int(run[-1])*500} samples')\n",
    "            else:\n",
    "                if weighted:\n",
    "                    histogram = ax.hist(params_dicts[run][param], density=True, histtype='bar', bins=20, \n",
    "                                        weights=weights_dict[run], label=f'{int(run[-1])*500} samples', alpha=1)  \n",
    "                else:\n",
    "                    histogram = ax.hist(params_dicts[run][param], density=True, histtype='bar', bins=20, \n",
    "                                        label=f'{int(run[-1])*500} samples', alpha=1)  \n",
    "                bar_heights, endpoints = histogram[0], histogram[1]\n",
    "                centers = (endpoints[1:] + endpoints[:-1]) / 2\n",
    "                \n",
    "            histograms[run][param]['density'] = bar_heights\n",
    "            histograms[run][param]['endpoints'] = endpoints\n",
    "            histograms[run][param]['probability'] = bar_heights*np.mean(np.diff(endpoints))\n",
    "            \n",
    "            ax.set_title(f'Historgram of parameter {param}')\n",
    "            ax.set_ylabel('Density')\n",
    "\n",
    "    for ax in axs.flat:\n",
    "        ax.legend()\n",
    "    if savefig:\n",
    "        fig.savefig(filename)\n",
    "    return fig, histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, histograms = create_histograms_and_plot(weighted=False, savefig=False, filename='constrainted-unweighted-histogram.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, histograms = create_histograms_and_plot(weighted=True, savefig=False, filename='constrainted-weighted-histogram.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=len(params_dicts['m1'])//2, ncols=2, figsize=(18, 6*(len(params_dicts['m1'])//2)))\n",
    "for i, param in enumerate(params_dicts['m1'].keys()):\n",
    "    ax = axs.flat[i]\n",
    "    kl_matrix = np.array([[entropy(histograms[run1][param]['probability'], histograms[run2][param]['probability']) for run2 in histograms.keys()] for run1 in histograms.keys()])\n",
    "    sns.heatmap(kl_matrix, annot=True, xticklabels = np.arange(1, kl_matrix.shape[0]+1)*500, yticklabels = np.arange(1, kl_matrix.shape[0]+1)*500, vmax=10, ax=ax)\n",
    "    ax.set_title(f'KL Divergence matrix of parameter {param}')\n",
    "plt.show()\n",
    "# fig.savefig('constrained-kl-matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_mean_var = copy.deepcopy(params_dicts)\n",
    "for run in params_mean_var.keys():\n",
    "    for param in params_mean_var[run].keys():\n",
    "        params_mean_var[run][param] = np.std(params_mean_var[run][param])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(params_mean_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in params_dicts.keys():\n",
    "    fig, axs = plt.subplots(nrows=len(param_distributions)//2, ncols=2, figsize=(18, 6*(len(param_distributions)//2)))\n",
    "    for i, param in enumerate(params_dicts[run].keys()):\n",
    "        dist = param_distributions[param]\n",
    "        param_trials = params_dicts[run][param]\n",
    "        dist_fit = dist.fit(param_trials)\n",
    "        sampling_points = np.linspace(np.min(param_trials), np.max(param_trials), len(param_trials))\n",
    "        pdf_fitted = dist.pdf(sampling_points, *dist_fit[:-2], loc=dist_fit[-2], scale=dist_fit[-1])\n",
    "        \n",
    "        ax = axs.flat[i]\n",
    "        ax.hist(params_dicts[run][param], density=True)\n",
    "        ax.plot(sampling_points, pdf_fitted)\n",
    "        ax.set_title(f'Historgram of parameter {param} for run {run}')\n",
    "        ax.set_ylabel('Density')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
