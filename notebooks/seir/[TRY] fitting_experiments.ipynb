{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "\n",
    "import datetime\n",
    "import copy\n",
    "import json\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from data.dataloader import Covid19IndiaLoader\n",
    "from data.processing import get_data\n",
    "from data.processing.whatifs import scale_up_acc_to_testing\n",
    "\n",
    "from models.seir import SEIRHD, SEIR_Testing, SEIR_Movement, SEIR_Movement_Testing\n",
    "\n",
    "from main.seir.fitting import single_fitting_cycle, get_variable_param_ranges\n",
    "from main.seir.uncertainty import MCUncertainty\n",
    "from main.seir.optimiser import Optimiser\n",
    "from main.seir.forecast import get_forecast, create_region_csv, create_all_csvs, write_csv, forecast_all_trials, trials_to_df, scale_up_testing_and_forecast\n",
    "from main.seir.sensitivity import gridsearch_single_param, calculate_sensitivity_and_plot\n",
    "\n",
    "from utils.create_report import create_report\n",
    "from utils.loss import Loss_Calculator\n",
    "from utils.enums import Columns\n",
    "from utils.enums.columns import *\n",
    "\n",
    "from viz import plot_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Districts to fit on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, district = ('Maharashtra', 'Mumbai')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_of_interest = '2020-07-31'\n",
    "forecast_days = 37\n",
    "now = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "folder = str(now)\n",
    "ktrials = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform M1 and M2 fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict['m1'] = single_fitting_cycle(\n",
    "    state, district, data_from_tracker=True, granular_data=False, filename=None, #Data\n",
    "    model=SEIRHD, #Choose Model and Ranges\n",
    "    train_period=21, val_period=30, num_evals=1000, initialisation='intermediate', #Optimisation related parameters\n",
    "    which_compartments=['total_infected', 'hospitalised', 'recovered', 'deceased'], #Compartments to Apply Loss on \n",
    "    smooth_jump=True)\n",
    "\n",
    "predictions_dict['state'] = state\n",
    "predictions_dict['dist'] = district\n",
    "predictions_dict['fitting_date'] = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "predictions_dict['datasource'] = 'covid19api' if predictions_dict['m1']['data_from_tracker'] else 'municipality'\n",
    "predictions_dict['variable_param_ranges'] = predictions_dict['m1']['variable_param_ranges']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M1 Loss DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict['m1']['df_loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M2 Loss DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict['m2']['df_loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in predictions_dict.keys():\n",
    "    predictions_dict[region]['m2']['df_forecast'] = get_forecast(predictions_dict[region], days=forecast_days)\n",
    "    predictions_dict[region]['m2']['forecast'] = plot_forecast(predictions_dict[region], region, both_forecasts=False, error_bars=True, days=forecast_days)\n",
    "    \n",
    "    predictions, losses, params = get_all_trials(predictions_dict[region], train_fit='m1')\n",
    "    predictions_dict[region]['m1']['params'] = params\n",
    "    predictions_dict[region]['m1']['losses'] = losses\n",
    "    predictions_dict[region]['m1']['predictions'] = predictions\n",
    "    predictions_dict[region]['m1']['all_trials'] = trials_to_df(predictions, losses, params)\n",
    "\n",
    "    predictions, losses, params = get_all_trials(predictions_dict[region], train_fit='m2')\n",
    "    predictions_dict[region]['m2']['params'] = params\n",
    "    predictions_dict[region]['m2']['losses'] = losses\n",
    "    predictions_dict[region]['m2']['predictions'] = predictions\n",
    "    predictions_dict[region]['m2']['all_trials'] = trials_to_df(predictions, losses, params)\n",
    "    kforecasts = plot_trials(\n",
    "        predictions_dict[region],\n",
    "        train_fit='m2',\n",
    "        predictions=predictions, \n",
    "        losses=losses, params=params, \n",
    "        k=ktrials,\n",
    "        which_compartments=[Columns.confirmed, Columns.active])\n",
    "    predictions_dict[region]['m2']['forecast_confirmed_topk'] = kforecasts[Columns.confirmed]\n",
    "    predictions_dict[region]['m2']['forecast_active_topk'] = kforecasts[Columns.active]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_dict = predictions_dict[('Maharashtra', 'Mumbai')]\n",
    "uncertainty = MCUncertainty(region_dict, date_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty.beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in predictions_dict.keys():\n",
    "    create_report(predictions_dict[region], ROOT_DIR=output_folder)\n",
    "    predictions_dict[region]['m1']['all_trials'].to_csv(os.path.join(output_folder, 'm1-trials.csv'))\n",
    "    predictions_dict[region]['m2']['all_trials'].to_csv(os.path.join(output_folder, 'm2-trials.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Save Output CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = create_all_csvs(predictions_dict, icu_fraction=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(df_output, filename=os.path.join(output_folder, f'output-{t}.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_processed = forecast_all_trials(predictions_dict, train_fit='m1', forecast_days=forecast_days)\n",
    "predictions_dict['m1']['trials_processed'] = trials_processed\n",
    "predictions_dict['m1']['all_trials'] = trials_to_df(trials_processed, column=Columns.confirmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict['m1']['all_trials'].to_csv('m1-trials.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_array = predictions_dict['m1']['all_trials']['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_fulldict = predictions_dict['m1']['all_trials']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.367\n",
    "R0means=[]\n",
    "R0stdevs=[]\n",
    "Pfatalmeans=[]\n",
    "Pfatalstdevs=[]\n",
    "Tinfmeans=[]\n",
    "Tinfstdevs=[]\n",
    "Tincmeans=[]\n",
    "Tincstdevs=[]\n",
    "Trsmeans=[]\n",
    "Trsstdevs=[]\n",
    "Trfmeans=[]\n",
    "Trfstdevs=[]\n",
    "\n",
    "Loss_norm=0\n",
    "R0sum=0\n",
    "R0sqsum=0\n",
    "Pfatal_sum=0\n",
    "Pfatal_sqsum=0\n",
    "Tinf_sum=0\n",
    "Tinf_sqsum=0\n",
    "Tinc_sum=0\n",
    "Tinc_sqsum=0\n",
    "Trs_sum=0\n",
    "Trs_sqsum=0\n",
    "Trf_sum=0\n",
    "Trf_sqsum=0\n",
    "\n",
    "tempdict = params_fulldict\n",
    "templosses = losses_array\n",
    "for k in range(len(tempdict)):\n",
    "    Loss_norm += np.exp(-beta*templosses[k])\n",
    "    R0sum += np.exp(-beta*templosses[k])*tempdict['lockdown_R0'][k]\n",
    "    R0sqsum += np.exp(-beta*templosses[k])*tempdict['lockdown_R0'][k]**2\n",
    "    Pfatal_sum += np.exp(-beta*templosses[k])*tempdict['P_fatal'][k]\n",
    "    Pfatal_sqsum += np.exp(-beta*templosses[k])*tempdict['P_fatal'][k]**2\n",
    "    Tinf_sum += np.exp(-beta*templosses[k])*tempdict['T_inf'][k]\n",
    "    Tinf_sqsum += np.exp(-beta*templosses[k])*tempdict['T_inf'][k]**2\n",
    "    Tinc_sum += np.exp(-beta*templosses[k])*tempdict['T_inc'][k]\n",
    "    Tinc_sqsum += np.exp(-beta*templosses[k])*tempdict['T_inc'][k]**2\n",
    "    Trs_sum += np.exp(-beta*templosses[k])*tempdict['T_recov_severe'][k]\n",
    "    Trs_sqsum += np.exp(-beta*templosses[k])*tempdict['T_recov_severe'][k]**2\n",
    "    Trf_sum += np.exp(-beta*templosses[k])*tempdict['T_recov_fatal'][k]\n",
    "    Trf_sqsum += np.exp(-beta*templosses[k])*tempdict['T_recov_fatal'][k]**2\n",
    "R0means.append(R0sum/Loss_norm)\n",
    "R0stdevs.append(np.sqrt(R0sqsum/Loss_norm-(R0sum/Loss_norm)**2))\n",
    "Pfatalmeans.append(Pfatal_sum/Loss_norm)\n",
    "Pfatalstdevs.append(np.sqrt(Pfatal_sqsum/Loss_norm-(Pfatal_sum/Loss_norm)**2))\n",
    "Tinfmeans.append(Tinf_sum/Loss_norm)\n",
    "Tinfstdevs.append(np.sqrt(Tinf_sqsum/Loss_norm-(Tinf_sum/Loss_norm)**2))\n",
    "Tincmeans.append(Tinc_sum/Loss_norm)\n",
    "Tincstdevs.append(np.sqrt(Tinc_sqsum/Loss_norm-(Tinc_sum/Loss_norm)**2))\n",
    "Trsmeans.append(Trs_sum/Loss_norm)\n",
    "Trsstdevs.append(np.sqrt(Trs_sqsum/Loss_norm-(Trs_sum/Loss_norm)**2))\n",
    "Trfmeans.append(Trf_sum/Loss_norm)\n",
    "Trfstdevs.append(np.sqrt(Trf_sqsum/Loss_norm-(Trf_sum/Loss_norm)**2))\n",
    "\n",
    "param_mean=[R0means, Pfatalmeans, Tinfmeans, Tincmeans, Trsmeans, Trfmeans]\n",
    "param_stdev=[R0stdevs, Pfatalstdevs, Tinfstdevs, Tincstdevs, Trsstdevs, Trfstdevs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
