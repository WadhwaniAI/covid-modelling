{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "from utils.generic import init_params\n",
    "from main.seir.optimiser import Optimiser\n",
    "from models.seir.seir_testing import SEIR_Testing\n",
    "from data.processing import get_district_time_series\n",
    "from data.dataloader import get_covid19india_api_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load covid19 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = get_covid19india_api_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_district = get_district_time_series(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Make splits\n",
    "df_train = df_district"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Calculation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calc_rmse(y_pred, y_true, log=True):\n",
    "    if log:\n",
    "        y_true = np.log(y_true)\n",
    "        y_pred = np.log(y_pred)\n",
    "    loss = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "    return loss\n",
    "\n",
    "def _calc_mape(y_pred, y_true):\n",
    "    y_pred = y_pred[y_true > 0]\n",
    "    y_true = y_true[y_true > 0]\n",
    "\n",
    "    ape = np.abs((y_true - y_pred + 0) / y_true) *  100\n",
    "    loss = np.mean(ape)\n",
    "    return loss\n",
    "\n",
    "def calc_loss_dict(states_time_matrix, df, method='rmse', rmse_log=False):\n",
    "    pred_hospitalisations = states_time_matrix[6] + states_time_matrix[7] + states_time_matrix[8]\n",
    "    pred_recoveries = states_time_matrix[9]\n",
    "    pred_fatalities = states_time_matrix[10]\n",
    "    pred_infectious_unknown = states_time_matrix[2] + states_time_matrix[4]\n",
    "    pred_total_cases = pred_hospitalisations + pred_recoveries + pred_fatalities\n",
    "    \n",
    "    if method == 'rmse':\n",
    "        if rmse_log:\n",
    "            calculate = lambda x, y : _calc_rmse(x, y)\n",
    "        else:\n",
    "            calculate = lambda x, y : _calc_rmse(x, y, log=False)\n",
    "    \n",
    "    if method == 'mape':\n",
    "            calculate = lambda x, y : _calc_mape(x, y)\n",
    "    \n",
    "    losses = {}\n",
    "#     losses['hospitalised'] = calculate(pred_hospitalisations, df['Hospitalised'])\n",
    "#     losses['recovered'] = calculate(pred_recoveries, df['Recovered'])\n",
    "#     losses['fatalities'] = calculate(pred_fatalities, df['Fatalities'])\n",
    "#     losses['active_infections'] = calculate(pred_infectious_unknown, df['Active Infections (Unknown)'])\n",
    "    losses['total'] = calculate(pred_total_cases, df['total_infected'])\n",
    "    \n",
    "    return losses\n",
    "\n",
    "def calc_loss(states_time_matrix, df, method='rmse', rmse_log=False):\n",
    "    losses = calc_loss_dict(states_time_matrix, df, method, rmse_log)\n",
    "#     loss = losses['hospitalised'] + losses['recovered'] + losses['total'] + losses['active_infections']\n",
    "    loss = losses['total']\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize params and state values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_params, testing_params, state_init_values = init_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_init_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set priors for parameters of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## assuming uniform priors, following dictionary contains the ranges\n",
    "prior_ranges = OrderedDict()\n",
    "prior_ranges['R0'] = (1.6, 3)\n",
    "prior_ranges['T_inc'] = (4, 5)\n",
    "prior_ranges['T_inf'] = (3, 4)\n",
    "prior_ranges['T_recov_severe'] = (9, 20)\n",
    "prior_ranges['P_severe'] = (0.3, 0.99)\n",
    "prior_ranges['intervention_amount'] = (0.3, 1)\n",
    "\n",
    "def param_init():\n",
    "    theta = defaultdict()\n",
    "    for key in prior_ranges:\n",
    "        theta[key] = np.random.uniform(prior_ranges[key][0], prior_ranges[key][1])\n",
    "        \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposal function to sample theta_new given theta_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stddevs for all params are set to 1 now. must tune later.\n",
    "proposal_sigmas = OrderedDict()\n",
    "proposal_sigmas['R0'] = 1\n",
    "proposal_sigmas['T_inc'] = 1\n",
    "proposal_sigmas['T_inf'] = 1\n",
    "proposal_sigmas['T_recov_severe'] = 5\n",
    "proposal_sigmas['P_severe'] = 1\n",
    "proposal_sigmas['intervention_amount'] = 1\n",
    "\n",
    "def proposal(theta_old):\n",
    "    theta_new = np.random.normal(loc=[*theta_old.values()], scale=[*proposal_sigmas.values()])\n",
    "    return dict(zip(theta_old.keys(), theta_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Likelihood and Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(theta):\n",
    "    alpha = 0.01\n",
    "    optimiser = Optimiser()\n",
    "    default_params = optimiser.init_default_params(df_train)\n",
    "    df_prediction = optimiser.solve(theta, default_params, df_train)\n",
    "    pred = np.array(df_prediction['total_infected'])\n",
    "    true = np.array(df_train['total_infected'])\n",
    "    sigma = alpha * true.std()\n",
    "    N = len(true)\n",
    "    ll = - (N * np.log(np.sqrt(2*np.pi) * sigma)) - (np.sum(((true - pred) ** 2) / (2 * sigma ** 2)))\n",
    "    return ll\n",
    "\n",
    "def log_prior(theta):\n",
    "    prior = 1\n",
    "    for key in prior_ranges:\n",
    "        if theta[key] > 0:\n",
    "            prior *= 1 / (prior_ranges[key][1] - prior_ranges[key][0])\n",
    "        else:\n",
    "            prior = 0\n",
    "            break\n",
    "    \n",
    "    return np.log(prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acceptance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accept(theta_old, theta_new):    \n",
    "    x_new = log_likelihood(theta_new) + log_prior(theta_new)\n",
    "    x_old = log_likelihood(theta_old) + log_prior(theta_old)\n",
    "    \n",
    "    if (x_new) > (x_old):\n",
    "        return True\n",
    "    else:\n",
    "        x = np.random.uniform(0, 1)\n",
    "        return (x < np.exp(x_new - x_old))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolis loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis(iter=1000):\n",
    "    theta = param_init()\n",
    "    accepted = [theta]\n",
    "    rejected = list()\n",
    "    \n",
    "    for i in tqdm(range(iter)):\n",
    "        theta_new = proposal(theta)\n",
    "        if accept(theta, theta_new):\n",
    "            theta = theta_new\n",
    "        else:\n",
    "            rejected.append(theta_new)\n",
    "        accepted.append(theta)\n",
    "    \n",
    "    return accepted, rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, rej = metropolis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.DataFrame(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(list(range(len(samples['R0']))), samples['R0'], s=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covid",
   "language": "python",
   "name": "covid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
