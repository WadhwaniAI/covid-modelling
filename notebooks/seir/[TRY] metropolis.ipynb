{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "np.random.seed(10)\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "from datetime import datetime\n",
    "from joblib import delayed, Parallel\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "from utils.generic import init_params\n",
    "from main.seir.optimiser import Optimiser\n",
    "from models.seir.seir_testing import SEIR_Testing\n",
    "from data.processing import get_district_time_series\n",
    "from data.dataloader import get_covid19india_api_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load covid19 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "dataframes = get_covid19india_api_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [('Delhi', 'South Delhi'), ('Karnataka', 'Bengaluru Urban'), ('Maharashtra', 'Mumbai'), ('Maharashtra', 'Pune'), ('Gujarat', 'Ahmedabad'), ('Rajasthan', 'Jaipur')]\n",
    "state, district = regions[3]\n",
    "df_district = get_district_time_series(dataframes, state=state, district=district, use_dataframe = 'districts_daily')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train-val splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df_district\n",
    "df_train = df_district.iloc[:-5, :]\n",
    "df_val = df_district.iloc[-5:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set priors for parameters of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## assuming uniform priors, following dictionary contains the ranges\n",
    "prior_ranges = OrderedDict()\n",
    "prior_ranges['R0'] = (1.6, 5)\n",
    "prior_ranges['T_inc'] = (4, 5)\n",
    "prior_ranges['T_inf'] = (3, 4)\n",
    "prior_ranges['T_recov_severe'] = (9, 20)\n",
    "prior_ranges['P_severe'] = (0.3, 0.99)\n",
    "prior_ranges['P_fatal'] = (1e-10, 0.3)\n",
    "prior_ranges['intervention_amount'] = (1e-10, 1)\n",
    "prior_ranges['sigma'] = (0, 1)\n",
    "\n",
    "def param_init(prior_ranges):\n",
    "    theta = defaultdict()\n",
    "    for key in prior_ranges:\n",
    "        theta[key] = np.random.uniform(prior_ranges[key][0], prior_ranges[key][1])\n",
    "        \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposal function to sample theta_new given theta_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_sigmas = OrderedDict()\n",
    "proposal_sigmas['R0'] = 20\n",
    "proposal_sigmas['T_inc'] = np.exp(10)\n",
    "proposal_sigmas['T_inf'] = np.exp(10)\n",
    "proposal_sigmas['T_recov_severe'] = np.exp(100)\n",
    "proposal_sigmas['P_severe'] = 10\n",
    "proposal_sigmas['P_fatal'] = 10\n",
    "proposal_sigmas['intervention_amount'] = 10\n",
    "proposal_sigmas['sigma'] = 10\n",
    "\n",
    "def proposal(theta_old, proposal_sigmas):\n",
    "    theta_new = [np.nan]\n",
    "    \n",
    "    while np.isnan(theta_new).any():\n",
    "        theta_new = np.random.normal(loc=np.exp([*theta_old.values()]), scale=[*proposal_sigmas.values()])\n",
    "        theta_new = np.log(theta_new)\n",
    "    \n",
    "    return dict(zip(theta_old.keys(), theta_new))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = param_init(prior_ranges)\n",
    "new_theta = proposal(theta, proposal_sigmas)\n",
    "for key in theta:\n",
    "    print(key, theta[key], new_theta[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Likelihood and Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(theta, df_train, fit_days=-10):\n",
    "    if (np.array([*theta.values()]) < 0).any():\n",
    "        return -np.inf\n",
    "    optimiser = Optimiser()\n",
    "    default_params = optimiser.init_default_params(df_train)\n",
    "    df_prediction = optimiser.solve(theta, default_params, df_train)\n",
    "    pred = np.array(df_prediction['total_infected'][fit_days:])\n",
    "    true = np.array(df_train['total_infected'][fit_days:])\n",
    "    sigma = theta['sigma']\n",
    "    N = len(true)\n",
    "    ll = - (N * np.log(np.sqrt(2*np.pi) * sigma)) - (np.sum(((true - pred) ** 2) / (2 * sigma ** 2)))\n",
    "    return ll\n",
    "\n",
    "def log_prior(theta):\n",
    "    if (np.array([*theta.values()]) < 0).any():\n",
    "        prior = 0\n",
    "    else:\n",
    "        prior = 1\n",
    "    \n",
    "    return np.log(prior)\n",
    "\n",
    "def in_valid_range(key, value):\n",
    "    return (value <= prior_ranges[key][1]) and (value >= prior_ranges[key][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acceptance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accept(theta_old, theta_new, df_train):    \n",
    "    x_new = log_likelihood(theta_new, df_train) + log_prior(theta_new)\n",
    "    x_old = log_likelihood(theta_old, df_train) + log_prior(theta_old)\n",
    "    \n",
    "    if (x_new) > (x_old):\n",
    "        return True\n",
    "    else:\n",
    "        x = np.random.uniform(0, 1)\n",
    "        return (x < np.exp(x_new - x_old))\n",
    "    \n",
    "def anneal_accept(iter):\n",
    "    prob = 1 - np.exp(-(1/(iter + 1e-10)))\n",
    "    x = np.random.uniform(0, 1)\n",
    "    return (x < prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolis loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis(prior_ranges, proposal_sigmas, df_train, iter=1000):\n",
    "    theta = param_init(prior_ranges)\n",
    "    accepted = [theta]\n",
    "    rejected = list()\n",
    "    \n",
    "    for i in tqdm(range(iter)):\n",
    "        theta_new = proposal(theta, proposal_sigmas)\n",
    "        if accept(theta, theta_new, df_train):\n",
    "            theta = theta_new\n",
    "        else:\n",
    "            rejected.append(theta_new)\n",
    "        accepted.append(theta)\n",
    "    \n",
    "    return accepted, rejected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Interval calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PI(pred_dfs, date, key, multiplier=1.96):\n",
    "    pred_samples = list()\n",
    "    for df in pred_dfs:\n",
    "        pred_samples.append(df.loc[date, key])\n",
    "        \n",
    "    mu = np.array(pred_samples).mean()\n",
    "    sigma = np.array(pred_samples).std()\n",
    "    low = mu - multiplier*sigma\n",
    "    high = mu + multiplier*sigma\n",
    "    return mu, low, high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run multiple chains in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chains = 5\n",
    "mcmc = Parallel(n_jobs=mp.cpu_count())(delayed(metropolis)(prior_ranges, proposal_sigmas, df_train, iter=20000) for run in range(n_chains))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Checking validity with Gelman-Rubin statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Section 4.2 [here](http://www.columbia.edu/~mh2078/MachineLearningORFE/MCMC_Bayes.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate(dict_list):\n",
    "    accumulator = defaultdict(int)\n",
    "    for elt in dict_list:\n",
    "        for key in elt:\n",
    "            accumulator[key]+=elt[key]\n",
    "    return accumulator\n",
    "\n",
    "def divide(dictvar, num):\n",
    "    return {key:dictvar[key]/num for key in dictvar}\n",
    "\n",
    "            \n",
    "def avg_sum_chain(chain):\n",
    "    chain_sums_avg = accumulate(chain)\n",
    "    return divide(chain_sums_avg, len(chain))\n",
    "\n",
    "def avg_sum_multiple_chains(chain_sums_avg):\n",
    "    multiple_chain_sums_avg = accumulate(chain_sums_avg)\n",
    "    return divide(multiple_chain_sums_avg, len(chain_sums_avg))\n",
    "\n",
    "def compute_B(multiple_chain_sums_avg, chain_sums_avg, n, m):\n",
    "    B = defaultdict(int)\n",
    "    for elt in chain_sums_avg:\n",
    "        for key in elt:\n",
    "            B[key] += np.square(elt[key] - multiple_chain_sums_avg[key])\n",
    "    return divide(B, (m-1)/n)\n",
    "\n",
    "def compute_W(split_chains, chain_sums_avg, n, m):\n",
    "    s = []\n",
    "    for j in range(m):\n",
    "        s_j_sq = defaultdict(int)\n",
    "        chain = split_chains[j]\n",
    "        chain_sum_avg_j = chain_sums_avg[j]\n",
    "        for i in range(n):\n",
    "            chain_elt = chain[i]\n",
    "            for key in chain_elt:\n",
    "                s_j_sq[key] += np.square(chain_elt[key] - chain_sum_avg_j [key])\n",
    "        s_j_sq = divide(s_j_sq, n - 1)\n",
    "        s.append(s_j_sq)\n",
    "    return (divide (accumulate(s),m))\n",
    "\n",
    "def divide_dict(d1, d2):\n",
    "    accumulator = defaultdict(int)\n",
    "    for key in d1:\n",
    "        accumulator[key] = d1[key]/d2[key]\n",
    "    return accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burn_in = int(len(mcmc[0][0]) / 2)\n",
    "chains = [mcmc_chain[0] for mcmc_chain in mcmc]\n",
    "burn_in = int(len(chains[0]) / 2)\n",
    "sampled_chains = [chain[:burn_in] for chain in chains]\n",
    "split_chains = [sampled_chain[int(burn_in/2):] for sampled_chain in sampled_chains] \\\n",
    "            + [sampled_chain[:int(burn_in/2)] for sampled_chain in sampled_chains]\n",
    "\n",
    "chain_sums_avg = []\n",
    "for chain in split_chains:\n",
    "    chain_sums_avg.append(avg_sum_chain(chain))\n",
    "multiple_chain_sums_avg = avg_sum_multiple_chains(chain_sums_avg) \n",
    "\n",
    "\n",
    "m = len(split_chains)\n",
    "n = len(split_chains[0])\n",
    "W =  compute_W(split_chains, chain_sums_avg, n, m)\n",
    "B =  compute_B(multiple_chain_sums_avg, chain_sums_avg, n, m)\n",
    "var_hat = accumulate([divide(W, n/(n-1)), divide(B, n) ])\n",
    "R_hat_sq = divide_dict(var_hat, W)\n",
    "R_hat = {key:np.sqrt(value) for key, value in R_hat_sq.items()}\n",
    "neff = divide_dict(var_hat, B)\n",
    "neff = {key: m*n*value for key, value in neff.items()}\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "# pp.pprint(neff)\n",
    "pp.pprint(R_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the samples and intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(compartments: list, end_date: str = None): \n",
    "    data_split = pd.concat([df_train, df_val])\n",
    "    optimiser = Optimiser()\n",
    "    default_params = optimiser.init_default_params(data_split)\n",
    "    \n",
    "    combined_acc = list()\n",
    "    for k, run in enumerate(mcmc):\n",
    "        burn_in = int(len(run) / 2)\n",
    "        combined_acc += run[0][burn_in:]\n",
    "\n",
    "    n_samples = 1000\n",
    "    sample_indices = np.random.uniform(0, len(combined_acc), n_samples)\n",
    "\n",
    "    pred_dfs = list()\n",
    "    for i in tqdm(sample_indices):\n",
    "        pred_dfs.append(optimiser.solve(combined_acc[int(i)], default_params, data_split, end_date=end_date))\n",
    "\n",
    "    for df in pred_dfs:\n",
    "        df.set_index('date', inplace=True)\n",
    "\n",
    "    result = pred_dfs[0].copy()\n",
    "    for col in result.columns:\n",
    "        result[\"{}_low\".format(col)] = ''\n",
    "        result[\"{}_high\".format(col)] = ''\n",
    "\n",
    "    for date in tqdm(pred_dfs[0].index):\n",
    "        for key in pred_dfs[0]:\n",
    "            result.loc[date, key], result.loc[date, \"{}_low\".format(key)], result.loc[date, \"{}_high\".format(key)] = get_PI(pred_dfs, date, key)\n",
    "\n",
    "    data_split.set_index(\"date\", inplace=True)\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    train_start_date = df_train.iloc[-10, :]['date']\n",
    "    train_end_date = df_train.iloc[-1, :]['date']\n",
    "    \n",
    "    actual = data_split[data_split.index >= train_start_date]\n",
    "    pred = result[result.index >= train_start_date]\n",
    "    \n",
    "    color = plt.cm.rainbow(np.linspace(0,1,len(compartments)))\n",
    "\n",
    "    for i, bucket in enumerate(compartments):\n",
    "        plt.plot(actual.index.array, actual[bucket].tolist(), c=color[i], marker='o', label='Actual {}'.format(bucket))\n",
    "        plt.plot(pred.index.array, pred[bucket].tolist(), c=color[i], label='Estimated {}'.format(bucket))\n",
    "        plt.plot(pred.index.array, pred['{}_low'.format(bucket)].tolist(), c=color[i], linestyle='dashdot')\n",
    "        plt.plot(pred.index.array, pred['{}_high'.format(bucket)].tolist(), c=color[i], linestyle='dashdot')\n",
    "    plt.axvline(x=train_end_date, c='k', linestyle='dashed', label='train ends')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend()\n",
    "    plt.title(\"95% confidence intervals for {}, {}\".format(district, state))\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig('./mcmc_confidence_intervals_{}_{}.png'.format(district, state))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compartments = [\"total_infected\"]#, \"hospitalised\", \"recovered\", \"deceased\"]\n",
    "visualize(compartments, end_date=\"2020-06-24\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize all runs separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_runs(df_district, mcmc, district, state):\n",
    "    plt.figure(figsize=(30, 50))\n",
    "\n",
    "    for k, run in enumerate(mcmc):\n",
    "        data_split = df_district.copy()\n",
    "        optimiser = Optimiser()\n",
    "        default_params = optimiser.init_default_params(data_split)\n",
    "\n",
    "        acc, rej = run[0], run[1]\n",
    "        df_samples = pd.DataFrame(acc)\n",
    "\n",
    "        plt.subplot(len(mcmc), 3, 3*k + 1)\n",
    "        for param in df_samples.columns:\n",
    "            plt.plot(list(range(len(df_samples[param]))), df_samples[param], label=param)\n",
    "        plt.xlabel(\"iterations\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Accepted samples from run {}\".format(k+1))\n",
    "\n",
    "        rej_samples = pd.DataFrame(rej)\n",
    "\n",
    "        plt.subplot(len(mcmc), 3, 3*k + 2)\n",
    "        for param in rej_samples.columns:\n",
    "            plt.scatter(list(range(len(rej_samples[param]))), rej_samples[param], label=param, s=2)\n",
    "        plt.xlabel(\"iterations\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Rejected samples from run {}\".format(k+1))\n",
    "\n",
    "        burn_in = int(len(acc) / 2)\n",
    "        n_samples = 1000\n",
    "        posterior_samples = acc[burn_in:]\n",
    "        sample_indices = np.random.uniform(0, len(posterior_samples), n_samples)\n",
    "\n",
    "        pred_dfs = list()\n",
    "        for i in tqdm(sample_indices):\n",
    "            pred_dfs.append(optimiser.solve(posterior_samples[int(i)], default_params, data_split))\n",
    "\n",
    "        for df in pred_dfs:\n",
    "            df.set_index('date', inplace=True)\n",
    "\n",
    "        result = pred_dfs[0].copy()\n",
    "        for col in result.columns:\n",
    "            result[\"{}_low\".format(col)] = ''\n",
    "            result[\"{}_high\".format(col)] = ''\n",
    "\n",
    "        for date in tqdm(pred_dfs[0].index):\n",
    "            for key in pred_dfs[0]:\n",
    "                result.loc[date, key], result.loc[date, \"{}_low\".format(key)], result.loc[date, \"{}_high\".format(key)] = get_PI(pred_dfs, date, key)\n",
    "\n",
    "        data_split.set_index(\"date\", inplace=True)\n",
    "\n",
    "        plt.subplot(len(mcmc), 3, 3*k + 3)\n",
    "        color = plt.cm.rainbow(np.linspace(0,1,len(compartments)))\n",
    "        for i, bucket in enumerate(compartments):\n",
    "            plt.plot(data_split.index.array, data_split[bucket].tolist(), c=color[i], marker='o', label='Actual {}'.format(bucket))\n",
    "            plt.plot(result.index.array, result[bucket].tolist(), c=color[i], label='Estimated {}'.format(bucket))\n",
    "            plt.plot(result.index.array, result['{}_low'.format(bucket)].tolist(), c=color[i], linestyle='dashdot')\n",
    "            plt.plot(result.index.array, result['{}_high'.format(bucket)].tolist(), c=color[i], linestyle='dashdot')\n",
    "        plt.axvline(x=df_train['date'][len(df_train)-1], c='b', linestyle='dashed', label='train-test boundary')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.ylabel(\"Total infected\")\n",
    "        plt.legend()\n",
    "        plt.title(\"95% confidence intervals for {}, {}\".format(district, state))\n",
    "        plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\"./mcmc_runs_{}_{}.png\".format(district, state))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse_runs(df_district, mcmc, district, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
