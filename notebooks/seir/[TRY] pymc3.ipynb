{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import multiprocessing as mp\n",
    "import arviz as az\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "from joblib import delayed, Parallel\n",
    "from collections import defaultdict, OrderedDict\n",
    "import pymc3 as pm\n",
    "from pymc3.ode import DifferentialEquation\n",
    "from utils.generic import init_params\n",
    "from main.seir.optimiser import Optimiser\n",
    "from models.seir.seir_testing import SEIR_Testing\n",
    "from data.processing import get_district_time_series\n",
    "from data.dataloader import get_covid19india_api_data\n",
    "from theano.ifelse import ifelse\n",
    "from theano import tensor as T\n",
    "from theano import tensor as T, function, printing\n",
    "from theano import function\n",
    "import theano\n",
    "theano.config.compute_test_value='ignore'\n",
    "theano.config.gcc.cxxflags = \"-Wno-c++11-narrowing\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load covid19 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = get_covid19india_api_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [('Delhi', ''), ('Karnataka', 'Bengaluru Urban'), ('Maharashtra', 'Mumbai'), ('Maharashtra', 'Pune'), ('Gujarat', 'Ahmedabad'), ('Rajasthan', 'Jaipur')]\n",
    "state, district = regions[2]\n",
    "df_district = get_district_time_series(dataframes, state=state, district=district, use_dataframe='districts_daily')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train-val splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_district.iloc[:-5, :]\n",
    "df_val = df_district.iloc[-5:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('df_train.csv')\n",
    "df_val.to_csv('df_val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Calculation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _calc_rmse(y_pred, y_true, log=True):\n",
    "    if log:\n",
    "        y_true = np.log(y_true)\n",
    "        y_pred = np.log(y_pred)\n",
    "    loss = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "    return loss\n",
    "\n",
    "def _calc_mape(y_pred, y_true):\n",
    "    y_pred = y_pred[y_true > 0]\n",
    "    y_true = y_true[y_true > 0]\n",
    "\n",
    "    ape = np.abs((y_true - y_pred + 0) / y_true) *  100\n",
    "    loss = np.mean(ape)\n",
    "    return loss\n",
    "\n",
    "def calc_loss_dict(states_time_matrix, df, method='rmse', rmse_log=False):\n",
    "    pred_hospitalisations = states_time_matrix[6] + states_time_matrix[7] + states_time_matrix[8]\n",
    "    pred_recoveries = states_time_matrix[9]\n",
    "    pred_fatalities = states_time_matrix[10]\n",
    "    pred_infectious_unknown = states_time_matrix[2] + states_time_matrix[4]\n",
    "    pred_total_cases = pred_hospitalisations + pred_recoveries + pred_fatalities\n",
    "    \n",
    "    if method == 'rmse':\n",
    "        if rmse_log:\n",
    "            calculate = lambda x, y : _calc_rmse(x, y)\n",
    "        else:\n",
    "            calculate = lambda x, y : _calc_rmse(x, y, log=False)\n",
    "    \n",
    "    if method == 'mape':\n",
    "            calculate = lambda x, y : _calc_mape(x, y)\n",
    "    \n",
    "    losses = {}\n",
    "#     losses['hospitalised'] = calculate(pred_hospitalisations, df['Hospitalised'])\n",
    "#     losses['recovered'] = calculate(pred_recoveries, df['Recovered'])\n",
    "#     losses['fatalities'] = calculate(pred_fatalities, df['Fatalities'])\n",
    "#     losses['active_infections'] = calculate(pred_infectious_unknown, df['Active Infections (Unknown)'])\n",
    "    losses['total'] = calculate(pred_total_cases, df['total_infected'])\n",
    "    \n",
    "    return losses\n",
    "\n",
    "def calc_loss(states_time_matrix, df, method='rmse', rmse_log=False):\n",
    "    losses = calc_loss_dict(states_time_matrix, df, method, rmse_log)\n",
    "#     loss = losses['hospitalised'] + losses['recovered'] + losses['total'] + losses['active_infections']\n",
    "    loss = losses['total']\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Interval calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PI(pred_dfs, date, key, multiplier=1.96):\n",
    "    pred_samples = list()\n",
    "    for df in pred_dfs:\n",
    "        pred_samples.append(df.loc[date, key])\n",
    "        \n",
    "    mu = np.array(pred_samples).mean()\n",
    "    sigma = np.array(pred_samples).std()\n",
    "    low = mu - multiplier*sigma\n",
    "    high = mu + multiplier*sigma\n",
    "    return mu, low, high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define new class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SEIR_Test_pymc3(SEIR_Testing):\n",
    "    def __init__(self,  *args, **kwargs):\n",
    "        super().__init__( *args, **kwargs)\n",
    "    def get_derivative(self, y, t, p):\n",
    "        # Init state variables\n",
    "        #for i, _ in enumerate(y):\n",
    "        #for i in range(11):\n",
    "        #    y[i] = ifelse(T.lt(y[i], 0), y[i], np.float64(0))\n",
    "        #    y[i] = max(y[i], 0)\n",
    "        zero = T.cast(0.0, 'float64')\n",
    "        for i in range(11):\n",
    "            T.set_subtensor(y[i], ifelse(T.gt(y[i], zero), y[i], zero))\n",
    "        # Init time parameters and probabilities\n",
    "        for key in self.vanilla_params:\n",
    "            setattr(self, key, self.vanilla_params[key])\n",
    "        for key in self.testing_params:\n",
    "            suffix = '_D' if key in self.vanilla_params else ''\n",
    "            setattr(self, key + suffix, self.testing_params[key])\n",
    "            \n",
    "        \n",
    "        ## Set up variables using `y` and `p`\n",
    "        \n",
    "        S = y[0]\n",
    "        E = y[1]\n",
    "        I = y[2]\n",
    "        D_E = y[3]\n",
    "        D_I = y[4]\n",
    "        R_mild = y[5]\n",
    "        R_severe_home = y[6]\n",
    "        R_severe_hosp = y[7]\n",
    "        R_fatal = y[8]\n",
    "        C = y[9]\n",
    "        D = y[10]\n",
    "        \n",
    "        # p\n",
    "    \n",
    "        self.R0 = p[0]\n",
    "        self.T_inc = p[1]\n",
    "        self.T_inf = p[2]\n",
    "        self.T_recov_severe = p[3]\n",
    "        self.P_severe = p[4]\n",
    "        self.P_fatal = p[5]\n",
    "        self.intervention_amount = p[6]\n",
    "        \n",
    "        #Define variables  \n",
    "        #if self.post_lockdown_R0 == None:\n",
    "        #    self.post_lockdown_R0 = self.lockdown_R0\n",
    "\n",
    "        self.P_mild = 1 - self.P_severe - self.P_fatal\n",
    "\n",
    "        # define testing related parameters\n",
    "        self.T_inf_detected = self.T_inf\n",
    "        self.T_inc_detected = self.T_inc\n",
    "\n",
    "        self.P_mild_detected = self.P_mild\n",
    "        self.P_severe_detected = self.P_severe\n",
    "        self.P_fatal_detected = self.P_fatal\n",
    "        #self.T_trans_D = self.T_trans\n",
    "  \n",
    "        self.theta_E = self.testing_rate_for_exposed\n",
    "        self.psi_E = self.positive_test_rate_for_exposed\n",
    "        self.theta_I = self.testing_rate_for_infected\n",
    "        self.psi_I = self.positive_test_rate_for_infected\n",
    "        #TODO incorporate lockdown R0 code\n",
    "        #T.set_subtensor(self.R0, ifelse(T.gt(t, self.lockdown_removal_day), self.R0 , self.post_lockdown_R0))\n",
    "        # Modelling the behaviour lockdown\n",
    "        #elif t >= self.lockdown_day:\n",
    "        #    self.R0 = self.lockdown_R0\n",
    "        #T.set_subtensor(self.R0, ifelse(T.gt(t, self.lockdown_day), self.R0, self.lockdown_R0))\n",
    "        # Modelling the behaviour pre-lockdown\n",
    "        #else:\n",
    "        #    self.R0 = self.pre_lockdown_R0\n",
    "        #T.set_subtensor(self.R0, ifelse(T.gt(y[i], zero), self.R0, self.pre_lockdown_R0))\n",
    "        self.T_trans = self.T_inf/self.R0\n",
    "        self.T_trans_D = self.T_inf_D/self.R0\n",
    "        \n",
    "       \n",
    "        # Write differential equations\n",
    "        dS = - I * S / (self.T_trans) - (self.q / self.T_trans_D) * (S * D_I) # # S\n",
    "        #dS = - y[2] * y[0]*p[0]/p[2]  - self.q*p[2] * (y[0] * y[4])\n",
    "        dE = I * S / (self.T_trans) + (self.q / self.T_trans_D) * (S * D_I) - (E/ self.T_inc) - (self.theta_E * self.psi_E * E) # E\n",
    "        dI = E / self.T_inc - I / self.T_inf - (self.theta_I * self.psi_I * I) # I\n",
    "        dD_E = (self.theta_E * self.psi_E * E) - (1 / self.T_inc_D) * D_E# D_E\n",
    "        dD_I = (self.theta_I * self.psi_I * I) + (1 / self.T_inc_D) * D_E - (1 / self.T_inf_D) * D_I # D_I \n",
    "        dR_mild = (1/self.T_inf)*(self.P_mild*I) + (1/self.T_inf_D)*(self.P_mild_D*D_I) - R_mild/self.T_recov_mild  # R_mild\n",
    "        dR_severe_home = (1/self.T_inf)*(self.P_severe*I) + (1/self.T_inf_D)*(self.P_severe_D*D_I) - R_severe_home/self.T_hosp  # R_severe_home\n",
    "        dR_severe_hosp = R_severe_home/self.T_hosp - R_severe_hosp/self.T_recov_severe# R_severe_hosp\n",
    "        dR_fatal = (1/self.T_inf)*(self.P_fatal*I) + (1/self.T_inf_D)*(self.P_fatal_D*D_I) - R_fatal/self.T_death # R_fatal\n",
    "        dC = R_mild/self.T_recov_mild + R_severe_hosp/self.T_recov_severe # C\n",
    "        dD = R_fatal/self.T_death # D\n",
    "\n",
    "        return [dS, dE, dI, dD_E, dD_I, dR_mild, dR_severe_home, dR_severe_hosp, dR_fatal, dC, dD]\n",
    "    \n",
    "    def init_intermediate(self, variable_params, default_params, df_true, start_date=None, end_date=None, \n",
    "              state_init_values=None, initialisation='starting', loss_indices=[-20, -10]):\n",
    "        params_dict = {**variable_params, **default_params}\n",
    "        if initialisation == 'intermediate':\n",
    "            row = df_true.iloc[loss_indices[0], :]\n",
    "            \n",
    "            state_init_values = OrderedDict()\n",
    "            key_order = ['S', 'E', 'I', 'D_E', 'D_I', \n",
    "                'R_mild', 'R_severe_home', 'R_severe_hosp', 'R_fatal', 'C', 'D']\n",
    "            for key in key_order:\n",
    "                state_init_values[key] = 0\n",
    "\n",
    "            state_init_values['R_severe_hosp'] = params_dict['P_severe'] / (params_dict['P_severe'] + params_dict['P_fatal']) * row['hospitalised']\n",
    "            state_init_values['R_fatal'] = params_dict['P_fatal'] / (params_dict['P_severe'] + params_dict['P_fatal']) * row['hospitalised']\n",
    "            state_init_values['C'] = row['recovered']\n",
    "            state_init_values['D'] = row['deceased']\n",
    "\n",
    "            state_init_values['E'] = params_dict['E_hosp_ratio'] * row['hospitalised']\n",
    "            state_init_values['I'] = params_dict['I_hosp_ratio'] * row['hospitalised']\n",
    "            \n",
    "            nonSsum = sum(state_init_values.values())\n",
    "            state_init_values['S'] = (params_dict['N'] - nonSsum)\n",
    "            for key in state_init_values.keys():\n",
    "                state_init_values[key] = state_init_values[key]/params_dict['N']\n",
    "\n",
    "            params_dict['state_init_values'] = state_init_values\n",
    "        \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = T.scalar('x')\n",
    "z = T.scalar('z')\n",
    "xplus = ifelse(T.lt(x, z), x, z)\n",
    "xplus.eval({x:1,z:0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEIR_Test_obj = SEIR_Test_pymc3()\n",
    "num_patients = SEIR_Test_obj.__dict__['vanilla_params']['N']\n",
    "init_vals = list(SEIR_Test_obj.__dict__['state_init_values'].values())\n",
    "num_states = 11\n",
    "num_params = 7\n",
    "num_steps = 40\n",
    "num_train_steps = 7\n",
    "\n",
    "\n",
    "burn_in = 100\n",
    "mcmc_steps = 400\n",
    "\n",
    "observed = df_train['total_infected'][-num_train_steps:]\n",
    "num_train = len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sir_model = DifferentialEquation(\n",
    "    func=SEIR_Test_obj.get_derivative,\n",
    "    times=np.arange(0, num_steps, 1),\n",
    "    n_states= num_states,\n",
    "    n_theta= num_params,\n",
    "    t0 = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    R0 = pm.Uniform(\"R0\", lower = 1, upper = 3.5)#(1.6, 3)\n",
    "    T_inc = pm.Uniform(\"T_inc\", lower = 1, upper = 5)#(3, 4)\n",
    "    T_inf = pm.Uniform(\"T_inf\", lower = 1, upper = 4)#(3, 4)\n",
    "    T_recov_severe = pm.Uniform(\"T_recov_severe \", lower = 9, upper = 20)\n",
    "    P_severe = pm.Uniform(\"P_severe\", lower = 0.3, upper = 0.99)\n",
    "    P_fatal = pm.Uniform(\"P_fatal\", lower = 1e-4, upper = 0.3)\n",
    "    intervention_amount = pm.Uniform(\"intervention_amount\", lower = 0.3, upper = 1)\n",
    "    \n",
    "    ode_solution = sir_model(y0=init_vals , theta=[R0, T_inc, T_inf, T_recov_severe, P_severe,\n",
    "                                                   P_fatal, intervention_amount])\n",
    "    # The ode_solution has a shape of (n_times, n_states)\n",
    "    \n",
    "    predictions = ode_solution[num_train-num_train_steps-1:num_train-1]\n",
    "    hospitalised = predictions[:,6] + predictions[:,7] + predictions[:,8]\n",
    "    recovered = predictions[:,9]\n",
    "    deceased = predictions[:,10]\n",
    "    total_infected = hospitalised + recovered + deceased\n",
    "    total_infected = total_infected * num_patients \n",
    "    #sigma = pm.HalfNormal('sigma',\n",
    "    #                      sigma=observed.std(),\n",
    "    #                      shape=num_params)\n",
    "    Y = pm.Normal('Y', mu = total_infected, observed=observed)\n",
    "    \n",
    "    prior = pm.sample_prior_predictive()\n",
    "    trace = pm.sample(mcmc_steps, tune=burn_in , target_accept=0.9, cores=4)\n",
    "    posterior_predictive = pm.sample_posterior_predictive(trace)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " theano.printing.Print(\"Predictions\")(ode_solution[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theano.printing.Print(\"R0\")(R0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    data = az.from_pymc3(trace=trace, prior=prior, posterior_predictive=posterior_predictive)\n",
    "    az.plot_posterior(data,round_to=2, credible_interval=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pm.forestplot(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plots.traceplot(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plots.autocorrplot(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trace[500:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_runs = trace#[burn_in:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the samples and intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def visualize(): \n",
    "data_split = df_district.copy()\n",
    "optimiser = Optimiser()\n",
    "default_params = optimiser.init_default_params(data_split)\n",
    "\n",
    "#combined_acc = list()\n",
    "#for k, run in enumerate(mcmc):\n",
    "#    burn_in = int(len(run) / 2)\n",
    "#    combined_acc += run[0][burn_in:]\n",
    "\n",
    "n_samples = 1000\n",
    "sample_indices = np.random.uniform(0, len(final_runs), n_samples)\n",
    "\n",
    "pred_dfs = list()\n",
    "for i in tqdm(sample_indices):\n",
    "    pred_dfs.append(optimiser.solve(final_runs[int(i)], \n",
    "                default_params, data_split, \n",
    "                initialisation = 'intermediate', \n",
    "                start_date = data_split.iloc[-num_train_steps, :].date,\n",
    "                end_date= data_split.iloc[-1, :].date,\n",
    "                hardcode_ratios = True, loss_indices = [-num_train_steps,0]))\n",
    "\n",
    "for df in pred_dfs:\n",
    "    df.set_index('date', inplace=True)\n",
    "\n",
    "result = pred_dfs[0].copy()\n",
    "for col in result.columns:\n",
    "    result[\"{}_low\".format(col)] = ''\n",
    "    result[\"{}_high\".format(col)] = ''\n",
    "\n",
    "for date in tqdm(pred_dfs[0].index):\n",
    "    for key in pred_dfs[0]:\n",
    "        result.loc[date, key], result.loc[date, \"{}_low\".format(key)], result.loc[date, \"{}_high\".format(key)] = get_PI(pred_dfs, date, key)\n",
    "\n",
    "data_split.set_index(\"date\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_runs[int(i)],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split['total_infected']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['hospitalised']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dfs[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result['total_infected'], data_split['total_infected']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_plot = range(len(df_train) - len(observed)-7, len(df_train) - len(observed) + num_steps)\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(data_split['total_infected'].tolist(), c='g', label='Actual')\n",
    "plt.plot( result['total_infected'].tolist(), c='r', label='Estimated')\n",
    "plt.plot( result['total_infected_low'].tolist(), c='r', linestyle='dashdot')\n",
    "plt.plot( result['total_infected_high'].tolist(), c='r', linestyle='dashdot')\n",
    "plt.axvline(x=len(df_train), c='b', linestyle='dashed')\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"Total infected\")\n",
    "plt.legend()\n",
    "plt.title(\"95% confidence intervals for {}, {}\".format(district, state))\n",
    "\n",
    "plt.savefig('./mcmc_confidence_intervals_{}_{}.png'.format(district, state))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
